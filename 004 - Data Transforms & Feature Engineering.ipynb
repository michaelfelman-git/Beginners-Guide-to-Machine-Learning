{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe1ee60",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">DATA TRANSFORMS & FEATURE ENGINEERING</h1>\n",
    "<h3><mark style=\"background-color: yellow\">CONTENTS</mark></h3>\n",
    "\n",
    "- [**NEED FOR PREPROCESSING**](#need)\n",
    "- [**HOW TO SCALE NUMERICAL DATA**](#intro)\n",
    "    - [**Scale of the Data Matters**](#matter)\n",
    "    - [**Common Numerical Data Scaling Methods**](#method)\n",
    "        - [**Centering**](#center)\n",
    "        - [**MinMaxScaler**](#minmax)\n",
    "        - [**MaxAbsScaler**](#maxabs)\n",
    "        - [**Normalization**](#norm)\n",
    "        - [**Standardization**](#stand)\n",
    "        - [**Diabetes Dataset Example**](#diab)\n",
    "        - [**Data Binarization**](#binary)\n",
    "    - [**Common Tips & Questions**](#common)\n",
    "- [**HOW TO SCALE DATA WITH OUTLIERS**](#out)\n",
    "    - [**Robust Scaling Data**](#robust)\n",
    "    - [**Robust Scaler Transforms**](#scale)\n",
    "    - [**IQR Robust Scaler Transform**](#iqr)\n",
    "    - [**Explore Robust Scaler Range**](#explore)\n",
    "- [**HOW TO ENCODE CATEGORICAL DATA**](#categ)\n",
    "    - [**Nominal and Ordinal Variables**](#var)\n",
    "    - [**Encoding Categorical Data**](#encode)\n",
    "        - [**Ordinal Encoding**](#ord)\n",
    "        - [**One Hot Encoding**](#hot)\n",
    "        - [**Dummy Variable Encoding**](#dummy)\n",
    "    - [**Breast Cancer Dataset Example**](#bre)\n",
    "        - [**OrdinalEncoder Transform**](#tran)\n",
    "        - [**OneHotEncoder Transform**](#one)\n",
    "        - [**Dummy Variable Transform**](#dum)\n",
    "        - [**ColumnTansformer**](#col)\n",
    "    - [**Common Questions**](#quest)\n",
    "- [**HOW TO MAKE DISTRIBUTIONS MORE GAUSSIAN**](#gaus)\n",
    "    - [**Power Transforms**](#power)\n",
    "        - [**Sonar Dataset**](#sonar)\n",
    "        - [**Box-Cox Transform**](#box)\n",
    "        - [**Yeo-Johnson Transform**](#yeo)\n",
    "- [**HOW TO CHANGE NUMERICAL DISTRIBUTIONS**](#change)\n",
    "    - [**Quantile Transforms**](#quant)\n",
    "        - [**Normal Quantile Transform**](#nqt)\n",
    "        - [**Uniform Quantile Transform**](#uqt)\n",
    "        - [**Select Number of Quantiles**](#select)\n",
    "- [**HOW TO TRANSFORM NUMERICAL TO CATEGORICAL DATA**](#cat)\n",
    "    - [**Discretization Transforms**](#disc)\n",
    "        - [**Uniform Discretization Transform**](#uni)\n",
    "        - [**k-Means Discretization Transform**](#kmean)\n",
    "        - [**Quantile Discretization Transform**](#qdt)\n",
    "    - [**Grouping Observations Using Clustering**](#cluster)\n",
    "- [**HOW TO DERIVE NEW INPUT VARIABLES**](#derive)\n",
    "    - [**Interaction Terms**](#inter)\n",
    "    - [**Polynomial Features**](#poly)\n",
    "        - [**Polynomial Feature Transform**](#pft)\n",
    "        - [**Effect of Polynomial Degree**](#degree)\n",
    "    - [**Transforming Features with FunctionTransformer**](#func)\n",
    "- [**HOW TO TRANSFORM NUMERICAL AND CATEGORICAL DATA**](#num_cat)\n",
    "    - [**Challenge of Transforming Different Data Types**](#chall)\n",
    "    - [**How to use the ColumnTransformer**](#use)\n",
    "    - [**Abalone Regression Dataset**](#abalone)\n",
    "- [**HOW TO TRANSFORM THE TARGET VARIABLE**](#reg)\n",
    "    - [**Handling Imbalanced Classes**](#imbal)\n",
    "    - [**How to Scale Target Variables**](#target)\n",
    "        - [**Manual Transform of the Target Variable**](#manual)\n",
    "        - [**Automatic Transform of the Target Variable**](#auto)\n",
    "    - [**Using the TransformedTargetRegressor**](#ttr)\n",
    "- [**HOW TO HANDLE TEXT**](#text)\n",
    "    - [**Cleaning Text**](#clean)\n",
    "        - [**Removing Punctuation**](#punc)\n",
    "    - [**Parsing and Cleaning HTML**](#parse)\n",
    "    - [**Tokenizing Text**](#token)\n",
    "    - [**Removing Stop Words**](#stop)\n",
    "    - [**Stemming Words**](#stem)\n",
    "    - [**Tagging Parts of Speech**](#tag)\n",
    "    - [**Encoding Text as a Bag of Words**](#bag)\n",
    "    - [**Weighting Word Importance**](#weigh)\n",
    "- [**HOW TO HANDLE DATES & TIMES**](#date)\n",
    "    - [**Converting Strings to Dates**](#convert)\n",
    "    - [**Handling Time Zones**](#zone)\n",
    "    - [**Selecting Dates and Times**](#time)\n",
    "    - [**Breaking Up Time Data into Multiple Features**](#break)\n",
    "    - [**Calculating the Difference Between Dates**](#diff)\n",
    "    - [**Encoding Days of the Week**](#week)\n",
    "    - [**Creating a Lagged Feature**](#lag)\n",
    "    - [**Using Rolling Time Windows**](#roll)\n",
    "    - [**Handling Missing Data in Time Series**](#miss)\n",
    "- [**HOW TO SAVE AND LOAD DATA TRANSFORMS**](#how)\n",
    "    - [**Challenge of Preparing New Data for a Model**](#prep)\n",
    "    - [**Save Data Preparation Objects**](#data)\n",
    "    - [**Save Model and Data Scaler**](#save)\n",
    "    - [**Load Model and Data Scaler**](#load)\n",
    "- [**REFERENCES**](#ref)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef0ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83dc80",
   "metadata": {},
   "source": [
    "<a id=\"need\"></a>\n",
    "<h1 align=\"center\">NEED FOR PREPROCESSING</h1>\n",
    "\n",
    "Many machine learning algorithms make assumptions about data. As such, it is often a good idea (and best practice) to prepare the data in such a way to best expose the structure of the problem to the machine learning algorithms intended for use. One of the difficulties is that different algorithms make different assumptions about data and may require different transforms. Further, when you follow all of the rules and prepare your data, sometimes algorithms can deliver better results without pre-processing. \n",
    ">**It is recommended to apply a handful of different machine learning algorithms to many different views and transforms of the data. This will help flush out which data transforms might be better at exposing the structure of the problem in general.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc401ffa",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "<h1 align=\"center\">HOW TO SCALE NUMERICAL DATA</h1>\n",
    "\n",
    "**Scaling** data is the process of increasing or decreasing the magnitude according to a fixed ratio (i.e. change the range of the values). In other words, you change the size but not the shape of the data (i.e. the shape of the distribution is unchanged). Think about how a scale model of a building has the same proportions as the original, just smaller.\n",
    "\n",
    "Some data scaling methods often change the *location* of the data as well. For example, when \"centering\" we take a distribution and change it's mean to be zero by subtracting the mean of the distribution from each data point in the distribution. While this is not technically \"scaling\", changing the location is often a component of the process and preserves the shape of the data (it just shifts it around).\n",
    "\n",
    "**There are a number of good reasons why we scale data:**\n",
    "- To handle disparities in units.\n",
    "- Cut computational expense.\n",
    "- Improve model performance (Especially in Machine Learning).\n",
    "- We scale for models to prevent the steps on different axes from varying widely.\n",
    "\n",
    "It is common to scale data prior to fitting a machine learning model. This is because data often consists of many different input variables or features (columns) and each may have a different range of values or units of measure, such as feet, miles, kilograms, dollars, etc. If there are input variables that have very large values relative to the other input variables, these large values can dominate or skew some machine learning algorithms. The result is that the algorithms pay most of their attention to the large values and ignore the variables with smaller values. \n",
    "\n",
    "This pertains to algorithms that use a weighted sum of inputs like linear regression, logistic regression, and artificial neural networks, as well as algorithms that use distance measures between examples, such as k-nearest neighbors and support vector machines. As such, it is normal to scale input variables to a common range as a data preparation technique prior to fitting a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7043f",
   "metadata": {},
   "source": [
    "Some popular methods for scaling datasets prior to modeling are:\n",
    "- **Centering** - Mean centering is the act of subtracting a variable's mean from all observations on that variable in the dataset such that the variable's new mean is zero.\n",
    "- **Normalization** scales each input variable separately to the range 0-1, which is the range for floating-point values where we have the most precision.\n",
    "- **Standardization** scales each input variable separately by subtracting the mean (called centering) and dividing by the standard deviation to shift the distribution to have a mean of zero and a standard deviation of one. \n",
    "- **Robust** - Using the median and interquartile range when standardizing numerical input variables.\n",
    "- **Binarization** is the process of dividing data into two groups - `from sklearn.preprocessing import Binarizer`\n",
    "\n",
    "**Assumptions**:\n",
    "- Implicit/explicit assumptions of machine learning algorithms - features follow a normal distribution.\n",
    "* Most method are based on linear assumptions\n",
    "* Most machine learning requires the data to be normally distributed - Gaussian with zero mean and unit variance.\n",
    "* Many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) **assume that all features are centered around zero and have variance in the same order**. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75d6b0",
   "metadata": {},
   "source": [
    "<a id=\"matter\"></a>\n",
    "<h2><ins>Scale of the Data Matters</ins></h2>\n",
    "\n",
    "Machine learning models learn a mapping from input variables to an output variable. As such, the scale and distribution of the data drawn from the domain may be different for each variable. Differences in the scales across input variables may increase the difficulty of the problem being modeled. An example of this is that large input values (e.g. a spread of hundreds or thousands of units) can result in a model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer from poor performance during learning and sensitivity to input values resulting in higher generalization error. \n",
    "\n",
    "This difference in scale for input variables does not affect all machine learning algorithms. Some of the algorithms unaffected by the scale of numerical input variables are *decision trees* and *ensembles of trees*, like *random forest*. **This is because they consider features independently**.\n",
    "\n",
    "When data is comprised of attributes with varying scales, many machine learning algorithms can benefit from rescaling the attributes to all have the same scale. This is useful for optimization algorithms used in the core of machine learning algorithms like gradient descent. **Many machine learning algorithms perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed.**<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;$Algorithms that fit a model that use a weighted sum of input variables are affected by the scale, such as *linear regression*, *logistic regression*, *perceptrons* and *artificial neural networks (deep learning)*. If using gradient descent/ascent-based optimization, some weights will update much faster than others.\n",
    "> **Note:** In ordinary linear regression, centering and scaling variables does *not* impact the amount of variance accounted for. This is because we are only moving and adjusting the magnitude of the distribution: the shape of the distribution does not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fce286",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis, Principal Component Analysis, Kernel Principal Component analysis are also affected by the scale. Since you want to find directions of maximizing the variance (under the constraints that those directions/eigenvectors/principal components are orthogonal); you want to have features on the same scale since you would emphasize variables on \"larger measurement scales\" more.<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;$Finally, algorithms that use distance measures between examples are affected, such as *k-nearest neighbors*, *k-means* and *support vector machines*. \n",
    ">Different attributes are measured on different scales, so if the Euclidean distance formula were used directly, the effect of some attributes might be completely dwarfed by others that had larger scales of measurement.\n",
    ">>When the distance or dot products between predictors are used, or when the variables are required to be a common scale in order to apply a penalty, a standardization procedure is essential to allow features to contribute equally.\n",
    "\n",
    "It can also be a good idea to scale the target variable for regression predictive modeling problems to make the problem easier to learn, most notably in the case of neural network models. A target variable with a large spread of values, in turn, may result in large error gradient values causing weight values to change dramatically, making the learning process unstable. Scaling input and output variables is a critical step in using neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abbfdf",
   "metadata": {},
   "source": [
    "<a id=\"common\"></a>\n",
    "<h2><ins>Common Tips & Questions</ins></h2>\n",
    "\n",
    ">If you want more normally distributed data, and are okay with transforming the data - try `QuantileTransformer(output_distribution='normal')`.\n",
    "\n",
    "**Should I Normalize or Standardize?** - Whether input variables require scaling depends on the specifics of the problem and of each variable. If the distribution of the data is normal, then it should be standardized, otherwise, the data should be normalized.\n",
    "- Standardization assumes data conforms to a normal distribution.\n",
    "- Normalization does not assume any specific distribution.\n",
    "\n",
    "In clustering analyses, standardization may be especially crucial in order to compare similarities between features based on certain distance measures. Another prominent example is the Principal Component Analysis, where we usually prefer standardization over Min-Max scaling, since we are interested in the components that maximize the variance (depending on the question and if the PCA computes the components via the correlation matrix instead of the covariance matrix. However, this doesn’t mean that Min-Max scaling is not useful at all! A popular application is image processing, where pixel intensities have to be normalized to fit within a certain range (i.e., 0 to 255 for the RGB color range). Also, typical neural network algorithm require data that on a 0-1 scale.\n",
    "\n",
    "If the data values are small (near 0-1) and the distribution is limited (e.g. standard deviation near 1), then perhaps no scaling of the data is required. Predictive modeling problems can be complex, and it may not be clear how to best scale input data. If in doubt, normalize the input sequence. If you have the resources, ***explore modeling with the raw data, standardized data, and normalized data and see if there is a beneficial difference in the performance of the resulting model.***\n",
    "\n",
    "**Should I Standardize then Normalize?** - Standardization can give values that are both positively and negatively centered around zero. It may be desirable to normalize data after it has been standardized. This might be a good idea of you have a mixture of standardized and normalized variables and wish all input variables to have the same minimum and maximum values as input for a given algorithm, such as an algorithm that calculates distance measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6fe54",
   "metadata": {},
   "source": [
    "<a id=\"method\"></a>\n",
    "<h2><ins>Common Numerical Data Scaling Methods</ins></h2>\n",
    "\n",
    "Good practice usage with scaling techniques is as follows:\n",
    "- **Fit the scaler using available training data** - For normalization, this means the training data will be used to estimate the min and max observable values. For standardization, this means calculating the mean and standard deviation. This is done by calling the `fit()` function.\n",
    "- **Apply the scale to training data** - This means we can use the scaled data to train a model. This is done by calling the `transform()` function.\n",
    "- **Apply the scale to data going forward** - This means we can prepare new data in the future on which we want to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404c5d2",
   "metadata": {},
   "source": [
    "|Preprocessing<br>Type|Sklearn<br>Function|Range|Mean|Distribution<br>Characteristics|When Use|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Scale|MinMaxScaler|0 to 1 default,<br>can override|varies|Bounded|When want a light touch.|\n",
    "|Standardize|RobustScaler|varies|varies|Unbounded|Use if have outliers and don't<br>want them to have much influence.|\n",
    "|Standardize|StandardScaler|varies|0|Unbounded,<br>Unit variance|When need to transform a feature with<br>zero mean and unit standard deviation.|\n",
    "|Normalize|Normalizer|varies|0|Unit norm|Rarely| \n",
    "<br>\n",
    "\n",
    "|Definition|Notes|\n",
    "|:-:|:-:|\n",
    "|**MinMaxScaler** subtracts the minimum value in the column and then divides by the difference between the original maximum and original minimum.|Preserves the shape of the original distribution. Doesn't reduce the importance of outliers. Least disruptive to the information in the original data. Default range is [0,1].|\n",
    "|**RobustScaler** standardizes a feature by removing the median and dividing by the interquartile range.|Outliers have less influence. Range is larger than MinMaxScaler or StandardScaler.\n",
    "|**StandardScaler** standardizes a feature by removing the mean and dividing each value by the standard deviation.|Results in a distribution with a standard deviation equal to 1 (and variance equal to 1). If outliers are present, normalizing will scale most of the data to a small interval.| \n",
    "|An observation (row) is **normalized** by applying l2 (Euclidian) normalization. If each element were squared and summed, the total would equal 1. Could also specify l1 (Manhatten) normalization.|Normalizes each sample observation (row), not the feature (column)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba5a7d",
   "metadata": {},
   "source": [
    "<a id=\"center\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Centering</h5>\n",
    "\n",
    "We can start with the simplest transformation example - **changing the location of data**. If we have a distribution of values $X$, then to center our data to a new distribution $X_c$:\n",
    "$$X_c = X - \\bar{X}$$\n",
    ">The primary benefit of centering data in linear modeling is so **the intercept represents the estimate of the target when all predictors are at their mean value.** If we don't center, the intercept is the estimate of our model when all predictors are at value 0. It often makes the intercept much more interpretable when centering the predictors. Centering the data will not change the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5b43d",
   "metadata": {},
   "source": [
    "<a id=\"minmax\"></a>\n",
    "<h5 style=\"text-decoration:underline\">MinMaxScaler</h5>\n",
    "\n",
    "**Transform features by scaling each feature to a given range.** This estimator scales and transforms each feature individually such that it is in the given range on the training set. MinMaxScaler preserves the shape of the original distribution. It doesn’t meaningfully change the information embedded in the original data.\n",
    "- **Note that MinMaxScaler doesn’t reduce the importance of outliers. It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).**\n",
    "\n",
    "This transformation is often used as an alternative to zero mean, unit variance scaling. The motivation to use this scaling include robustness to very small standard deviations of features and preserving zero entries in sparse data. This scaler also works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better.\n",
    ">MinMaxScaler isn’t a bad place to start, unless you know you want your features to have a normal distribution (`StandardScaler`) or you have outliers and you want them to have reduced influence (`RobustScaler`).\n",
    "\n",
    "For each value in a feature, MinMaxScaler subtracts the minimum value in the feature and then divides by the range. The range is the difference between the original maximum and original minimum. The transformation is given by:\n",
    "\n",
    "$$X = \\frac{(X - X.min(axis=0))}{(X.max(axis=0) - X.min(axis=0))}$$\n",
    "\n",
    "-  If an $x$ value is provided that is outside the bounds of the min and max values, the resulting value will not be in the range of 0 and 1. We can check for these observations prior to making predictions and either remove them from the dataset or limit them to the pre-defined min or max values. \n",
    "<br><br>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_minmax = MinMaxScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "```\n",
    "The default scale for the MinMaxScaler is to rescale variables into the range [0,1], although a preferred scale can be specified via the `feature_range` argument as a tuple containing the min and the max for all variables. If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the `inverse_transform()` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca65a4",
   "metadata": {},
   "source": [
    "<a id=\"maxabs\"></a>\n",
    "<h5 style=\"text-decoration:underline\">MaxAbsScaler</h5>\n",
    "\n",
    "**Scale each feature by its maximum absolute value.** This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "\n",
    "`MaxAbsScaler` works very similar to `MinMaxScaler` but scales in a way that the training data lies within the range [-1, 1] by dividing through the largest maximum value in each feature. **It is meant for data that is already centered at zero or sparse data.**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "X_minmax = MaxAbsScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d407c37",
   "metadata": {},
   "source": [
    "<a id=\"norm\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Normalization</h5>\n",
    "\n",
    "**Normalize samples individually to unit norm.** Normalization is a rescaling of the data from the original range so that all values are within the new range of 0 and 1. Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra). This pre processing method can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as k-Nearest Neighbors.\n",
    ">This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples. This assumption is the base of the Vector Space Model often used in text classification and clustering contexts. \n",
    "\n",
    "There are two types of Normalization\n",
    "- **L1 normalization** - Least Absolute Deviations ensure the sum of absolute values is 1 in each row.\n",
    "- **L2 normalization** - Least squares ensure that the sum of squares is 1.\n",
    "\n",
    "**Sklearn's `Normalizer` works on the rows, not the columns.** By default, L2 normalization is applied to each observation so the that the values in a row have a unit norm.\n",
    ">Unit norm with L2 (Euclidean) means that if each element were squared and summed, the total would equal 1. Alternatively, L1 (aka taxicab or Manhattan) normalization can be applied instead of L2 normalization.\n",
    "\n",
    "In most cases one of the other preprocessing tools will be more helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d55c3a",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.preprocessing import normalize, Normalizer\n",
    "\n",
    "X_norm = normalize(X, norm='l2')\n",
    "\n",
    "or\n",
    "\n",
    "X_norm = Normalizer(norm='l2').fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a29ac8",
   "metadata": {},
   "source": [
    "<a id=\"stand\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Standardization</h5>\n",
    "\n",
    "**Standardize features by removing the mean and scaling to unit variance. Assumes the data is normally distributed within each feature.** \n",
    "\n",
    "Standardizing a dataset involves rescaling the distribution of values so that the mean value is removed (mean is 0) and the standard deviation is 1. This is to remove bias. Subtracting the mean from the data is called *centering*, whereas dividing by the standard deviation is called *scaling*. As such, the method is sometimes called *center scaling*. Can be influenced by outliers. `StandardScaler` therefore cannot guarantee balanced feature scales in the presence of outliers. \n",
    "- Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used later in the `transform` stage.\n",
    "\n",
    "Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms. Furthermore, many machine learning algorithms behave badly if the individual features do not more or less look like standard normally distributed data: **Gaussian with zero mean and unit variance**.\n",
    "- However, it depends on the learning algorithm. For example, principal component analysis often works better using standardization, while min-max scaling is often recommended for neural networks.\n",
    "- If the data has significant outliers, it can negatively impact standardization by affecting the feature’s mean and variance. In this case, it is often helpful to instead rescale the feature using the median and quartile range (i.e. use `RobustScaler`).\n",
    "- \n",
    "\n",
    "Standardization assumes that the observations fit a Gaussian distribution (bell curve) with a well-behaved mean and standard deviation. If this expectation is not met, we can still standardize the data, but may not get reliable results. A value is standardized as follows:\n",
    "$$Z=\\frac{X-\\mu}{\\sigma}$$\n",
    "\n",
    "where:\n",
    "- $mean=\\frac{\\Sigma{x_i}}{N}$$\\;\\;$\n",
    "- $standard\\;deviation=\\sqrt{\\frac{\\Sigma{(x_i-mean)^2}}{N-1}}$\n",
    "\n",
    "The mean and standard deviation estimates of a dataset can be more robust to new data than the minimum and maximum.\n",
    "\n",
    "There are many benefits to standardizing data, especially when there is more than one predictor present:\n",
    "- Intercepts are interpreted as the estimate when all predictors are at their mean value.\n",
    "- Coefficients are in units of standard deviations of the original predictors. This allows for direct comparison of the magnitude of impact between different predictors.\n",
    "- Optimization methods (minimizing loss functions) are faster and more stable.\n",
    "- It is required for regularization penalties where the magnitude of coefficients for different predictors must have the same meaning.\n",
    "- In K-Nearest Neighbors methods it is necessary if you want features to contribute equally since these models use the distance between observations calculated from the features.\n",
    "- K-means clustering is affected by the scale of the data and standardizing the features will prevent variables from dominating simply based on their scale.\n",
    "- In logistic regression, neural networks, and support vector machines unscaled data can result in a disproportionate effect of some data points over others.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_std = ss.fit_transform(X_train)\n",
    "X_test_std = ss.transform(X_test)\n",
    "```\n",
    "It is possible to disable either centering or scaling by either passing \n",
    "`with_mean=False` or `with_std=False` to the constructor of `StandardScaler`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584c735",
   "metadata": {},
   "source": [
    "<a id=\"diab\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Diabetes Dataset Example</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1cdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59d33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diab = pd.read_csv('./datasets/Data Transforms/Diabetes.csv',header=None)\n",
    "df_diab.columns = ['pregnant','glucose_conc','blood_press','tricep_thick',\n",
    "                  'serum_ins','bmi','pedigree','age','target']\n",
    "\n",
    "X = df_diab.drop('target', axis=1)\n",
    "y = df_diab['target']\n",
    "\n",
    "# ensure inputs are floats and output is an integer label\n",
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a0e772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>blood_press</th>\n",
       "      <th>tricep_thick</th>\n",
       "      <th>serum_ins</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant  glucose_conc  blood_press  tricep_thick   serum_ins  \\\n",
       "count  768.000000    768.000000   768.000000    768.000000  768.000000   \n",
       "mean     3.845052    120.894531    69.105469     20.536458   79.799479   \n",
       "std      3.369578     31.972618    19.355807     15.952218  115.244002   \n",
       "min      0.000000      0.000000     0.000000      0.000000    0.000000   \n",
       "25%      1.000000     99.000000    62.000000      0.000000    0.000000   \n",
       "50%      3.000000    117.000000    72.000000     23.000000   30.500000   \n",
       "75%      6.000000    140.250000    80.000000     32.000000  127.250000   \n",
       "max     17.000000    199.000000   122.000000     99.000000  846.000000   \n",
       "\n",
       "              bmi    pedigree         age      target  \n",
       "count  768.000000  768.000000  768.000000  768.000000  \n",
       "mean    31.992578    0.471876   33.240885    0.348958  \n",
       "std      7.884160    0.331329   11.760232    0.476951  \n",
       "min      0.000000    0.078000   21.000000    0.000000  \n",
       "25%     27.300000    0.243750   24.000000    0.000000  \n",
       "50%     32.000000    0.372500   29.000000    0.000000  \n",
       "75%     36.600000    0.626250   41.000000    1.000000  \n",
       "max     67.100000    2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517f8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histograms of the variables\n",
    "fig = df_diab.hist(xlabelsize=8, ylabelsize=8,figsize=(10,6))\n",
    "[x.title.set_size(8) for x in fig.ravel()]\n",
    "\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa61518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import (MinMaxScaler, StandardScaler, MaxAbsScaler,\n",
    "                                   RobustScaler, Normalizer)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f563ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardized', StandardScaler()),\n",
       "                ('model', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('standardized', StandardScaler()),\n",
    "              ('model', KNeighborsClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c52780",
   "metadata": {},
   "source": [
    "<ins>Accessing the `named_steps` attribute<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a066dc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardized': StandardScaler(), 'model': KNeighborsClassifier()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddb0ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cc60a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23e8fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe['standardized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ff67f",
   "metadata": {},
   "source": [
    "<ins>Accessing the `steps` attribute<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6435a502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardized', StandardScaler()), ('model', KNeighborsClassifier())]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd9c6a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('standardized', StandardScaler())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0d166a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047da7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2f68c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps.model == pipe.steps[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1e04a",
   "metadata": {},
   "source": [
    "<ins>Spot check different scaling methods<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a5d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with   original   data: 0.717 +/-(0.040)\n",
      "Accuracy with   centered   data: 0.717 +/-(0.040)\n",
      "Accuracy with    MinMax    data: 0.739 +/-(0.053)\n",
      "Accuracy with    MaxAbs    data: 0.738 +/-(0.048)\n",
      "Accuracy with  normalized  data: 0.690 +/-(0.043)\n",
      "Accuracy with standardized data: 0.741 +/-(0.050)\n"
     ]
    }
   ],
   "source": [
    "# define and configure the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "pipe_dict = {'original': Pipeline(steps=[('m', model)]),\n",
    "             'centered': Pipeline(steps=[('cen', StandardScaler(with_std=False)),\n",
    "                                         ('m', model)]),\n",
    "             'MinMax': Pipeline(steps=[('minmax', MinMaxScaler()), ('m', model)]),\n",
    "             'MaxAbs': Pipeline(steps=[('maxabs', MaxAbsScaler()), ('m', model)]),\n",
    "             'normalized': Pipeline(steps=[('norm', Normalizer()), ('m', model)]),\n",
    "             'standardized': Pipeline(steps=[('std', StandardScaler()), ('m', model)])}\n",
    "\n",
    "for i, pipe in pipe_dict.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipe, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    print(f'Accuracy with {i:^12} data: {np.mean(scores):.3f} +/-({np.std(scores):.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a03448",
   "metadata": {},
   "source": [
    "<a id=\"binary\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Data Binarization</h5>\n",
    "\n",
    "$$f(x)={0,1}$$\n",
    "\n",
    "Feature binarization is the process of thresholding numerical features to get boolean values. All values above the threshold are marked 1 and all equal to or below are marked as 0. \n",
    "- This can be useful for downstream probabilistic estimators that make assumptions that the input data is distributed according to a multi-variate Bernoulli distribution.\n",
    "- It can be useful when you have probabilities that you want to make crisp values. \n",
    "- It is also useful when feature engineering and you want to add new features that indicate something meaningful.\n",
    "- It is also common among the text processing community to use binary feature values (probably to simplify the probabilistic reasoning) even if normalized counts (a.k.a. term frequencies) or TF-IDF valued features often perform slightly better in practice.\n",
    "\n",
    "```python\n",
    "# Using Sklearn\n",
    "---------------\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X_bin = Binarizer(threshold=0.0).fit_transform(X)\n",
    "\n",
    "# Using Numpy\n",
    "-------------\n",
    "np.digitize(x, bins, right=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb11008",
   "metadata": {},
   "source": [
    "<a id=\"out\"></a>\n",
    "<h1 align=\"center\">HOW TO SCALE DATA WITH OUTLIERS</h1>\n",
    "\n",
    "Standardizing is a popular scaling technique that subtracts the mean from values and divides by the standard deviation, transforming the probability distribution for an input variable to a standard Gaussian (zero mean and unit variance). **Standardization can become skewed or biased if the input variable contains outlier values.** To overcome this, the median and interquartile range can be used when standardizing numerical input variables, generally referred to as **robust scaling**.\n",
    "\n",
    "<a id=\"robust\"></a>\n",
    "<h2><ins>Robust Scaling Data</ins></h2>\n",
    "\n",
    "Sometimes an input variable may have outlier values. These are values on the edge of the distribution that may have a low probability of occurrence, yet are overrepresented for some reason. Outliers can skew a probability distribution and make data scaling using standardization difficult as the calculated mean and standard deviation will be skewed by the presence of the outliers. \n",
    "\n",
    "One approach to standardizing input variables in the presence of outliers is to ignore the outliers from the calculation of the mean and standard deviation, then use the calculated values to scale the variable. This is called **robust standardization** or **robust data scaling**. This can be achieved by calculating the median (50th percentile) and the 25th and 75th percentiles. The values of each variable then have their median subtracted and are divided by the interquartile range (IQR) which is the difference between the 75th and 25th percentiles.\n",
    "$$X_R=\\frac{X-median}{IQR}=\\frac{X-median}{p_{75}-p_{25}}$$\n",
    "**The resulting variable has a zero mean and median and a standard deviation of 1, although not skewed by outliers and the outliers are still present with the same relative relationships to other values.**\n",
    ">Unlike the previous scalers, the centering and scaling statistics of `RobustScaler` is based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe41cad",
   "metadata": {},
   "source": [
    "<a id=\"scale\"></a>\n",
    "<h2><ins>Robust Scaler Transforms</ins></h2>\n",
    "\n",
    "**Transforms the feature vector by subtracting the median and then dividing by the interquartile range (75% value — 25% value).** The robust scaler transform is available in the scikit-learn Python machine learning library via the `RobustScaler` class. The `with_centering` argument controls whether the value is centered to zero (median is subtracted) and defaults to True. The `with_scaling` argument controls whether the value is scaled to the IQR (standard deviation set to one) or not and defaults to True. Interestingly, the definition of the scaling range can be specified via the `quantile_range` argument. It takes a tuple of two integers between 0 and 100 and defaults to the percentile values of the IQR, specifically (25, 75). Changing this will change the definition of outliers and the scope of the scaling. \n",
    ">**Note that RobustScaler does not scale the data into a predetermined interval like MinMaxScaler. The range for each feature after `RobustScaler` is applied is larger than it was for MinMaxScaler. Use `RobustScaler` if you want to reduce the effects of outliers, relative to MinMaxScaler.** \n",
    "\n",
    "The histogram plots shown previously confirm the differing scale for each input variable and show that the variables have differing scales. Importantly, we can see some of the distributions show the presence of outliers. The dataset provides a good candidate for using a robust scaler transform to standardize the data in the presence of differing input variable scales and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e9214",
   "metadata": {},
   "source": [
    "<a id=\"iqr\"></a>\n",
    "<h2><ins>IQR Robust Scaler Transform</ins></h2>\n",
    "\n",
    "We can apply the robust scaler to the diabetes dataset directly. We will use the default configuration and scale values to the IQR. First, a RobustScaler instance is defined with default hyperparameters. Once defined, we can call the fit_transform() function and pass it to our dataset to create a robust scale transformed version of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6decdc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform a robust scaler transform of the dataset\n",
    "trans = RobustScaler()\n",
    "data = trans.fit_transform(X)\n",
    "df_robust = pd.DataFrame(data, columns = X.columns)\n",
    "fig = df_robust.hist(xlabelsize=8, ylabelsize=8, figsize=(10,6))\n",
    "[x.title.set_size(8) for x in fig.ravel()]\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88b63e",
   "metadata": {},
   "source": [
    "Histogram plots of the transformed variables show that the distributions don’t look much\n",
    "different from their original distributions. We can see that the center of mass for each distribution is now close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fdd9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'original':X,\n",
    "             'minmax':pd.DataFrame(MinMaxScaler().fit_transform(X),columns=X.columns),\n",
    "             'standard':pd.DataFrame(StandardScaler().fit_transform(X),columns=X.columns),\n",
    "             'robust':pd.DataFrame(RobustScaler().fit_transform(X),columns=X.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfda80b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAHwCAYAAAC7apkrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd1xUx/r48c9sYZfeVRQEewdE7BrRWBOjKcY0k5im6e0mN+2bdpPc5Obml2Ka1zRTTTMxTRNj713sqIiIoNI77MLuzu+PBQTpsCug8369eAnnzJkzi3p4mH3mGSGlRFEURVEURVEUO01LD0BRFEVRFEVRWhMVICuKoiiKoihKJSpAVhRFURRFUZRKVICsKIqiKIqiKJWoAFlRFEVRFEVRKlEBsqIoiqIoiqJUogJk5bwRQswXQjzr6Lb19BMmhJBCCF0D2y8UQrxc9vloIcTh5o6hUt/LhBC3ln0+WwixwYF93ySEWO6o/hRFabuEEJ2FEAVCCG1Lj6Ux1PNXaU0aFDQoiiNIKe92RltnkVKuB3rV104I8QLQXUo5q57+pjhiXEKIMOA4oJdSWsr6/hr42hH9K4rStkkpkwCPlh5Hc6jnr9LS1Ayycl60tZkMRxJ26v+aoijKeaaev0pTqX80SpMJIfoIIdYIIXKEEAeEENMqnVsohPhQCLFUCFEIjK389llZm38KIU4LIU4JIe4sS4XoXun68rfaYoQQyUKIfwgh0squua1SP5cLIXYLIfKEECfLZhQa+hoGCiF2CSHyhRDfAcZK52KEEMmVvn5CCJFS1vawEOJSIcRk4GngurK3NPeUtV0jhHhFCLERKAK6lh27s+rtxbtCiFwhRJwQ4tJKJxKFEOMrff2CEOKrsi/Xlf2ZU3bP4ee+ZSiEGCGE2F7W93YhxIhK59YIIV4SQmwsey3LhRABDf2eKYpy/pU9Ex4XQuwVQhQKIT4RQrQvSx3IF0KsEEL4lrWtklpW1//5Sm1vK3t+Zgsh7hZCDC67V44Q4r1K4+gmhFglhMgUQmQIIb4WQvhUOpclhIgq+7pjWZuYWl6Tev6q52+rpQJkpUmEEHrgN2A50A54APhaCFH5LbEbgVcAT2DDOddPBh4FxgPdgTH13LID4A10Au4A3i//YQAUArcAPsDlwD1CiCsb8BpcgCXAl4Af8ANwTS1tewH3A4OllJ7AJCBRSvkn8G/gOymlh5QyotJlNwNzsL/+EzV0OxRIAAKA54GfhBB+9Y0buKTsT5+ye24+Z6x+wB/APMAfeBP4QwjhX6nZjcBt2P/uXIDHGnBfRVFa1jXABKAncAWwDHuAGID95/mDdVxb3//5oUAP4DrgbeAZ7M/nfsBMIUT5M1oArwIdgT5ACPACgJTyGPAE9p8FbsBnwEIp5ZpzB6Oev+r529qpAFlpqmHYc9xek1KWSClXAb8DN1Rq84uUcqOU0ialNJ1z/UzgMynlASllEfBiPfcrBf4lpSyVUi4FCijLT5NSrpFS7iu7z15gEfUH3OWvQQ+8Xdbvj8D2WtpaAQPQVwihl1Imlv0wqMvCstdnkVKW1nA+rdK9vwMOYw/wm+ty4KiU8suyey8C4rD/QC33mZTyiJSyGPgeiHTAfRVFca53pZSpUsoUYD2wVUq5W0ppBn4GBtZxbX3/51+SUpqklMuxTzosklKmVbrXQAApZbyU8m8ppVlKmY49AKx43kopPwKOAluBIOyBdk3U81c9f1s1FSArTdUROCmltFU6dgL7DG+5k/Vd38C2AJnlCyLKFFG2CEUIMVQIsVoIkS6EyAXuxj4rUJ+OQIqUUlY6VtNMA1LKeOBh7DMlaUKIb4UQHevpv77XVNO96+uzITpS/XWc+3dzptLnFd9LRVFatdRKnxfX8HVd/4/r+z/foL6FEO3Knn8pQog84CuqP28/AvpjD+jNtYxHPX/t1PO3lVIBstJUp4AQUXXxQ2cgpdLXktqdBoIrfR3SjLF8A/wKhEgpvYH52N8GrM9poJMQonLbzrU1llJ+I6UcBYRif23/KT9V2yX13L+me58q+7wQcKt0rkMj+j1VNsbKzv27URRFaYpXsT+DwqWUXsAsKj1vhRAe2FM0PgFeqCNtQT1/lVZNBchKU23F/hD5pxBCX7YI4wrg2wZe/z1wm7Av9HMDnmvGWDyBLCmlSQgxBHt+V0NsBizAg0IInRDiamBITQ2FEL2EEOOEEAbAhH1GxVp2OhUIE41fKd2u7N56IcS12PP5lpadiwWuLzsXDcyodF06YAO61tLvUqCnEOLGstd1HdAXewqMoihKc3hiT3HLEUJ0Ah4/5/w7wE4p5Z3Yc3Hn19KPev4qrZoKkJUmkVKWANOAKUAG8AFwi5QyroHXL8O+iGE1EI/9YQlQ29txdbkX+JcQIh97oP19A8dQAlwNzAaysS9O+amW5gbgNeyv9Qz2h+vTZed+KPszUwixqxHj3op9UUwG9sWMM6SUmWXnngW6lY3rReyz5OXjLiprv1HYV5gPO+d1ZQJTgX8AmcA/galSyoxGjE1RFKUmLwJRQC72ALjimSmEmA5Mxp7mBvaF2FFCiJvO7UQ9f5XWTlRNwVGUliGE6APsBwzn5BoriqIoiqKcV2oGWWkxQoirhBAuZeXa/gP8poJjRVEURVFamgqQlZY0F3s+1zHs+WT3tOxwFEVRFEVRVIqFoiiKoiiKolShZpAVRVEURVEUpRJdSw/AkQICAmRYWFhLD0NRFKVeO3fuzJBSBrb0OM4lhPABPsa+0YMEbj93O93K1HNXUZS2pKHP3gsqQA4LC2PHjh0tPQxFUZR6CSFq3DWsFXgH+FNKOUMI4ULVDROqUc9dRVHakoY+ey+oAFlRFEVpOiGEF3AJ9tq05bVqS1pyTIqiKC1B5SAriqIo5bpiryzzmRBitxDiYyGE+7mNhBBzhBA7hBA70tPTz/8oFUVRnEwFyIqiKEo5HfZd0j6UUg7Evp38k+c2klIukFJGSymjAwNbXRq1oihKs6kAWVEURSmXDCRLKbeWff0j9oBZURTloqICZEVRFAUAKeUZ4KQQolfZoUuBgy04JEVRlBahFukpiqIolT0AfF1WwSIBuK2Fx6MoinLeqQBZURRFqSCljAWiW3ociqIoLUmlWDiRtElyliZgzTO39FAURVGUSnYsPc6+NclYLbaWHoqiKK2QmkF2opLEXArWpVB6upDAOwa09HAURVEUICetiK2/HgfgxIFMpt4X0cIjUhSltVEzyE4kZdknVllnO0VRFOX8SYi1127uPqgdSQeyKCm2tPCIFEVpbVSArCiKolxUEnanE9jZk36jOyJtklPxOS09JEVRWhkVICuKoigXjcIcM6nH8+gaGUiHrt5odIKUw9ktPSxFUVoZp+UgCyE+BaYCaVLK/jWcfxy4qdI4+gCBUsosIUQikA9YAYuUsk2vqJYqw0JRFKVVSDuRB0Bwb190LlqCunqTrAJkRVHO4cwZ5IXA5NpOSin/K6WMlFJGAk8Ba6WUWZWajC0736aDY0VRFKX1yEktBsCnvRsAnXr5kpFcgLmotCWHpShKK+O0AFlKuQ7Iqreh3Q3AImeNRVEURVEAclILcfXUY3TXAxAQ7AESslOLWnhkiqK0Ji2egyyEcMM+07y40mEJLBdC7BRCzKnn+jlCiB1CiB3p6enOHKqiKIrSxuWkFePTzq3i6/KZ5Ny04pYakqIorVCLB8jAFcDGc9IrRkopo4ApwH1CiEtqu1hKuUBKGS2ljA4MDHT2WBVFUZQ2LCe1CO/2ZwNkrwBXhLAfVxRFKdcaAuTrOSe9Qkp5quzPNOBnYEgLjEtRFEW5gJQUWyjKK8GnnWvFMa1Og2eAKzlpKkBWFOWsFg2QhRDewBjgl0rH3IUQnuWfAxOB/S0zQkVRFOVCUR4E+7Z3r3Lcp52rmkFWFKUKZ5Z5WwTEAAFCiGTgeUAPIKWcX9bsKmC5lLKw0qXtgZ+FEOXj+0ZK+aezxqkoiqJcHMoDZO/2rlWO+7Rz43R8LlJKyn72KIpykXNagCylvKEBbRZiLwdX+VgCEOGcUSmKoigXq/KFeN6B5wTI7d0oNVspyivB3dvQEkNTFKWVaQ05yIqiKIridAU5Zlw99ej02irHy6taqDQLRVHKqQD5vFBb6SmKorS0ohwz7j7VZ4i9yxbt5aarUm+KotipANmJVCqboihK61GYW4KbV/UA2d3HAAIKss0tMCpFUVojFSAriqIoF4XCXDPuPi7Vjmt1Gtw8XSjINrXAqBRFaY1UgKwoiqJc8GxWG8V1LMLz8DWoGWRFUSqoAFlRFEW54BXnlyIlNeYgA3j4GSnIUjPIiqLYqQBZURRFueAV5tpnh929q6dYwNkZZCnVompFUVSArCiKolwECnPsAbJbbSkWPkZKzVZKTNbzOSxFUVopFSAriqIoF7zC3BKA2nOQ/ezHVZqFoiigAmRFURTlIlCYawYBbl76Gs97+BoBVepNURQ7p201rSiKorQ9QohEIB+wAhYpZXTLjsgxinLMuHm6oNHWPC/k4Vs2g6xKvSmKggqQzw+15kNRlLZlrJQyo6UH4UiFuSW41bJAD+yL94TaLERRlDIqxcKp1FZ6iqIorUFRXs276JXTaDW4eRtUDrKiKICaQVYUhystLSU5ORmTSf2gbU2MRiPBwcHo9TXnoCoVJLBcCCGB/0kpF7T0gByhuKAEv47udbZx93ahMK/kPI1IUZTWTAXIiuJgycnJeHp6EhYWhhDqXYTWQEpJZmYmycnJdOnSpaWH09qNlFKeEkK0A/4WQsRJKddVbiCEmAPMAejcuXNLjLHRTPmluHrU/cuRu4+BvIzi8zQiRVFaM5VioSgOZjKZ8Pf3V8FxKyKEwN/fX83qN4CU8lTZn2nAz8CQGtoskFJGSymjAwMDz/cQG620xIql1IaxngDZzdtAYY6aQVYURQXIiuIUKjhufdTfSf2EEO5CCM/yz4GJwP6WHVXzFefbg15Xz9oX6YE9xcJUWIq11HY+hqUoSivmtABZCPGpECJNCFHjw1UIESOEyBVCxJZ9PFfp3GQhxGEhRLwQ4klnjVFRFEWpoj2wQQixB9gG/CGl/LOFx9RspoJSAIzu9aRYlG0iUpinKlkoysXOmTnIC4H3gC/qaLNeSjm18gEhhBZ4H5gAJAPbhRC/SikPOmugiqKcf0uWLKFnz5707du3pYeilJFSJgARLT0ORysuC5Drm0EuLwNXlFuCl7+r08elKErr5bQZ5LJFHVlNuHQIEC+lTJBSlgDfAtMdOjhFUbBarS16/yVLlnDwoPq9V3G+8hnkehfplc0gF+WqPGRFudi1dBWL4WVv5Z0CHpNSHgA6AScrtUkGhtbWQVtcTa1cPF787QAHT+U5tM++Hb14/op+dbZJTExk8uTJDB06lN27d9OzZ0+++OIL+vbty+23387y5cu5//778fPz4/nnn8dsNtOtWzc+++wzPDw8WLp0KY8++igBAQFERUWRkJDA77//zgsvvEBSUhIJCQkkJSXx8MMP8+CDDwJw5ZVXcvLkSUwmEw899BBz5swBwMPDg4ceeojff/8dV1dXfvnlF44dO8avv/7K2rVrefnll1m8eDHdunVz6PdJUcqV5yDXv0jPPoNcmKtSLBTlYteSi/R2AaFSygjgXWBJ2fGaVtLUuhddW1tNrSjny+HDh5kzZw579+7Fy8uLDz74ALDXA96wYQPjx4/n5ZdfZsWKFezatYvo6GjefPNNTCYTc+fOZdmyZWzYsIH09PQq/cbFxfHXX3+xbds2XnzxRUpL7bNzn376KTt37mTHjh3MmzePzMxMAAoLCxk2bBh79uzhkksu4aOPPmLEiBFMmzaN//73v8TGxqrgWHEqU0EpQiMwuNY9J+Tqad9NTwXIiqK02AyylDKv0udLhRAfCCECsM8Yh1RqGox9hrntUYvmL3r1zfQ6U0hICCNHjgRg1qxZzJs3D4DrrrsOgC1btnDw4MGKNiUlJQwfPpy4uDi6du1aUS/4hhtuYMGCs3tFXH755RgMBgwGA+3atSM1NZXg4GDmzZvHzz//DMDJkyc5evQo/v7+uLi4MHWqfanBoEGD+Pvvv8/PN0BRyhQXlGL00CM0dT+UNRqBm5cLhSrFQlEuei0WIAshOgCpUkophBiCfTY7E8gBegghugApwPXAjS01TkVpq84ta1b+tbu7fTcxKSUTJkxg0aJFVdrt3r27zn4NhrPb9Wq1WiwWC2vWrGHFihVs3rwZNzc3YmJiKmoO6/X6inuXt1eU88lUUP8mIeXcvA0UqRlkRbnoObPM2yJgM9BLCJEshLhDCHG3EOLusiYzgP1lOcjzgOulnQW4H/gLOAR8X5abrChKIyQlJbF582YAFi1axKhRo6qcHzZsGBs3biQ+Ph6AoqIijhw5Qu/evUlISCAxMRGA7777rt575ebm4uvri5ubG3FxcWzZsqXeazw9PcnPz2/kq1KUxisuKGlwgOzuY1AzyIqiOLWKxQ1SyiAppV5KGSyl/ERKOV9KOb/s/HtSyn5Syggp5TAp5aZK1y6VUvaUUnaTUr7irDE6Xa2Z04rifH369OHzzz8nPDycrKws7rnnnirnAwMDWbhwITfccAPh4eEMGzaMuLg4XF1d+eCDD5g8eTKjRo2iffv2eHt713mvyZMnY7FYCA8P59lnn2XYsGH1ju/666/nv//9LwMHDuTYsWPNeq2KUhdTWYpFQ7h5u6gZZEVRWryKhaIoTqLRaJg/f36VY+WzwuXGjRvH9u3bq107duxY4uLikFJy3333ER0dDcALL7xQpd3+/Wf3AVq2bFmN4ygoKKj4fMaMGcyYMQOAkSNHqjJvynlRnF+Kq0fdNZDLuXu5UJxfitVqQ6tVm80qysVK/e93JrVIT2mjPvroIyIjI+nXrx+5ubnMnTu3pYekKE1is0lMRQ2fQXb3UbWQFUVRM8iKckEKCwurMrvbWI888giPPPKIA0ekKC2jpMgCsv5tpsu5VdosxNPP6MyhKYrSiqkZZEVRFOWCZSqy1+k2ujdsPshdbRaiKAoqQFYURVEuYOZCe1lBQwNnkM9uN60CZEW5mKkA+XxQ1SwURVFahLlsBtng1rAA2dVTDwJV6k1RLnIqQHYmtUhPURSlRTU2xUKj1eDm6aJSLBTlIqcCZEVRFOWCVZFi0cAZZCivhaxmkBXlYqYCZEW5iMyePZsff/yxpYehKOfN2RSLhhdtsu+mp2aQFeVipsq8OZPKPVaWPQln9jm2zw4DYMprju1TUS5QpiILOoMWra7h80HuXi6knVDboCvKxUzNICvKBeqll16id+/eTJgwgRtuuIE33nijyvmwsDAyMjIA2LFjBzExMYB957vbbruNAQMGEB4ezuLFiwFYtGgRAwYMoH///jzxxBMAWK1WZs+eTf/+/RkwYABvvfUWAMeOHWPy5MkMGjSI0aNHExcXV+s4U1NTueqqq4iIiCAiIoJNm+y7zr/55pv079+f/v378/bbbwP2nQD79OnDXXfdRb9+/Zg4cSLFxcUAxMfHM378eCIiIoiKilLbVysAmAtLMTZi9hjstZCL80uwWW1OGpWiKK2dmkF2JrVIT2mhmd4dO3awePFidu/ejcViISoqikGDBjXo2pdeeglvb2/27bPPfGdnZ3Pq1CmeeOIJdu7cia+vLxMnTmTJkiWEhISQkpJSsSlJTk4OAHPmzGH+/Pn06NGDrVu3cu+997Jq1aoa7/fggw8yZswYfv75Z6xWKwUFBezcuZPPPvuMrVu3IqVk6NChjBkzBl9fX44ePcqiRYv46KOPmDlzJosXL2bWrFncdNNNPPnkk1x11VWYTCZsNhXcKGAusjQq/xjKdtOTUJRXioevocY2NpMFjVH9CFWUC5X6360oF6ANGzYwffp0XF1dAbjiiisafO2KFSv49ttvK7729fVl3bp1xMTEEBgYCMBNN93EunXrePbZZ0lISOCBBx7g8ssvZ+LEiRQUFLBp0yauvfbaij7M5trzOVetWsUXX3wBgFarxdvbmw0bNnDVVVfh7u4OwNVXX8369euZNm0aXbp0ITIyEoBBgwaRmJhIfn4+KSkpXHXVVQAYjWoHNMXOVFja4AoW5dy87JuFFOWZqwXIJSfzyVwUhzXLhLGvP37X90LjonXYeBVFaR1UioWiXICkrD8BXqfTVcyymkymKtcKUfXtj9r68/X1Zc+ePcTExPD+++9z5513YrPZ8PHxITY2tuLj0KFDDhu/wXA2YNFqtVgslga9XuXi1OQZZKrXQraZLGQuigOrxGNER0yHMsn6+pD696coFyAVICvKBWjUqFH89ttvmEwmCgoK+OOPP6q1CQsLY+fOnQAVecYAEydO5L333qv4Ojs7m6FDh7J27VoyMjKwWq0sWrSIMWPGkJGRgc1m45prruGll15i165deHl50aVLF3744QfAHuzu2bOn1rFeeumlfPjhh4A9pzkvL49LLrmEJUuWUFRURGFhIT///DOjR4+utQ8vLy+Cg4NZsmQJYJ+xLioqavg3TLlgmQtLMTRyBrliu+mcqu985C0/gTXHhN+NvfGZ1g3vy7pgOpyN+Ui2w8arKErroAJkRbkADR48mGnTphEREcHVV19NdHQ03t7eVdo8//zzPPTQQ4wePRqt9uxbxP/3f/9HdnY2/fv3JyIigtWrVxMUFMSrr77K2LFjKxbBTZ8+nZSUFGJiYoiMjGT27Nm8+uqrAHz99dd88sknRERE0K9fP3755Zdax/rOO++wevVqBgwYwKBBgzhw4ABRUVHMnj2bIUOGMHToUO68804GDhxY52v+8ssvmTdvHuHh4YwYMYIzZ8404zuoXCiaMoPs6uUCoup207YSK4W7UnELD8QQ6gWAx/COaP2N5Cw9jrSpWWRFuZCIC+mtoejoaLljx46WHkYFc2Iu6fP34hLqRbt7Ilp6OMp5cujQIfr06dPSw6CgoAAPDw+Kioq45JJLWLBgAVFRUS09rBbVWv5uAIQQO6WU0S09juZqbc/dyiylVv73wFqGXdmVQZPDGnXtp4+vp0tEIGNn9QagcGcq2T8cIXDOAAxdfSraFe5KJfv7IwTcNQBjN5+aO1MUpdVo6LNXzSArygVqzpw5REZGEhUVxTXXXHPRB8fKxcdc1Phd9Mq5eRuqzCAX7khF52/EpUvVd2LcBgQgjFqKdqQ2b7CKorQqTqtiIYT4FJgKpEkp+9dw/ibgibIvC4B7pJR7ys4lAvmAFbBcCLMsinK+ffPNNy09hCpeeeWVirzkctdeey3PPPNMC41IqY0QQgvsAFKklFNbejxNZSps/C565dy9DRWL9GxFpZQk5uI5NqTaAlah1+IW2Y7CHan4TO+mSr8pygXCmf+TFwLvAV/Ucv44MEZKmS2EmAIsAIZWOj9WSpnhxPEpinIePfPMMyoYbjseAg4BXi09kOYwF9pnkI1NmEF293YhI9m+m545IRckGHv41tx2UHsKt5ymeH8G7tEdmj5gRVFaDaelWEgp1wFZdZzfJKUsX/q7BQh21lgURVGUhhFCBAOXAx+39Fiay1xUNoPcyCoWAG7eLhTnlWCzSUzxOQgXLS6dPWtsqw/2QOttoPhgrT/yFEVpY1pLDvIdwLJKX0tguRBipxBiTl0XCiHmCCF2CCF2pKenO3WQiqIoF4G3gX8CtW5F2Faeu6bCpucgu3sbkBKK80swx+dg6OqN0Nb8I1MIgbGvH+aj2dhKrM0as6IorUOLB8hCiLHYA+QnKh0eKaWMAqYA9wkhLqnteinlAilltJQyunyXL0VRFKXxhBDl60Z21tWurTx3y2eQG7uTHtgDZIDC5AIsGcUYuvvU2d61rz+y1IY5PqfR91IUpfVp0QBZCBGO/W286VLKzPLjUspTZX+mAT8DQ1pmhIrSNiUmJtK/f7W1scTExOCIklwLFy7k/vvvb3Y/SqszEphWtlD6W2CcEOKrlh1S05mLLCDApQkL59x87JuFFB/PBcAQVnc6tqGLN8KgxXRIpVkoyoWgxQJkIURn4CfgZinlkUrH3YUQnuWfAxOB/S0zSge5gGpNK4qjWCyWlh6Ccg4p5VNSymApZRhwPbBKSjmrhYfVZObCUgxuOoRG1N/4HOUzyJZTBaAV6Du419le6DQYuvlgOpbTlKEqitLKOLPM2yIgBggQQiQDzwN6ACnlfOA5wB/4oKxsTnk5t/bAz2XHdMA3Uso/nTVOpxKNfygrF5b/bPsPcVlxDu2zt19vnhjyRL3tLBYLt956K7t376Znz5588UXVgjKLFi3i3//+N1JKLr/8cv7zn//Uefyzzz7j1VdfJSgoiJ49e2IwGGq99+zZszEajRw4cIDU1FTefPNNpk6dysKFC/njjz8wmUwUFhby22+/8cADD7Bv3z4sFgsvvPAC06dP58CBA9x2222UlJRgs9lYvHgxHTt2ZObMmSQnJ2O1Wnn22We57rrrmvGdVC50pibsolfOzcs+g0ymCX2QO0JX/3ySoZs3poOZWLJM6PyMTbqvoiitg9MCZCnlDfWcvxO4s4bjCYDadk5Rmunw4cN88sknjBw5kttvv50PPvig4typU6d44okn2LlzJ76+vkycOJElS5YwZMiQGo8PHTqU559/np07d+Lt7c3YsWPr3fo5MTGRtWvXcuzYMcaOHUt8fDwAmzdvZu/evfj5+fH0008zbtw4Pv30U3JychgyZAjjx49n/vz5PPTQQ9x0002UlJRgtVpZunQpHTt25I8//gAgNzfXed88BSnlGmBNCw+jWcxFpRibUAMZQKvTYPTQo88vwaWPX4OuMXb3IRcwH8tB56fKvSlKW6YqmiuKEzVkptdZQkJCGDlyJACzZs1i3rx5Fee2b99OTEwM5QusbrrpJtatW4cQosbjQJXj1113HUeOHKEuM2fORKPR0KNHD7p27UpcnH0mfcKECfj52QOO5cuX8+uvv/LGG28AYDKZSEpKYvjw4bzyyiskJydz9dVX06NHDwYMGMBjjz3GE088wdSpUxk9erSjvlXKBcpUaMHg3rQZZIAATz2a4lJcgmsu73YuXTs3NJ56TPE5uA9WAbKitGUtXsVCURTnqLbjV6WvZS158bUdr6m/pt7f3f1sLqeUksWLFxMbG0tsbCxJSUn06dOHG2+8kV9//RVXV1cmTZrEqlWr6NmzJzt37mTAgAE89dRT/Otf/2rUeJSLT3NmkAH8DVoAXEI8GtReCIGhmw/mYzl1/l9SFKX1UwGyolygkpKS2Lx5M2DPKx41alTFuaFDh7J27VoyMjKwWq0sWrSIMWPG1Hl8zZo1ZGZmUlpaWm3L6Jr88MMP2Gw2jh07RkJCAr169arWZtKkSbz77rsVwcTu3bsBSEhIoGvXrjz44INMmzaNvXv3curUKdzc3Jg1axaPPfYYu3btcsS3SbmAmQubnoMM4KUBK6ALcGvwNcZuPtgKSrGkFjX5vheb7DOn2PDtF/z8nxf5e8F7ZCQltvSQFEWlWCjKhapPnz58/vnnzJ07lx49enDPPffw22+/ARAUFMSrr77K2LFjkVJy2WWXMX36dIBaj7/wwgsMHz6coKAgoqKisFrr3hChV69ejBkzhtTUVObPn4/RWH3R0rPPPsvDDz9MeHg4UkrCwsL4/fff+e677/jqq6/Q6/V06NCB5557ju3bt/P444+j0WjQ6/V8+OGHDv6OKRcSaZOYi0qbtIteOVerpMAqoRFvnpTXSzYdy6m38sXFTkrJrqW/sn7RQmwWK/7BISQf2s++VcuJufUuoqZc0dJDVC5i4kJ6Gyg6Olo6osaro5hP5JH+4R5cOnvS7t7Ilh6Ocp4cOnSIPn36tPQwWtTs2bOZOnUqM2bMaOmhVNGa/m6EEDvLKve0aa3tuVvOXGzh40fWMeKa7gyc0LlJfSQ9v4mU/FIiXhh+tqpFA5x+fTv69m4E3NqvSfe9GEgpWfvlJ+z8Ywndoocy/o578fDzp7ggn78+fIdjO7Zw2QOP0WdUTEsPVbnANPTZq2aQFUVRlAuOubDpu+gB2IpK0Zit5FklhbnmRgXIxu4+FO1JR1olQqvKfdZk0w/fsPOPJQyccgVjb7kLobFnfLp6eDL14Sf48eX/Y8XH7xPSdwAefv6N7t9sNbM0YSmx6bGYrWYiAiOY2nUqni4NW3CpKCpAVhSlyV555ZVq+cjXXnstCxcubJkBKUoZc5F9I5qm5iCXptlziPOskqLcEghp+LWGbj4UbjtD6akCXEJUQHauQ+tXs2XxIvqPncDYW+dUW9Cr0+uZdM9DfP7Yfaz54mOmPty4akC703bz+NrHSS1Kxc/oh06j44+EP1iwdwEvjniRS4IvceTLUS5QKkBWFKXJnnnmGZ555pmWHoaiVGMqat4McukZe4CcXzaD3BiGrt4AmBNyVYB8joykRJZ/9B7Bffsz/s77aq2O49uhI4OnXcOWxd8y9OrrCOwc1qD+V5xYwePrHqeje0c+mvgRQzsMRQjBvvR9/GvLv3hw1YO8OvpVpnSZ4sBXpVyIVBULRVEU5YJjLmzmDHJqIcKgpVhCUSMDZK2nC7pAV8zH1WY2lVlKSvj9nddxMbpy+YP/RKur+5eXqMumozcY2f7r4gb1v+PMDv657p/08+/HoqmLGBY0rCIAHxA4gIWTFzKw3UCeXv80sWmxzX05ygVOBciKoijKBcdcNoPc1ADZklqEvr0bBncdhbkljb7e0MUb8/FcpO3CWQjfXBu//4rM5CQm3/sIHr71707o6uFJ+PhJxG1cS15GWp1tM4szeWztYwR7BvP+pe/j5eJVrY273p154+bRwb0Dj619jBxTTlNfinIRaFCALIRYLIS4XAihAmpFUZQ24mJ+dpvKFuk1tcxbaUYxukA33L0NFOY0bgYZ7GkW0myl9FRBk+5/oUmOO8CO338mfPxkukQOavB1AydPQ9psHFizstY2Ukpe2PQC+SX5vDHmDbwN3rW29XTx5I2YN8gszuTtXW835iUoF5mGPjQ/BG4EjgohXhNC9HbimBRFURTHuGif3eYiC1qdBp2+8b8b2MwWbHkl6AJc8fA1UJDdtAAZUGkWQKnJxJ8fvIV3YDvGzLq9Udd6t2tP5/4RHFi7Ammz1dhmZdJK1iSv4cGoB+np27PePvv59+OmPjfx09Gf2Ju+t1HjUS4eDXpySClXSClvAqKAROBvIcQmIcRtQoimb1OkKIrD5eTk8MEHH9R6fsSIEU4fQ2xsLEuXLq34+oUXXuCNN95o0nhiYmJojXV224KL+dltLizF4KZr9BbpAJYMEwC6AFc8/V3JyyxudB9aLwO6AFfMCSpA3rx4EbmpZ5h8zyO4uDZ8V8Jy/cdOIDctlZMH91U7V2wp5vXtr9PTtyc39bmpwX3eE3kPAa4B/L8d/09tC67UqMG/Wgsh/IHZwJ3AbuAd7A/dv50yMkVRmqS2ALl857tNmzY5fQznBsh1OR/juZhdrM9uc5EFg3sT84/T7RUs9IGuePkbMRdaKDFZGt2PPQ8576LOQ85ISmTnH0voP3YCwX37N6mP7kOG4+LqStzGtdXOfX3oa04XnuapIU+h0zQ8ncZd787c8LnsStvF5lObmzQu5cLWoH9NQoifgN7Al8AVUsrTZae+E0KoqR1FqcWZf/8b86E4h/Zp6NObDk8/Xev5J598kmPHjhEZGYler8fDw4OgoCBiY2M5ePAgHh4eFBTY8yJff/11vvzySzQaDVOmTOG1117j2LFj3HfffaSnp+Pm5sZHH31E7969mT17NkajkQMHDpCamsqbb77J1KlTq92/pKSE5557juLiYjZs2MBTTz0FwMGDB4mJiSEpKYmHH36YBx98EKDe8ZSz2WzcdttthISE8PLLLzvs+3khu5if3aYiC0a3puUfWzKKQYDO34inn32L9PxME/6dPBrVj6GrN4Xbz1B6phCXjo279kIgbTZWfPIBLm7ujL5xdpP70bsY6DZoKEe3bebSO+6tqH6RV5LHp/s/5ZLgS4ju0PhNKa/qcRWf7P+E92PfZ3jH4U16t0G5cDX06fGxlLLKdJAQwiClNF8IW6UqyoXktddeY//+/cTGxrJmzRouv/xy9u/fT5cuXaq0W7ZsGUuWLGHr1q24ubmRlZUFwJw5c5g/fz49evRg69at3HvvvaxatQqAxMRE1q5dy7Fjxxg7dizx8fEYjcYq/bq4uPCvf/2LHTt28N577wH2FIu4uDhWr15Nfn4+vXr14p577kGv19c7HgCLxcJNN91E//79Vd3lxrlon93molI8fI31N6xBaXoxWh8DQq/F07/pAbJL5XrIF2GAvH/tClLiDjLx7gdx86p94VxD9Bw2ikMb1nDywF7CIqIA+OrgV+SX5HN/5P1N6tNF68Id/e/g5a0vsyttF4PaN3zxoHLha2iA/DJw7vulm7G/TacoSi3qmuk9X4YMGVItOAZYsWIFt912G25u9pxAPz8/CgoK2LRpE9dee21FO7P57AKlmTNnotFo6NGjB127diUuLo7IyMgGjePyyy/HYDBgMBho164dqampBAcH1zmecnPnzmXmzJkqOG68i/bZbS604N+p6TPIugBXgLMBcpap0f3ovA1o/YyYE3LxHNWpSWNpq4rz81j39UI69upL/zHjm91fWEQULq6uHNmygbCIKIpKi/gm7htiQmLo49+nyf1O6z6N92Lf44sDX6gAWamizhxkIUQHIcQgwFUIMVAIEVX2EQPUmWkvhPhUCJEmhNhfy3khhJgnhIgXQuwVQkRVOjdZCHG47NyTjX9ZrczFm36mtALu7u41HpdSVntL0Waz4ePjQ2xsbMXHoUOHKs6f274xb0kaDIaKz7VaLRZL1ZzOmsZTbsSIEaxevRqTqfFBysWoOc/uC4WpyL5Ir7GklFjSzwbIbp4uaHUa8jKb9m/P0NWbksSLrx7yuq8XYi4sYPyd9yI0za8yqHNxISwymoTdO5A2Gz/H/0yuOZc7+t/RrH5dda7M7DWT1SdXczLvZLPHqVw46vtXOwl4AwgG3gT+X9nHo0B9U2MLgcl1nJ8C9Cj7mIO9HBFCCC3wftn5vsANQoi+9dyrdVLpTEoL8PT0JD8/v952EydO5NNPP6WoyL4gKSsrCy8vL7p06cIPP/wA2IOFPXv2VFzzww8/YLPZOHbsGAkJCfTq1atZY6hvPOXuuOMOLrvsMq699tpqgbVSo+Y8u9s8q9VGqcmKsQmL9GyFpcgSKzp/e4AsNAJPfyP5TahkAfaFerYiC6WpRU26vi1KTYhn/+rlRF02vcFbRDdE14HRFGZncTrhKF8e/JKB7QYS2S6y2f1e1+s6hBD8FP9T8wepXDDqDJCllJ9LKccCs6WUYyt9TJNS1vkvSUq5Dsiqo8l04AtptwXwEUIEAUOAeCllgpSyBPi2rK2iKA3g7+/PyJEj6d+/P48//nit7SZPnsy0adOIjo4mMjKyogzb119/zSeffEJERAT9+vXjl19+qbimV69ejBkzhilTpjB//vxq+cflxo4dy8GDB4mMjOS7775r0LhrG0+5Rx99lKioKG6++WZstdRDVeya8+y+EJQUlW8z3fgZZEtZKoXO7+y/bU8/A/nNmEEGKEnIadL1bY2UktWfL8DVy5vh19zg0L67DIwGIVi79idSClIaVdatLu3c2nFJp0v4Jf4XLDb1C7hiV+fTQwgxS0r5FRAmhHj03PNSyjebce9OQOX3M5LLjtV0fGgz7qMoF51vvvmm1nPlFSPAXvHiySerZjF16dKFP//8s8ZrR44cyVtvvVXv/f38/Ni+fXut5/fvP5t5Vd941qxZU/H5iy++WO+9Fac/u1s9c0WA3PgZZGt2DQGyvysZyelNGovO14jW14A5IRePkRd+HvLRrRtJiTvI+Dvvw+Dm2GweNy9vgrr1JGH3dgIvCWRc53EO6/vqHlezJnkNG1I2EBMS47B+lbarvhSL8uRFD8Czho/mqCkBQdZxvOZOhJgjhNghhNiRnt60B5jTXFwpZ4qitB7OfHa3ehXbTDdpBtm+KFVbqQKGV4CR4vxSSoqbNrto6OqD+fiFn4dsKSlh7VefEdA5jAHjJjrlHv79emJIN3NNpyvQaxy3183o4NEEuAaw+Ohih/WptG11Pj2klP8r+9MZ0zbJQEilr4OBU4BLLcdrG+MCYAFAdHT0hf30UZQWtHDhwmrH/vrrL5544okqx7p06cLPP/98nkal1MTJz+5Wr3wGuSk5yNYsExp3PRqDtuKYT3v7TGhOWhHtQr0a3aehmzdFO1MpPV2ISyNLxbUlu5b9Sl56KjOeeRmNVlv/BU0Q75eNQDCwsLND+9VpdEzvNp2FBxaSVpRGO7d2Du1faXsatLRUCPG6EMJLCKEXQqwUQmQIIWY1896/AreUVbMYBuSWFbHfDvQQQnQRQrgA15e1bXvUIj3lAjdp0qQqFS9iY2NVcNyKOOnZ3eo1awY521QlvQIqBchNXGhn7OFrH9eR7CZd3xYU5mSz9efv6DpoCKHhkU65h5SS3wvWUuqmIfPAUYf3f1WPq7BKK78ea5shh+JYDa29MlFKmQdMxT7z2xOoffUPIIRYhL3eZi8hRLIQ4g4hxN1CiLvLmiwFEoB44CPgXgAppQW4H/gLOAR8L6U80LiXpSiKotDIZ7cQwiiE2CaE2COEOCCEaJMz0M2ZQbZkmdCeEyB7B7qCaHqArPV0QR/kfkEHyJt//AZLSQljZjWv7FpdYtNjSS5Mxr9vDxL37MLq4Io2oV6hRLePZkn8EqRUb0hf7Br663X5U+YyYJGUMqu++qdSyjqXr0r7v777ajm3lOrF7RVFUZTGaeyz2wyMk1IWCCH0wAYhxLKySkNthrnIPoPs0sgZZGmVWHNM6MIDAXtd8CNHjpCWlgYBmaSfavpucMaevuSvT8FmtqAxNG0Dk9YqJ/UM+1YtZ8Clk/Hr6LyFiL8e+xVXnSvDR17BXzve4NSRQ4T0HeDQe1zR7Qqe3/Q8BzMP0i+gn0P7VtqWhs4g/yaEiAOigZVCiEBAVexXFEVp3Rr17C4ru1leVkRf9tHmptLMhRb0Bi1abeM2qLDmmsEGWj8DWVlZfPrpp3z77besWrWKdO0Bdpxeyq5du5o0u2jo6Qs2iflYbqOvbe22LF6ERqNl2FUznXYPs9XMX8f/Ynzn8fSIHIzQaEjcs8vh97m086XoNDqWHV/m8L6VtqVBTw8p5ZPAcCBaSlkKFKJqEzdYm/vpoijKBaEpz24hhFYIEQukAX9LKbfW0Kb1Vg/CPoNscG9a/jFAiZvkiy++ICMjg6uuuoqnnnqKwWGT0Zd68uuvv7Jq1apG920I9ULoNZiOXlhpFpnJJzm4bjURky7Hw8/fafdZc3IN+aX5XNHtCgxu7nTs2dspAbK3wZtRHUfxZ+Kf2KSqt34xa8yv132A64QQtwAzAOfUcLkQqVwm5SI3f/58vvjii5YexsWqUc9uKaVVShmJvYLQECFE/xraLJBSRkspowMDA50x5mYxFVmaVgM5y4RE8suWPykoKGDWrFlERERgMBjoHBaMV+YAwvtHsH79erZurfZ7Q52EToOhmw/mCywPedOP36AzGBgyfYZT7/Pbsd9o59aOIR2GABAWHkXa8WMU5eY4/F5TukwhtSiVXamOD8CVtqOhVSy+xL5t6ShgcNlHtBPHdUGoL09bUVobZ23jfPfdd3PLLbc4pW+lds15dkspc4A1wGQnDc9pzEWlGJsyg5xlIl57hhPJSUyZMoXg4OCKcz4d3BAIBvUdTa9evfjrr79ISUlpVP/GHj5YMk1YmrhtdWuTmXySI5vXEzVlGm5eTc/Prk9+ST4bT21kStgUtBp7+biwiCgATuzd7fD7xYTE4KpzVWkWF7mGPkGigb5SLetUlEZZ//0RMk4W1N+wEQJCPBg9s2edbQoLC5k5cybJyclYrVaeffZZunfvzqOPPkpBQQEBAQEsXLiQoKAgYmJiGDFiBBs3bmTatGns27ePqVOnMmOGfUbIw8ODgoIC1qxZw/PPP0/79u2JjY3l6quvZsCAAbzzzjsUFxezZMkSunXrVuN4XnjhBTw8PHjssceIiYlh6NChrF69mpycHD755BNGjx7NgQMHuO222ygpKcFms7F48WJ69Ojh0O/dRahRz+6yHOVSKWWOEMIVGA/8x5kDdAZToQXfDo3fxa04s4Ad+gQ6duzIwIEDq5wLKKtfnJVSxJVXXsmHH37I4sWLufvuu3FxcWlQ/4aeZeXejmbj4e/a6PG1NjuXLkGndyHqsmlOvc+65HVYbBbGh46vONa+a3dcPb1I3LOLPqPHOvR+bno3YoJjWH5iOU8OfdKhG5IobUdDUyz2Ax2cORBFURznzz//pGPHjuzZs4f9+/czefJkHnjgAX788Ud27tzJ7bffzjPPPFPRPicnh7Vr1/KPf/yjzn737NnDO++8w759+/jyyy85cuQI27Zt48477+Tdd99t8PgsFgvbtm3j7bffrtg+ev78+Tz00EPExsayY8eOKrN3SpM19tkdBKwWQuzFXpP+bynl704ZmROZi0oxNqEG8r5TcRRiYtKkSWg0VX88unq64O5jIONkPq6urlx55ZVkZWWxYcOGBvevC3BF62fEdCir0WNrbYpyczi4bhV9x4xz6uwxwIoTK2jn2o7wwPCKY0KjITR8IIl7dyNtjs8VntJlCjnmHLacalMFXBQHaugTJAA4KITYhr0MEABSSuf+2qgobVx9M73OMmDAAB577DGeeOIJpk6diq+vL/v372fChAkAWK1WgoKCKtpfd911Dep38ODBFdd169aNiRMnVtxv9erVDR7f1VdfDcCgQYNITEwEYPjw4bzyyiskJydz9dVXq9ljx2jUs1tKuRcYWNO5tsRc2PgcZJvNxt6CY3R0CyQ0NLTGNoEhHqSXvSPUtWtXBgwYwMaNG4mIiMDfv/4FakIIXPv6U7D5FDaTBY2x7ZZ7i12+FGtpKVGXOXe9frGlmA0pG7iy+5VoRNVfWsIioojbuJb0pETahXV16H1HdhqJp96T5SeWMzp4tEP7VtqGhv7vfMGZg7jgqcQU5Tzr2bMnO3fuZOnSpTz11FNMmDCBfv36sXnz5hrbu7u7V3yu0+mwlc3ISCkpKSmpOGcwGCo+12g0FV9rNJpG5S+XX6fVaiuuu/HGGxk6dCh//PEHkyZN4uOPP2bcuHEN7lOp0QstPYDzzVJixWqx1VnFQpaWUpqahj6oA6JsS+TDB+PIp5gxocNqvS4gxJMT+zMpLbGid9EyceJEDh8+zIoVKxr8S6ZrP38KNqRgOpKNW3jrW+DYEKUlZmKX/0HXqMH4dwpx6r02pWzCZDVVSa8oFxpu/10ucc8uhwfILloXxoSMYfXJ1ZTaSlWaxUWooWXe1gKJgL7s8+2AWt5ZH7VGT2khp06dws3NjVmzZvHYY4+xdetW0tPTKwLk0tJSDhyoeYPKsLAwdu7cCcAvv/xCaWnpeRlzQkICXbt25cEHH2TatGns3bv3vNz3QnYxPrvLd9GrbQbZZjJxfOZ1HBs/nviYsZQk2xfabd+6DXdpoHePXrX2HdjZEykhM8U+i+zp6cnw4cM5dOgQp06datD4XEK90LjrKT6Q2ZiX1aocWr+G4rxcBl1+ldPvtSJpBd4Gbwa1H1TtnIevH4Gdw5xS7g1gfOh4cs25bD+z3Sn9K61bQ6tY3AX8CPyv7FAnYImTxqQoSjPt27ePIUOGEBkZySuvvMK//vUvfvzxR5544gkiIiKIjIxk06ZNNV571113sXbtWoYMGcLWrVurzC4703fffUf//v2JjIwkLi5OVb1wgIvx2W0qtP9CZ6glBzn1lVcwHzpEwH33YS0sJPXll8nPz+d48gl6WIPQ+9e+uC8gxL5QLyMpv+LY8OHDMRqNDU4xEhp7moXpUBa2EmtDX1arsnfFMgJCQgnp59hd7M5Vai1l7cm1jA0Zi05T899naEQUKXEHKTE5vjLIyI4jcdW5suLECof3rbR+DU2xuA8YAmwFkFIeFUK0c9qoLjSq+Idynk2aNIlJkyZVO75u3bpqx9asWVPl6/bt27Nly9mFKa+++ioAMTExxMTE1HjduefO9cILL9R4XUBAQEUO8lNPPcVTTz1Vax9Kk1x0z+7yGWSje/UZ5JITJ8j54Uf8bruNwAfuR+PuTtrrr5OwZAlSSrpZO6DzM9bat6efEVdPPWcS8ug/xn7MaDQycuRIVq5cSVJSEp07d653jK4RARRuP4PpcBZuA9pWmkVaYgKpCfGMvfUup5cy3XpmK/ml+UwInXD2YGkx5J8BnRE82hEWEcWO337i5IF9dBs0xKH3N+qMXBJ8CSuTVvLM0GcqSswpF4eGVrEwSykrEhGFEDpUZm39yh8e6julKErLuOie3XXNIOf+8isIgd/sWwHwu+VmdIGB7I+LI9DVFz+dJxqP2nNNhRB07OFLypHsKttNDx06FHd39wbvsGfo6oPGQ09xbOvbhbA++9f8jVanc3hptZqsObkGV50rQwMiYMt8WBADr3SAeZHwZm94LZROu19Gp9eRGLvDKWMYHzqeLFMWu9Iu6MwkpQYNDZDXCiGeBlyFEBOAH4DfnDcsRVHaoldeeYXIyMgqH6+88kpLD+tidtE9u2ubQZY2G7m//IL78OHo27cHQOh0MGkS6Xo93Q2d0Poa650VDe7lQ0G2mdz0s2/pu7i4MHr0aBITEyveEamL0AjcwgMpPpyFrdg5m/M4g9ViIW7DWroNGoqrp5dT7yWlZEPKBoZ698Tw4Uj48wlAwJgnYfoHcPn/g/CZ6DIPE+KSxol1v8Ce78Dm2LSVSzpdgkFrUGkWF6GGBshPAunAPmAusBT4P2cNSlGUtumZZ54hNja2ykflesvKeXfRPbvNRTXPIBfHxlKakoL39KoV7lL79AYgJNe1zvSKcp162Tf7SDlcdcvoQYMG4ebmxsaNGxs0TreB7cAiKdrbdmaRk/bvoTg/77zMHh/PPU5KQQqjD68BrQvc8ivMWQ1jn4KBN8HgO2Hqm/DQHsLGXEm2SU/udw/AgjFw2nELfN30bozsOJIVJ1Zgk46vt6y0Xg2tYmHDvrDjXinlDCnlR2pXvQZQVSwURWlBF+Oz21xkQQhwOafGcOGGjaDR4HFO6cDjRUV4FhXhWdSwANmnvRtu3i4knxMg6/V6hgwZwtGjR0lLS6u3H32wB/oObhRuP9OAV9U6xG1ci8HdnbDI6hUlHG395tcBGN1hCMxdC13H1NxQoyFswo0AJPZ6CArS4KOxsPZ1sDqmAs+EsAmkFaexN11V1rmY1BkgC7sXhBAZQBxwWAiRLoR47vwM7wJxQf84UhSltbmYn92mwlJc3HQITdUZisJtWzH27YvW07PimNlsJjExkS6u7gihR+tT95bRUkosNknnvn4k7c/EUlr17fwhQ4ag1+trrRBTmRACt+gOlCYXUHqmsBGvsGVYSkqI376ZHkNGoNM7uSbwwV9Zf2Il3YWBoOu+BYNnnc19gzrhFdiOxHQJ926BflfB6lfg8yvsC/qaaUzwGHQanUqzuMjUN4P8MDASGCyl9JdS+gFDgZFCiEecPThFURSlSR7mIn12m4ssGM+pgWwrLsa0Zy9uQ6tWOTh27BhWq5Xune1pFrbCjGr9lVhsfLbxOJfPW0+PZ5bR6/+W8UlSGiUmK/u2VQ2+3NzcGDhwIHv37iUvL6/esboNbAc6QcGW0419medd0v49lBQX03PYKOfeKC2Owp/nstNoZHTva0FX9y8tYP9lIyw8iqT9e7C6eME1H8PVH8PpPfC/SyCpedtFe7p4MjxoOH+f+JsL/A0YpZL6AuRbgBuklMfLD0gpE4BZZeeUBlH/oZTzKzExkf79+zfp2lOnTjFjxgwHj0g5zy7aZ7e5qLR6/vGePcjSUtyHVA2Q4+PjMRgMhHaz78hWknioyvmE9AKufH8jL/52EK1GcOfortwb0x1tkJFCIfnq+0N8szWpStA0fPhwpJRs3bq13rFq3fW4RbajaGcqtqLzsyFPUx3dthkXVzc69w933k1KTfDj7Wzx8MQiYHTnhu+kGRYRRUlxMaePxtkPhF8Ld64AF3dYeDns/b5ZQ5sQOoFThac4mHWwWf0obUd9AbJeSlntV2opZTpQ73ssQojJQojDQoh4IcSTNZx/XAgRW/axXwhhFUL4lZ1LFELsKzvnnPotzla2Glr9wqm0JR07duTHH39s6WEozdOsZ3dbZiq0YDingkXRtm2g0eA6qGrubEJCAmFhYQhc7dfuPTvTGJ9WwHULtnAmz8SCmwfx6/2jeHJKbx6b1Isv7xxG32EdCCvR8PLifTz6/R7MFnu6ha+vL3379mXHjh2YTKZ6x+sxoiOy1Ebh9tTmvvQ6WXNyKFi/nvwVKzAdOtSomVCbzcqxnVvpGjUYrc6J/3zW/BvSDrC+5xjc9e5Etots8KWdB0QgNBoS9+w+e7B9P7hrNXQeDj/dBZvebfLQxoaMRSu0Ks3iIlJfgFzSxHMIIbTA+8AUoC9wgxCib+U2Usr/SikjpZSRwFPAWillVqUmY8vOR9czzlbJyTXUFaVOFouFW2+9lfDwcGbMmEFRURFhYWE8/fTTDB8+nOjoaHbt2sWkSZPo1q0b8+fPB5o3+6y0Gk1+drd15qJSjDVUsDD07oXWw6PiWFZWFjk5OXTt2hVrtgkooWjnVqTVSnZhCbd8shUp4bs5w5jYr0O1+4ya3AWtENzbPpCfd6dw22fbKS7bGW/EiBGYzeaKLdvr4tLRA0NXb/I3piBLHV8lwXT4MMkPPMCR4SM4edccku9/gONXXU38pZeSs3gx0lb/PU8diaM4L5fug4c5fHwVTu+BTe8hI2exviCB4UHD0WsaHowb3NwJ6tG7+rbTrj4wazH0vRKW/x/8/XyTZq18jD4M7jBYpVlcROrbSS9CCFFTIpUA6lvuOwSIL3tbDyHEt8B0oLb3J24AFtXTp6K0KasXLiDtRIJD+2wX2pWxs+fU2+7w4cN88sknjBw5kttvv50PPvgAgJCQEDZv3swjjzzC7Nmz2bhxIyaTiX79+nH33Xc7dKxKi2nOs7tNMxdaMFTKQZZSUnzgIF4TJ1Zpl5Bg/3/ZrVs3LPtPo3HXYMvLw5yQwGMbc8goKGHxPSPo0b7mBWI+7d3oNbQ9R3ek8fq1fXli2UHu/GI7n84eTKdOnQgLC2PLli0MHToUna7uH7We40LI+Hg/hTtT8RgW1MzvQNnrttnI+PBDMj6cj8bdHf+77sJ95Ei0nh6YjhwhZ9G3nH7m/8hbvpxOb7xRZfHiuRJjdyI0GkLDBzpkbNXYbPD7I+Dmz9Ght5G2/DZGB49udDdhEQPZ9MM3FOXl4ublffaEzgAzPoWlfrDxbdC7Qky1N7XrNSF0Ai9teYmjOUfp6duz0dcrbUudM8hSSq2U0quGD08pZX2/2nUCTlb6OrnsWDVCCDdgMrC48u2B5UKInUKIWqMBIcQcIcQOIcSO9PRWWk9S/bKptICQkBBGjhwJwKxZs9iwYQMA06bZ68AOGDCAoUOH4unpSWBgIEajkZycnJYaruJAzXx2t1nSJu05yO5nA9LS5GRsubkY+/Wr0jYhIQEvLy/8/f2xZpnQt7PPLq/7bR0r49J4+rLeDAj2pi6DL+8CgGtsLq9fE87G+Eye+mkfUkpGjhxJfn4++/fvr3fchm4+uHT2JH/NSaSl+bPItuJikh94kIx338Nr8mS6//Un7R59BPehQzD27YvPlVcS+u0i2j/3LIUbN3Hi5luw1vF/P3HPboJ69Mbo7lFrm2bZ+x2k7IQJ/2J9xh4ARnVq/GLAsIgokJIT+2Krn9Ro4bL/B5GzYM2rsHFeo/sf13kcAsHfJ/5u9LVK21PfDHJz1JRgUFuoeAWw8Zz0ipFSylNCiHbA30KIOCnlumodSrkAWAAQHR2tQlGlVWnITK+znLsjWPnXBoMBAI1GU/F5+dcWS9vZ1UtRzlVitiIlVWaQTQcOAFQJkKWUHD9+nJ49e4IES44ZY7+OCFdXDq7ZRvSUW7l1RFi99/MKcGXUtT1Y+81hhnTz5pHxPXlrxRG6BXpwb0x32rVrx6ZNm4iIiKhzhz4hBF4TQsn4ZD8Fm0/jObrGuaQGsRUXc/Keeynato32Tz+N782zary3EAK/G2/EJaQzyffeS9LcuYR+/jkaY9U3GIryckk9Hs+IGTc2eUx1KimClS9Cp0EQfh3rl99Ob7/etHNr1+iu2nftjtHDkxN7dtFnZA11kzUamDYPSgvh72fBPQAiG/66AlwDGNR+ECtOrOC+yPsaPT6lbWnoTnpNkQyEVPo6GDhVS9vrOSe9Qkp5quzPNOBn7CkbbZSK25XzLykpic2bNwOwaNEiRo1ycnkmRWlh5kJ7JQhjpRlk04EDoNdj6HX2LfH09HSKi4sJCwvDmlcCVonO35W0oC6Epify4vR+9W45Xa7f6I70HNqebb8dZ5RFz1WRHfnvX4f5Y99phg8fTlpaGseOHau3H2MPXww9fMhfndTkihY2s5nk++6naOtWOr76b/xuubne1+ExehQd3/x/mPbu4/Rzz1XLr03aFwtS2mdnnWHHp5B/Gia8RJ6lgNi02CbNHgNoNFpCB0SSuHd37XnCGi1c/RF0uQR+ewiSG1cDYHzoeOJz4knIdWzqnNL6ODNA3g70EEJ0EUK4YA+Cfz23kRDCGxgD/FLpmLsQwrP8c2AiUP/7VIqiVOjTpw+ff/454eHhZGVlcc8997T0kBTFqUzlAbLH2dq5pgMHMPTojsbl7LETJ04AEBoaijWrGIACo4aN2nZ0zz9N3wDXBt9TCMGlt/ShR3Q7tixJ4DKzgcEhPjz+w17cOoTh4eHRoI1DALyndMFmspC7LLHB9y8nS0tJefAhCjdvJuiVV/CePr3B13pNmEDggw+Q9+tv5HxXtRxa4p7dGN09aN+te6PHVK+SQtjwFnSNgbCRbD61Gau0NjlABnuaRWF2FhlJibU30urh2s/BMwi+vQnyGl6Henzn8QCqmsVFwGkBspTSAtwP/AUcAr6XUh4QQtwthKi8EugqYLmUsvJWQu2BDUKIPcA24A8p5Z/OGquiXGjCwsI4ePAg8+fPZ+/evSxevBg3NzcSExMJCAgAYPbs2bz33nsV15SfCwsLa1DepKK0NsUF9gDZ1cOeYiGlxHTgIK7n5B+fOHECT09PfH19sWSZAVh0OI0jPsHoLKWY4+MbdV+NVsOE2/sRfXkYRzaf4eo8F/y1Wh74di+DooeQkJDAmTP17+jm0tEDj1GdKNx+BnNCToPvL6XkzEsvU7B2LR2efx6fq69q1PgB/OfOxX3ECFJff52Skycr+j2xdxedB0Si0Wgb3We9tn0ERRkQ8zQAm05twlPvSURgRJO7DI2wLySsVs3iXG5+cMMiMOfDdzeBpWHFXdq7tyciMEIFyBcBZ84gI6VcKqXsKaXsJqV8pezYfCnl/EptFkoprz/nugQpZUTZR7/ya9sslWGhKIridKaC8hQLe4BsSUvDmpuLoVfvijZSSk6cOEFoaChCCCzZ9lrFH+9JJnSkvaJocRN+QRQawdArujLprv7knS7klgIDeacKWXrGFb1eX5HuVB+v8aFo/Yxk/xTf4LJvWZ98Qs733+M/dy6+11/X6LHbx68h6JWXERoNp556CmmzkXnyBAXZWc5JrzDnw8Z3oPt46DwUKSUbUzYyNGgoOk3Tl0d5+gUQEBJaf4AM9jrJV35gXyC45t8NvseE0AkcyjrEyfyT9TdW2iynBsiKoiiKcr5UBMhlM8jmI0cBMPTsUdEmOzub/Px8QkNDAbBmmSgyaim02rh+2jA07u6Y4w43eQzdB7Xjmn8OwuiiY1ahkf3bMvEK7sm+ffvIzc2t93qNixbfq7pjySgmb+WJetvn/fknaW/8P7wuu4zAhx5s8rgB9EFBtH/mGYp37CTriy9I3GvfdMMp5d22LYDirIrZ44TcBFKLUhnRaUSzuw6NiCIl7gClDdiohX5XQtQtsOFtOL6+Qf2PD1VpFhcDFSCfD2oGWVEUxelMhaUIAQZX+wyk+cgRAAw9zgbISUlJAHTu3BmA0qxijpeWMqKbP707emPo3RtTXFyzxhEQ7Mm1T0XTsZsPU4tcWL/fBSkl27Zta9D1xh6+uA1qT/7aZEzx2bW2K9q9m1P/fALXqCiCXv03QtP8H+neV07HY9w40t96m+PbNuPXMRivgMBm91tFqQm2zLfPHgfbdzfcmLIRgJEdRza7+7CIKKwWCycP7WvYBZNeBb+u8PNcKMqqt3knj0709e+ryr1d4FSArCiKolwQigtKMXroERp75Qbz0aPoAgPR+fpWtElOTsZgMBAYaA/6itKKSLRaKsq6GXv1whwX16Ad5uri6unCtAcjaN/Th0vyPciTAWxv4PbTAD7Tu6ELdCPr28NY88zVzpempJB83/3ogjoQ/P57aCqVbGwOIQQdnnsWm1bLqcOH6Dyg6fnAtdr3PRSmwYgHKg5tOrWJMK8wOnp0bHb3wb37oXMxNCzNAsDgAdd8DAWpsPTxBl0yIXQC+zL2caaw/txypW1SAbKiKIpyQTAVlFTkH4N9BtnQs+qOZydPniQ4OBiNRoMstaEvtpJv0DC+T3sADH16YysqojQ5udnj0em1XHl/BO4d3OiQ0YkSs5ndu3c36FqNixb/m3ojzVYyF8UhrWffirQVFnLy3vuQpaWEfDi/yi8AjqDv0AHNjddhQRIgHbw4z2aDTe9BhwHQxV6r2GQxsSN1R7OqV1Smc3EhuG9/Evc07HsNQKcouORx2P8jHF5Wb/MJoRMAlWZxIVMB8vmg9m1XFKUNEEKECCFWCyEOCSEOCCEeaukxNYapbAYZQFqtmI8dq5JeYTKZSEtLIzg4GIDUZHtOcGhXX7Rls87G3n3sbQ81L82inM5Fy8xHonDV+SBKvFi5dgNWq7VB1+rbu+NzdQ9KjueRu+y4/XXZbJx68knMR4/S6a23MHTt4pBxniu/u71f7feLsZmrz2A3WfwKyDgMwx+AshrNu1J3YbaaGdGx+fnH5cLCo8g+lUxeelrDLxr1KLTrC78/Cqa688VDvULp6dtTpVlcwFSArChKFYmJifTv3x+AHTt28OCDzVv4o7QpFuAfUso+wDDgPiFE3xYeU4MVF5RWzCCXJCUhzeYqM8gpKSlIKQkJse9htWFHCgCDI4Mq2hh6dAeNBvNhxwTIAO7eBq55aCDuhSFYTIWs2LSz4dcObIfHiI4UbEihcGcqGe+9R/7fK2j/xD/xGNX8fN3apByNw8vbF+2JJLI+/dRxHW9+Fzw7Qv+rKw5tPLURF40L0R2iHXab8sobDU6zANC5wPT3oOAMLH+23ubjQ8ezO2036UXpTR2m0oqpAPk8UPPHSlsVHR3NvHnzGtxeSomtmbmbSsuRUp6WUu4q+zwfew37pu97fJ6ZCksraiCX1zKuPIN8sqy+b/kM8tEjmQCEdPGpaKMxGnHp2sVhM8jlgrp4M2raYLQWV9atWEehueG75Xlf3gVDN2+yfzxM1qI/8Z5xDb633OLQ8VUmbTZS4g7SOSoaz8mTyfjfAkpTUprf8Zl9cHwdDLvbvllHmY0pG4lqH4WrruEbtNTHr1Mwnv6BjQuQwb7l9fD7YNfnkLC2zqYTOk9AIlmZtLIZI1VaKxUgO5HKrFBaSmJiIr179+bWW28lPDycGTNmUFRUxM6dOxkzZgyDBg1i0qRJnD5t30Fq586dREREMHz4cN5///2KftasWcPUqVMB+/a8EyZMICoqirlz5xIaGkpGRgaJiYn06dOHe++9l6ioKE6ePMl///tfBg8eTHh4OM8//3xFf1999RVDhgwhMjKSuXPnNvitZuX8E0KEAQOBrS08lAaRUpalWNh3zCs5Zt8KuHIKQnJyMu3atcNoNHIkNR9tfilWjUBTaec9sKdZNLeSRU2GjgvF36MXelHAKx8tr3075HMIrQa3KIGtMAO3UQ/S7uEnG7wVdlNkJidhKsgnuE9/2j/xTxCC1Ndea37H2xaAztVeVq3MmcIzHMs95pDqFZUJIQiLGEjS/j3YGvuciXnaXtXitwftu/3VoptPN7p4d1F5yBcoFSArihPl/HaMtP/tdehHzm/HGnTvw4cPM2fOHPbu3YuXlxfvv/8+DzzwAD/++CM7d+7k9ttv55lnngHgtttuY968eXVuZvDiiy8ybtw4du3axVVXXVVRLqv8Xrfccgu7d+/m8OHDHD16lG3bthEbG8vOnTtZt24dhw4d4rvvvmPjxo3Exsai1Wr5+uuvm/cNVpxCCOEBLAYellLm1XB+jhBihxBiR3p663h7udRkxWaVFSkW5oRj6IKC0Li7A2Cz2Th58mRFesUfe0/TEQ1aX0NF1Ytyxt69sJw+jTUnx6FjFEJw6z2T0ViNuJw+xOfrExp0nSUzk1OPPkDJse/QGD3J/PYostR5v1wmHzoAQHCffuiDggi4+27y/15B4ZYtTe+0OAf2/gDh14Lr2UWFm07Zt+F2RP3jc4VFRGEuKuT00UbWtXZxg2nvQnYirKp9nzIhBOM7j2d76nayTPWXh1PaFhUgnw9qJllpASEhIYwcaZ+VmTVrFn/99Rf79+9nwoQJREZG8vLLL5OcnExubi45OTmMGWNfUX7zzTfX2N+GDRu4/nr7ppeTJ0/Gt9LK+dDQUIYNGwbA8uXLWb58OQMHDiQqKoq4uDiOHj3KypUr2blzJ4MHDyYyMpKVK1eSkNCwAEE5f4QQeuzB8ddSyp9qaiOlXCCljJZSRpeXS2tpxedsElJyLAFD164V5zMyMjCbzRXpFUv3naa7ix5jQPW39Q3lC/WasWFIbdy9jQwbMhz0BWz9dQdbEjLrbC+tVlL+8RjWnByC33gBv+t7U5pcQPbiow2egW6s5EP78fDzxyvQXtnDb/at6Dt1IvXfryKb+q5P7DdgKYbBd1Y5vDFlI+1c29HDp0ctFzZd5/6RCKEhcW8j0ywAwkZB9O2w5QM4ub3WZhPDJmKTNlYnrW7GSJXWqOn7OSqKUi+fK7q12L3PfQvW09OTfv36VZslzsnJadDbtXX9MHYvm6Urb/fUU08xd+7cKm3effddbr31Vl599dWGDF9pAcL+D+ET4JCU8s2WHk9jlO+i5+qhR9psmI8fx2fGNRXny/OPQ0JCOJKaz9G0AtrrvdH6Gav1Zezdy95n3CHchw11+FjHTRnJjtitdHJJ4bnPdvLpo6MI9nWrsW36e+9RtGULQa+8grGPPXD3mhBK3t8n0Ad54Dkm2KFjk1KSEneA4L4DKp4LGoOBdo8/TsrDD5Pz42J8r5vZuE5tNtj+MQQPgaCzdZWtNitbTm9hbMhYp6SMGD086NCjJ4l7djFy5qzGdzD+RTiyHH65D+5eD7rqtaZ7+fYi2COYv0/8zTU9r6mhE6WtUjPIinKBSkpKqgiGFy1axLBhw0hPT684VlpayoEDB/Dx8cHb25sNGzYA1Jr2MGrUKL7//nvAPkucnV3zDl+TJk3i008/paCgALBXDkhLS+PSSy/lxx9/JC3NXnYpKyuLEyfq30pXOa9GAjcD44QQsWUfl7X0oBrCVHh2Btly5gyyqAhD17O/oCYnJ+Pq6oq/vz9/7D2NJ6Avleh8qwfIuoAAtIEBzdpyui46nY6YcaOxuOQxoiCPuxZuJ89UfdFewbp1ZH44H+9rrsbnmrNVHzzHheA6IIDcP49TfNixb+3npp6hIDuL4D79qhz3nDQRt+ho0t95B2t+fuM6Pb4Gso5Vmz3en7mfvJI8RnZyXjWOsPAozhw7SnF+tUyh+hm94Iq37WXp1v23xiZCCCaETWDr6a3kmuvfSlxpO1SAfD6o1XpKC+jTpw+ff/454eHhZGVlVeQfP/HEE0RERBAZGcmmTfb8v88++4z77ruP4cOH4+pa80ry559/nuXLlxMVFcWyZcsICgrC09OzWruJEydy4403Mnz4cAYMGMCMGTPIz8+nb9++vPzyy0ycOJHw8HAmTJhQsUhQaR2klBuklEJKGS6ljCz7WNrS42oIU0EJAEZ3PebyBXrdzqZYlOcfCyH4Y99pJnaypwjpaphBBuct1Cs3eEg0bkZ3dK4n8EkqZs4XOzBbzqYvWDIzOfXkUxh69aLDs1VLjgkh8L22J/oO7mR9E0dpWpHDxpV8aD8AwX36V7tnu6eexJqdTcb8+Y3rdPsn4OYPfadXObwpZRMCwfCg4c0ac126RA4CKUmMbXhpvSp6TIDw62HDW/YqHDWY0HkCFmlhbXLdVS+UtkWlWJwPKj5WWoBGo2H+OT/IIiMjWbduXbW2gwYNYs+ePRVfv/DCCwDExMQQExMDgLe3N3/99Rc6nY7NmzezevVqDAYDYWFh7N+/v0p/Dz30EA89VH2Pieuuu47rrruuma9MUaoryi9LsfByoTDBvpDVpZt9BrmoqIiMjAzCw8M5kppPfFoBjw3uAimZaGuYQQYw9u5N5pYtyJIShItLjW2aQ6/Xc+mEcfz2228MLs7ny6M2Hv1+D+9ePxAh4PRzz2PLz6fjws/QGKuPUeOixf/WvqS9G0vmFwdp98BANIbm73qXfOgArp5e+HUKqXbOtV8/vK++iqwvvsR35kxcQkPr7zDvtH1nuhH3g77q69h4aiP9/PvhY/Rp9rhr06FbDzx8/Ti6bTN9Ro9tWieTX4VjK+2pFneuAm3V0Kl/QH86uHfg78S/mdZtmgNGrbQGagZZUZQGSUpKYvDgwURERPDggw/y0UcftfSQFKVCcV4JGp3AxajFfCwBrY8POj8/wJ7mA/b6x8v2nUEIiPC0v1Oi8685QDb07gWlpZiduJA0MjISPz9/ijyOc4fRkz/2nOb/ftlPzk8/U7ByJYGPPILxnK2yK9P5GPG7sTeWzGJy/3DMOJPj9tOpd99ac4IDH3oIjV5P6n9rTjmoZs83IK0QdWuVw7nmXPZl7HNqegWA0GjoPmQEx3fvoMRU3LRO3Pzgsjfg9B7Y+Fb1e5RVs9h0ahMFJQXNHLHSWqgAWVEuQDXN6jZXjx492L17N3v27GH79u0MHjzYof0rSnMU5Zfg5umCEAJzwrGK2WOw5x8LIejUqROr4lIZGOKDMd+CxkOPxljzG6nlC+IcvWFIZVqtlgkTxmPRFmEqSOKBLh1YsTqWpH+9jGt0NH631r8ZiLGbDx6XBFO47QzFB+uuiFGf/KwMclPPVEuvqEzfrh3+c+dSsGJl/WXfpIRdX0LoSPCvumB56+mt2KTN6QEyQM9hI7GUlnB8dxPTLAD6XQn9roY1r0FK9aoYE0InUGIrYV1y9XfolLZJBcjng0qxUBRFcari/BLcvM5uElK5xFv5BiG5JZI9ybmM690OS2YxOv/ad25zCQ1FGI2Y4w45ddy9e/cmJCQEk08SnkfyeOX0BmwWC19ecis20bAf0d4TQtEHuZP901GsZbnYTZFSUf+49gAZKpV9e/W1usu+JW6A7ONVNgYpt/HURjz1ngwIGNDk8TZUp959cfP24cjWjc3raOqb4NEefrqr2gYike0iCXQNZEWS2jTkQqECZGdSi/MURVHOi6K8Elw9XbBkZ2PNzsalbIGezWYjOTmZ4OBg1hy2b2oyrnd7LBnFtaZXAAitFkPPnk6phVzlPkIwYcIELNJMrjaB3NIuJE69kU8SzNz39S6KS+qvOyx0Gvyu74XNZCHnl4ZtJFST5EMHcHF1JTC0S53tysu+mQ8fJmfx4tob7voCDN7Qp2perk3aWJe8jhGdRqDTOH8plEajpfvgYRzftZ3SEnPTO3L1havmQ+Yx+OuZqvcQGsZ1Hsf65PUUlTpu0aTScpwaIAshJgshDgsh4oUQT9ZwPkYIkVupnNBzDb1WURRFUcoV55Xg6uVCyTF7gGgoS7GovEHIqkNpBHkb6eXvhjWvpM4ZZLAv1DPFxTltQ45ynTt3Jrx/f4pcT5LSqT/Rs27nual9+evgGW74aAsZBfUHdfr27niN7Uzxvowml35LPrSfjr36otHWv9jPc9JEXKMHkf52LWXfirPh0K8wYIZ9Z7pKDmYeJKM4gzHBY5o0zqboOXQUpWYTiXuasGlIZV0usS843PkZHFhS5dTE0ImYrCY2nmrmTLXSKjgtQBZCaIH3gSlAX+AGIUTfGpqur1RO6F+NvLaNUDPJiqIoziKlpDi/FDdPl7Ml3spSLJKTkwHo0LET64+mE9OrHbZse8Cpq2EXvcqMfXpjy83Fch7KEUadPImutIRiv6Os+SGeW4Z2Zv6sQcSdyeOqDzayP6X+GrueY4LRBbqSsyQeWwNmnisrzs8jMzmJ4N796m+Mfea7/VNPYc3OJnNBDQt29/0IFlON6RVrk9eiERpGdRrVqDE2R3Df/hg9vTiyeUPzOxv3HHSKhl/uh4z4isNR7aPwNfjy94m/m38PpcU5cwZ5CBAvpUyQUpYA3wLT67nGEde2Pio+VhRFcRpzkQWbTeLqqcd8LB7h6oouKAiwB8hGo5H4XEFhiZVLe7fDkmGvZlBXigWAoVdvwDlbTldWmpKC6dPPGCYlJm0uaXmJ7PrzBJP6deDbOcMptUiu/nAT325LqnM2W+g0+F7VHWu2mfxVJxs1hpS4gwB06tOwABnsZd+8pk4l68svKU1Nq3py1+fQIRw6Rla7bu3JtUQERuBr9K12zlm0Oh09h4wgfscWzEXNTIHQucC1C+3l3n64FUrs/ek0OsZ1Hsfak2sxW5uRyqG0Cs4MkDsBlf+HJpcdO9dwIcQeIcQyIUT5/8yGXosQYo4QYocQYkd6erojxq0oiqK0IUV59oVpbl4u9gV6XbogNPYfbydPniQ4OJjVh9Nx0WkY0d0fS2ZZgFzPDLKhZ08QApOTF+qlz5sHGg2jH3yAkJAQiv0S2bb8CNlnCokM8eGPB0cxJMyPJ3/ax6Pf7yG3uPquexVj7uqD26D25K9LbtQGIsmH9qPV6+nQrfaycjUJfPABpNVKxgcfnD14Kta+qUYNs8ephakcyjp0XtMryvUfOwGL2czhTQ6oNOETAld/BKn74fdHKtYcTQidQJGliM2nNjf/HkqLcmaAXFMRxXN/9d0FhEopI4B3gSWNuNZ+UMoFUspoKWV0YGBgU8fqVGoCWWkJV155JYMGDaJfv34sWLAAgE8++YSePXsSExPDXXfdxf333w9Aeno611xzDYMHD2bw4MFs3Khy6JS2ozjfHiC7erlgTkioKPFmMplIT08nJCSEVXGpDO/qj5uLDkumCY177SXeymk93HHp3BmzE0u9meLiyP31N/xunoVLx45MmzYNoZHkex9mzTeHkVLi72Hg89uH8PD4Hvy65xST3lrH2iO1Twh5TwlD6DXkLj3e4HEkHzpAUPde6PT6Ro3fJSQE35kzyfnxR8zHy+636wvQGWHAtdXar0uxB6ctESB36N4T/+DO7Fu93DEd9pgAY56Evd/CpncBGNJhCJ4unirN4gLgzOWjyUDlrXiCgVOVG0gp8yp9vlQI8YEQIqAh17YpKkK+aC1btowzZ844tM8OHTowZcqUett9+umn+Pn5UVxczODBg7n88st56aWX2LVrF56enowbN46IiAjAvvPdI488wqhRo0hKSmLSpEkcOuTcWTNFcZTyGWSD1kLB6dMVC/TKNwjRevqTmHmC20fZqzNYMorrnT0uZ+jdG5MT/y+kvfkmGi8v/O+6C4DAwECmXDaFX3/9laMpeziyNYhew4LQagQPj+/J2F7t+McPe7j1023cMKQzz1zeBw9D1R/lWg8XvMZ1JnfZcUxHszH2qDuVwVxURNrxYwy9emaTXkPAPXeT8/PPpM+bR/B/XoF9P9i3lXb1qdZ27cm1dPLoRDefbtU7cjIhBAPGTWTNFx+TkZRIQOew5nc65glIPwR/PwcBPdH3mszYkLGsPrmaUmspem3jfuFQWg9nziBvB3oIIboIIVyA64FfKzcQQnQQZdv1CCGGlI0nsyHXti0qQlbOv3nz5hEREcGwYcM4efIkX375JWPGjMHPzw+9Xs+1156d3VmxYgX3338/kZGRTJs2jby8PPJrWpmuKK1Q+QyyLsMeEBt6dAfOLtA7mGsPIMf2agdQb4m3yox9elOalIS1wPE7pBVu2UrhuvUEzJmD1tu74vjAgQMZ0H8ARZ4nWPnzdkyFZ1MqIkJ8+P2BUcy5pCvfbk9i0lvr+OvAmWq5yR4jO6L1M5LzewLSWvfPoFOHDyKlrd76x7XRBQTgP3s2+cv+pPiP+WDOqzG9othSzJbTWxgTPKbWnfqcrc/osWi0OvavcdAMr0YDV86HoHBYfAekHmRC6ATyS/LZemarY+6htAinzSBLKS1CiPuBvwAt8KmU8oAQ4u6y8/OBGcA9QggLUAxcL+3/y2u81lljVRRnachMrzOsWbOGFStWsHnzZtzc3IiJiaFXr161zgrbbDY2b96Mq2vDZtUUpTUpyitBCCClrIJFd3uAfPLkSQIDA1kTn0PP9h6E+LlhK7E2qMRbOUNv+0I98+HDuA0a5LAxSylJf+cddB064DvrpirnhBBMvWIqSUnJpNv2sfrHTky59ey9jXotT1/Wh0n92vP0T/uZ++VOxvVuxwtX9KOzv72kmtBp8J7ShayvD1G44wweQ4NqHcvJQ/vRaHV07Nm7ya/H7/bbyF60iPT5X9L58q723fPOsfnUZsxWM2NCzn96RTk3L2+6Rw/l4LrVjL5xNlqdA2Z4Xdzg+kXw0ThYdB3Db/8Ld707K06sOK+VOhTHcmodZCnlUillTyllNynlK2XH5pcFx0gp35NS9pNSRkgph0kpN9V1raIoDZObm4uvry9ubm7ExcWxZcsWioqKWLt2LdnZ2VgsFhZXKvA/ceJE3nvvvYqvY2NjW2DUitI0xfmlGD30lMbHIwwG9MHBSClJTk6mQ8dObDuexdje9tlja5YJAF1AA2eQe5dXsnBsHnLR1q0U796N/5y70BgM1c4bDAZm3XwjWh3sOLqC5Pi0am0Ghfrx+4OjeOayPmxNyGTCW2t5Z8XRis1FXPv749LFi7zlJ7CZLLWOJfnAPjp064He0LDvSU20Hh4E3HwNhSdMFBrHQQ0zxMtPLMfb4M3gDi27Tf2AcRMpzs/jsCNKvpXz7gTXfwMFaRh+mM0lHUeyKmkVFlvt33eldVM76Z0PKsNCOc8mT56MxWIhPDycZ599lmHDhtGpUyeefvpphg4dyvjx4+nbty/eZW/rzps3jx07dhAeHk7fvn2ZP39+C78CRWm4olwzbl4GzMeO4dK1K0KrJTMzE5PJRIHWG4tNMq5SegXQ4BlkXfv2aH18MB086NAxZ3zwIbrAQHyuuabWNoGBgcy89nqsWjNfffMVBTWkeei1Gu66pCsr/xHD+L7teWvFEca+sYYfdyYjJfhc3hVbUSl5q2su+1ZiKuZMwlGC+zYtvaIyn7BsdG5W0ledrJbyYbaaWXNyDZd2vhS9pmXzckPDB+If3JltS35A2myO6zh4EFz1Pzi5jYkph8k2Z7PtzDbH9a+cVypAVpQLkMFgYNmyZezdu5cffviBNWvWEBMTw4033siRI0dYsWIFycnJREdHAxAQEMB3333H3r17OXjwoAqQlTalIMeMu48Bc3x8RXpFef7x/lwdXkYdg0LtC9UaWuKtnBACY0Q4xXv2OGy8RTt2ULRtG/533Vnj7HFlPft0Y1TEJEzWAv734UdkZmbW2K6Dt5H3b4zi+7nDae9l4LEf9nDFexvYYTbjFtWegg0pFa+9slOHDyFtNkKamH9cwVqK5sB3+MeEUhy7j6ItW6qc3pSyicLSQiaETmjefRxAaDQMufJaMpOTOLZru2M773clTH6NUfEbcBda/jr+p2P7V84bFSArykXkhRdeIDIykv79+9OlSxeuvPLKlh6SojRbYY4ZNw8NltOnq+QfGwwGVicWM6ZXO3Ra+4+7hpZ4q8w1IoKS+GNY8/Lqb9wAGR98iNbfH59rq5dBq8nY6YMJEYMpLChiwYIFHKxjNntIFz9+vnck71wfSU5RKTd+tJV/5eQgNaLGsm/Jh/YjNBo69urT5NcDwJG/oDANn9sfQte+Penvv19lFvnvE3/j5eLF0KChzbuPg/QecQlege3Z9vP3jt9KfNjdGIc/wLi8PP5O+IMSa4lj+1fOCxUgnw8qxUJpJd544w1iY2OJi4tj3rx5LbaSXFEcxWqx2XOQLfaqK5UrWHgHtCejsJRLy/KPoXEVLMq5RUYCULx3X7PHWxwbS+GmTfjffjuaBi6K1Wo1jL92CD4ZkbjqPfn+++/54YcfyM2teftpjUYwPbITK/8xhien9GZlcjYflRZRfCCTYzuqVkw9eXA/7bt2x8XVrXkvbNfn4BmEps9k/O+6i+IdOynaaq/iUGItYfXJ1YzrPK7F0yvKabRaBk+7htPxhzl5oPl/r9WMf5EpgVHk20rYtOHfju9fcToVICuKEzh8RkJpNvV3cmEqzLVv6WsosqceGLp1w2w2k5aWRo7wQiNgTM+zm0g1pgZyOWN4OAhBsQMWr6Z/+CFaHx98r7+uUdeF9vOna59g3JL7MWrEJRW/5P7222+cPn26xn/fRr2Wu8d0Y/0TY/G5JJhUbJz48QgPfbOL+LQCSs0mzsQfaXJ5two5J+Ho3zDwZtDq8Ll2Brp27ch4733AXr2ioLSgVaRXVNY/Zjxu3j5sWbzI8c8HjYZhV32ONxqW7f8SDixxbP+K06kA+bxQP5gvJkajkczMTBWQtSJSSjIzMzEam75KX2mdCnPKaiBnplRUsEhKSkJKyb5cPQM7++Lr7gKAzWyxl3hrZICs9fDA0KNHswPk4n37KVy7Dr/Zs9G4uzf6+pEzumMpAZfMTjzwwANERkYSGxvL//73P95++21+/fVX9u7dy+nTpykpOfu2vo+bC49e1oeQq3vSEy3aA1lMfGstz/zvd2xWCyF9BzTrdbH7S/ufUTcDoDEY8L/rLop27KBw6zaWn1iOp4snw4OGN+8+DqZzcWHY1ddx8uA+EnY5fjGd3sWdCd2msdrdneKf7oQjDtrBTzkvnLmTnlJOxUkXleDgYJKTk0lPr30rWOX8MxqNBAcHt/QwFAcrzLHPIOtOHcOlm72CxYkTJ9BoNGxPFzwyqVJ6RZp9kZq+fePTCVwHDiTvjz+QFgtC17QfnRkffojGy6ta3eOG8u3gTr9RHTmw/hTh40K44ooruPTSSzlw4ADHjh3jwIED7Nq1q6K9u7s7Xl5eeHp64unpiYeHByIwlxmFGtr39CNu3VYC0PDc1mLucEtjTM9ANJpGpl1ZLfatpbuPB5/OFYd9Zl5L5oIFpL47j5WXxTO+8/hWuatc+PgpxP71B2u//JSwiCjH1EWuZEq3K/jx2BLWdujO5O9vhpt+hC6jHXoPxTlUgKwoDqbX6+nSpUtLD0NRLgrlAbJIOIAh2p4qcOLECVy8/LEUaRnfp31F29LUIgB07RofILsPG0rOd99hOnAA17It2hvDdOgQBatWEXD//Wg9PBp9fbnBU7sQt/UMW5YcY/LcAbi5uTF48GAGDx6M1WolPT2dzMxMMjIyyM3NJT8/n7y8PFJSUigsLDzbURyEttNg8o/ALX0f//4ygf/4dmL2Jb24cmAnjHptwwZ0dDnkn4bL3qhyuHwWOfXf/ya0p4bp46Y3+TU7k1anY8zNd/Dzf15kz/KlRF3m2HEOaj+IQNdA/uzYm8klEr65Dm5ZAiFDHHofxfFUgKwoiqK0WQU5ZrQ6gTh1HEO3KykpKSElJYUcjzA6+bjSs/3ZYLQ0rQi0Ap1f43eMdBs2DIDCzZubFCBnfDgfjYcHfjfPavS1Vcbh5ULUxM5s++04ZxJy6dD17BbVWq2WDh060KFDhxqvtVgsFBYWkrLkAJlHTrMjdy3GbqG42Ux0tKUjC06w6rd9fLG0A0OiBjBrWBjd23nWPaCdC8GjA/ScVO2Uz8xrOfbef7lps4ZBzzpuF0JH6zIwmtDwgWz+cRF9Ro/F1dPLYX1rNVomhU3i+8Pfk3/D93h+NQO+vApu/B7Cqu82qLQeKgfZmcpSK1QqqqIoinMU5phxcxMI7BUskpOTsdls7MrWM75PuyqVWixpRegDXRHaxldv0fn6Yujbh8JNmxt9renQIfKXL8f35llovb3rv6AeEZeG4OblwqbF8Y1a66DT6fD29qbXjMGEagIZqxvOlVOn8o9HH+Xuu+9m9KiRdPOGIRyhYOdv3P/OD1z34UaW7E7BVGqt3mHOSYj/GwbOghrSJ85YsvhxiJUex80Ub9/RnJfsVEIIxtx8B+biIjZ+96XD+5/cZTIlthJWZe2H2UvBqyN8dQ0cW+3weymOowJkRVEUpc0qzDFj1JRVsujenRMnToAQpJS6cWml9AqwzyA3Jb2inPvw4RTv3o2tqKhR16W/+x4aLy/8b7utyfeuzMWoY8gVXTh9LJfjezIafb3WXc8pz0QCjMF4ZHgghKBDhw6MHz+exx99mOuvv57unQIZpk8iNG0Db/ywhmGvruRfvx3k8Jn8sx3t/so+A1S2OO9cvx77lb8jBcLfr6KiRWsV2DmMgZOmsmfFn6QmxDu07/CAcDp5dGJZ4jLwCrIHyX5d7ekWqrpFq6UCZEVRFKWCEOJTIUSaEGJ/S4+lIQpyzBhLchFGI/pOnThx4gQ2ozcuLgaGdvWraGcrsWLNNqFvToA8YgSytJTCc3aJq0vx3r0UrFqF/22z0Xo57q37PiOC8O3gxuafj2G1Nm67ZCkle46vJN8lh7y/TmDNM1ec02g09O7dm7vn3MWsWbMI8XNjvMtRprge48ctR5j09jqu+mAj329NwLbrC+g2DnzDqt3DJm38Ev8LUSHDaDd3LkXbtlG4tXVvuzxi5k24eXmz4pMPHLoFtRCCyWGT2XJqC5nFmeARCLN/h46R8MNs2PyBw+6lOI4KkM8HlWKhKErbsRCY3NKDaAhpkxRmm9HnnMbYqxdWKUlOTibJ7MboHoEYdGcXmlnSikA2bYFeOffBg9F4e5P3Z8O3D06f96697vHNtzT5vjXRaDUMv7o7OalFHNpwqv4LKslKOUlBVibWaBekRZK9+GiNqRrdu3fnnnvuYcKECbibM7nR8zCPDnajwGThr1++QpN/ii9Lx7I7Kbva9TtTd5JckMz07tPxmTkTXWAgGe++26rLXxrc3Blz8x2ciT/CvtV/O7TvK7pdgVVa+T3hd/sBNz+45RfofTn89RQse8JeEURpNVSArCiKolSQUq4Dslp6HA1RmFuC1WLD5XQ8hj69SUlJwWKxkGBy49I+7aq0LT1jr+CgD2p8/eFywsUFzwnjKVi5CpvZXG/7op07KdywAf+77kTr0fT71iZsgD8de/iw7ffjlJgaHlyd2LsbgJBhkfhc1gXT4WwKt5yusa1Op2PkyJHcfffd+Pn5krVvLfd1zeb10G3k6AJ5/XgXrvpgE5PfXs+nG46TXWivv/z94e/x1HtyaedL0RiN+M+ZQ9GOHRW767VWfUbF0Kl3P9Yv+pzigvz6L2igbj7dCA8IZ0n8krO/JOhdYeYXMOxe2DofvrwSChufMqM4hwqQFUVRlEYRQswRQuwQQuxoyXrfeRn2usaGnGSMffra84+BNOnB2N7nBMinChF6DTr/xlewqMxr8hRshYUUbthQZztps5H66mvoAgPxvfHGZt2zNkIIRlzdneL8Unb/ndTg647v2YVvUEe827XHfXgQhp6+5C49bq/yUYuAgADuuOMORo8eTWxsLD+eDkEOnsOmZybx6tUDMLpo+dfvBxn675Xc9c1Klicu56oeV+Gmt8/Y+8y8Fl379qS/+16rnkUWQnDp7XdjLixg47dfOLTv6d2nE58Tz4HMA2cParQw+VW48kM4uQ0WxEBy613QeDFRAfJ50XofBoqiKI0lpVwgpYyWUkYHBgbWf4GTlAfIrqZMjH37cOLECYq07vQJCSTAw1ClbcnpQvRB7ojGboRxDvdhQ9H6+5P93Xd1tsv9+WdM+/fT7p+Po3FtXlBel/ZdvOg+qB2xfydVbLtdF3NRESf376HroKGAPSD0m9ETodeQ9d1hZGntubdarZZLL72UG7oVkIUPC3bbSEtJ4oYhnfnlvpEse2g0Nw7tzJb037BKyc9rw3hv1VFS80z2ushz7qJ4506KNje+Esj5FBjahYGTr2DPij85c+yow/qd0mUKBq2BJfFLqp+MvBHu+AsQ8MlEWPtfsNVQOUQ5b1SAfD6o+FhRFMXh7AGyxFiai7ZLFxITT5Boduey/kFV2kkpKT1d0Kz0inJCp8Pv5pspXLceU1xcjW1KU1NJff2/uEZF4TV1arPvWZ9hV3bFZpVs+/14vW0T9+zEarHQffCwimNaLxd8r+lJaUoBOb8fq7uDoix6nfiKOX0K8fTy4quvvmL9+vVIKekT5MWTl3XDu/1O+vkMJ8w7hDeWH2Hka6t46NvdnBoxEV2HDq1+FhlgxLU34u7tw8pPP3TYgj1PF0/Gh45n6fGlmK01/DLTcSDcvR76XQmrX4aFl0OG4wJ0pXGcGiALISYLIQ4LIeKFEE/WcP4mIcTeso9NQoiISucShRD7hBCxQoi2+X5DK38AKIqitGV5GSZcKcK1S2dOpqZitVo4ZfNmyoCqG2VYs81IkxV9x6bvYFeZ7403oHF3J2P+/6qdkzYbp5/5P6TZTNArL1epw+ws3oFu9B/TiUMbTpF1urDOtvHbt+Dq5U3Hnr2rHHft54/HmGAKt56hcFdq7R3s+gIsxfiPmcOdd95Jv379WLlyJT/88ANms5k/Ev4g15zDY8Pu5Ju7hrH28Rhmjwhj5aE0pv5vG7/0m0Dx7t0UrK87RaWlGdzcuWTW7Q5fsHdl9yvJL8lnVdKqmhu4+sA1n8BV/4O0g/DhCFj7OlhKHDYGpWGcFiALIbTA+8AUoC9wgxCi7znNjgNjpJThwEvAgnPOj5VSRkopo501TkVRFOUsIcQiYDPQSwiRLIS4o6XHVJvcjGKMhekY+vTh2LFj2BAEdgwh2LdqpYrS081foFeZ1ssLv1tvJf/PP8n944+K41JKUl/5N4UbNtD+yScwnMct56MvC0Nv0LL559pngK2WUhJ2bafboCFoNNW3kvaeGIZLF29yfo6npKZA21oK2z+GsNHQoT8uLi5cc801TJgwgUOHDvHJJ5/wfez39PLtRXR7+4/tUH93/m9qXzY9NY5nLuvDr0FRpLr6sPHpl/l68/GaNyBpJaos2MvPc0ifQzoMoaN7R3488mPtjYSAiOvhvu32KherX4EPhsGh39XE23nkzBnkIUC8lDJBSlkCfAtU2eRcSrlJSpld9uUWINiJ41EURVHqIaW8QUoZJKXUSymDpZSftPSYapOXWogx7zSu4REcOnyUVKsHkwd0qtau5FQBCNB3cFwliYB77sZ14EDOPPsc2d9/T/HevaQ8/AjZX3+N32234XPddQ67V0O4ergQNTmUxL0ZpBzJrrHNyQP7KCkuqpJeUZnQCvxv7I0w6sj84gDWgnNmLff9ALknYfh9Z68RgpEjRzJr1iyycrLoFteN6T7Tq82cexn13HVJV1Y+NRHbbXMJzUhi+ftfM+K1Vbyz4mhF9YvWRAjBpXfcg7mwgA0OWrCnERpm9prJtjPbOJx1uO7Gnu3h2oVw04+g0cF3N9nTLo6vV4HyeeDMALkTcLLS18llx2pzB7Cs0tcSWC6E2CmEmOOE8SmKoihtlKXESlGBBaMpA2vPHmRnpnPK5s1lA4KqtS05mY+unRsal+qzpk0l9Ho6vf0Whj59OPPc8yTOvI6C1asJfOQR2v3z8fOSWnGuiHEhePgaat2COn77FnQGA50HRNbah9bThYBb+mLNLyXzq0NIS1n+rc0K69+E9v2hZ/Uy2V27diWuVxwWFwsJqxPYsGFDjWPQazWMvf8WDL178c+Tq4gOcuetFUcY8doqXvj1AMnZjdul0NkCO4cRNeUK9q78y2EL9mb0nIFRa+SbuG8adkGPCXDPJpj6FmTGw+dT7Qv54v5QC/mcyJkBck1Phxp/5RFCjMUeID9R6fBIKWUU9hSN+4QQl9RybasoN6QoiqKcP3mZJgDcSnM4URaIuQV2IsSvanqFlJLS5HwMnR23i105ffv2hH71JSGffEzw++/R7c9lBMyd0yLBMYDORcvQaV1JO5HPgfVVNw+RNhvHdmyhS8Qg9C6GWnqwcwnxxG9mT0oS88j+uSzYPvQbZB6F0Y/aUwDOsS55HXsK9jBk+hD69u3LihUr+PbbbyksrJ6qITQa2j32OJrU07ymP8pfD1/ClAEd+GrLCcb8dw2PfBfLodOOSWlwhOEzbnLogj1vgzdXdLuCPxL+INtU82x/NVodRN8OD+2Fy/8f5J+Bb2+EtwfAmtcgO7HZ41KqcmaAnAyEVPo6GKi23Y8QIhz4GJgupcwsPy6lPFX2ZxrwM/aUjWpaS7mhOql3QhRFURwqu2zjD58O7uw5dIR8mwsxkT2qtbNkmrAVWXAJ8XTKOIQQeIwcieell6Lv2NEp92iMXsM6ENLHl42L48lNPzsbe+roYQqys2pNrziXW3ggnpd2pmhnKgXrkmH9/wP/7tD3ymptpZR8sOcDgj2Cmd5rOjNmzGDy5MnEx8czf/58EhISql3jMWok7iNGkPHBh3R3tfHmzEjW/XMss0eE8deBM0x5Zz2zP9vGloTMFq94YXBz45KbbuNM/BEOrKtlcV0j3dTnJsxWc925yDXRG2HwnfDgLrjuKwjsbQ+Q34mABWNh4zuQfcIhY7zYOTNA3g70EEJ0EUK4ANcDv1ZuIIToDPwE3CylPFLpuLsQwrP8c2AisN+JY3UyFSEriqI4UlayfZcz7z6dOJmUyEmbT63pFQAunZ0TILc2QgjG3twHjUaw8vND2Gz2nz8H161EZzA0OEAG8Lq0M67hAeQuO05xijuMesS+scU51iWv42DmQeaEz0Gv0SOEYNiwYdx55524uLjwxRdf8Pvvv2Mymapc1+6fj2PNzyd93rsAdPRx5dmpfdn85KU8NrEn+5JzuX7BFq78YBN/7j+N1dZyP0v7jIohqEcv1n+zEHNR89NAuvl0Y3jQcL49/C2lttLGd6DVQ58r4Oaf4OG9MOEl+/G/n4N3wuF/Y2DdG5B+pO5+lFo5LUCWUlqA+4G/gEPA91LKA0KIu4UQd5c1ew7wBz44p5xbe2CDEGIPsA34Q0r5p7PGqiiKorQt6YfPYCxOJ7tLZ7BZMQYEE+pffRFeSVIewkWLrp1bDb1cmDz9jIy+rgen43OJ/TsJS0kJhzevp8eQEbi4Nvz7IDQC36u742I4SWbpPzF7TqnWxmqzMm/3PDp5dGJqt6o1n4OCgpg7dy7Dhg1j586dvP/++xw4cKBiRtjYuze+N9xA9qJFFB84u7uct5ue+8f1YOOT43j5yv7kFJVw91e7mPDmWhZtS2qRyhdCo2Hc7LkU5eWy5advHdLnrL6zSCtK48/jzQxvfDrDyAdhzmp4MBbGv2hf1LfqJXh/MLw3BFa+BKkH6u1KOcupdZCllEullD2llN2klK+UHZsvpZxf9vmdUkrfslJuFeXcyipfRJR99Cu/ts1RE8eKoihOkZWSj0fhaWJLrJillolDB9TYriQpH5dgj2bvoNfW9BragW4DA9nySwLbfluFubCQvpeMa3Q/miM/488T6Lwg46vDlJ6pmlP8U/xPHMk+wiODHkGv0Ve73sXFhcmTJ3PnnXfi5ubGDz/8wMcff0xiYiIAgQ89iNbXl9R/vVQtv9eo1zJrWCir/hHD+zdG4W7Q8dRP+xj9+mo+WBNPbnETZl6boUP3nvSPmcCupb+QmXKy/gvqMarTKHr59mLB3gVYHbXYzq8LjHoY7loJjx6Cy96wV8PY8Ja9pvKCGHupPnOBY+53AVM76Z0PKlBWFEVxGKvFRl6RDneXIk4kJ5Es/bgisnqVUFtRKaWnCjB09W6BUbYsIQTjbu2DT3s3tv+yFDdvPzr3D29cJ6UmWPkvtB27EnD3cDQuWtI/2Y8ly54qkV+Sz3u73yOqXRQTQyfW2VWnTp2YM2cO06ZNIy8vj4ULF7Jw4ULiT58m8LF/ULxnD7k//1zjtVqN4PLwIH69fyTf3DmU3h08ef3Pw4x87f+zd9/xcV1lwsd/z73TNerVRXLvduw4jtNJI50kZAmQQgmwQBYCWWCXXpeXuvS2oSSBDUtCCAGSkN57XOLemyzJtnqdPnfuef+4I1llVGx1+3zzUayZueXckXT06NznPOdZvv3oDmrbYhn3Gw3n3fg+XB4vz//ht8POjTbE4Nblt1LZXsmjBx4doRZ2kzMVVn8Y3v8w/MduuPx7Ti3rf34GfrwEnvkv6BhgUZiTnA6QNU3TtEml9UgHSgysGT7EtiiumEuuv+/oZfxAGyjwzs0b+0ZOAB6fiwvfU4EVP4Ct5tPekGF544Gs+bVT9/iSb+Iq8FP0oaWopE3jXVtJdST4zebf0BJr4XOrPzekyh2mabJy5Uo++clPcumll9Lc3My9997LH2tq2PvWi9n/s5+TrKvvd38R4ey5RdzzoTN45BPnctHCEn730n7O+/6zfPaBTeytH/1R0UBuHme/8yYqN73J/jfXDPt4F1VcxIL8Bfxy4y9JpEaxFnRWEZx5K9z6MnzoKZh1nlO276fLnUA51jZ6556kdICsaZqmTSq1a5wFFioDiqhycf0FKzNuF9/XhrgNPNNPjgl6mRze+QagcAeW8OAP1lN/cIjl08JN8OIPYd6lMPt8ANylWRTdsphUe5zD/7OexzY/wtvnvp3Fhb0XyR2Y2+3m7LPP5vbbb+cd73gHgUCA9UVFPHTB+dz5kx+zfv36jOXhuls6LZef3XgqL/znhdy4uoJ/bDzMJT9+gVvvWc+m6tZjas+xWnHZ2yiYVs7zf/gdVnJ4aR6GGHx61ac5FDrEvTvvHaEWDkAEylc7FTA+sd5Zqe+lH8JPV8C6u2AEytidKHSArGmapk0qdZsOoojRnArR4inlrDlFGbeL7WvFMzMHcZ2cv+qUUmx++nHK5s7nnV+4FNNt8OB/v8nWFw+hBqsI8fjnIBk5Wh0hzTszl8IPLiHeFuF7lbdz26xb+znA4EzTZNmyZXzoQx/ik5/8JGcWFBKOx3n44Yf5wQ9+wJ133slLL71EXV1dv+kM5QUB/uvapbzy+Yu47cK5vLqvkWt/+Qo3/fZ1XtrTMCol4kyXiwtv+QitdUdY9/CDwz7e2VPP5pxp5/DrTb+mMdo4Ai0cosI5cP2d8JHnoWQxPPIpuPsKqN85dm2YwE7OXmOM2XpJSE3TtBFTdyiG8lRioFh12sqMt/dT7XGsugjeOXlj38AJ4uCWjTQfruHUy95GflkW7/rC6UyZm8sLf9rF3374Jk2H+klJ2PWYs6z0W/4DShb2efmv0X/y2fIfUSj5WHdVEdvXOuy2FhQUcNknbuMdLS1c+sKLnLNiBZZl8cwzz/A///M//OQnP+GRRx5h+/btRKPRPvsXBb185tIFvPqFi/nSlYvY1xDivXeu4epfvMw/N498ibiZp5zK/DPO4fW/3ktTTdWwj/f50z9PLBXj+2u+PwKtO0ZTT4VbHoFrfwWNu+COc+HVX5z0o8k6QB4DyZQOkDVN00ZCoraeFqOQtuwWmsnipguXZ9wuut1Zd8q/qGAsmzehbHj8YQK5ecw/6zwA/NkervnkCi5870JaaiP8+Vtreeb323sGytFWZySxZAmc++k+x6xqr+In639C2dwZTP3YKgy/i8Y7t9DxYs2wR2vFMJj27W9TGAox+w9/4MPvfz+f/vSnufrqqykrK2PTpk3cf//9fP/73+e3v/0tzzzzDJWVlViW1XWMoNfFh98ymxc/eyHfe8cyIvEUH//Tm1z8w+e5b00VcWvkSsRd/KF/w+MP8PivfoydGt5xZ+bO5MOnfJjHKh/j2aqRWYzkmIjAqTfDx9fC/MvgyS/Bn94Jof5zwk90Mt4r1IykVatWqXXr1g2+4RiJV7XT8KtNxFHM+W7GlbI1TTtJicj6ztKWk9lY97v77/obD22A1sJNeGefzhfed1XG7Rru3EKqJU7pZ07rGmF+48gbPLjnQTY1bKIl1kJxoJgzp5zJ9fOvZ2FB35HSyaypporff+ZjnPmOGznnXTf3eT0WSrL20QNsf/kwVsKmYkkBS8+fzoz9X8PY9Cf412dgWs/cbsu2+NATH2JPyx7+du3fKM0qxY5ZtPxlN9FtTXhn55J3zRzcZX3rUR+Ljuefp+bfPkbuNVcz5bvf7fr6WZbFoUOH2LdvH/v37+fQoUMopXC73cyYMYPZs2dTUVFBWVkZLpcLgJSteGJbLf/z/D62HGqjLMfHv543i5vOqCDgcQ2rnQC7XnuJR37yPc698f2c8fZ3DutYyVSSmx+9mcPhw/z16r9SmlU67PYdF6Vg3Z3wxJfAlwc3/B9Mn/RdVZeh9r06QB5FoQOttP56iw6QNU3rQwfIx+fFW3/Ay3leQt5WPnH7vzOloO8EPDtqcfibrxM8dxp5V86iNlzLN177Bi8fepkcTw5nTz2bIn8Rh0KHeO3wa8RTcd4+9+189vTPEvQEx+xaRtNjv/wRu994hQ//4i4COf2XuYuFkmx5oYatLx4i0pYgaNSzZFGERe+7maxcb49tf7T+R9y99W6+fe63uXrO1V3PK6UIr6ml7bFKVNzCv6SQwMpSfAvyEfP4blQ3/PKXNP78F5R+6UsUvPc9mdsei1FZWdkVMDc1OXcNTNNk6tSplJeXU15eztSpU8nOzublvU386vm9vL6/mfyAm1vOnsX7z55BXsBzXG3s9PCPvsO+9W/w7m98jylzFwzrWAfaDvDuR97N/Pz53HnZnXhN7+A7jZbarXDfTdBRC1f/FFbcOH5tGUE6QJ4AGnc3E7trG3EUZd84myzv8P9a1TTtxKAD5GNnNTVx322/Ze+CGMaUxXz1o+/KuF34zTpa7t9N8a2n8KZnO5998bMkUgk+tuJj3LDwhh5BR3uind9u/i33bL+HqcGp/OzCnzE3f+6YXM9oaa2r5e5PfZQVl72NC9//4SHtkzq0hcpffZmtybdT0z4DwxBmrShm6fnTmDY/j6ernubTz3+ady94N18+88uZjxFOEnqphvDaWuywhZHlwjsrF095Du5pQdwlAYxs95BKwinbpua2TxB64QWm//znZF904aD7tLe3U1NTQ3V1NdXV1Rw5coRUOvUhEAhQVlZGWVkZMXcOj+6N8MS+CAGPixtXV/Des2ZkXIlxKKId7fzxC5/CTlm85zs/ISsv/7iO0+mpg0/x6ec/zRWzruA7534HM8Py3mMm0gx/eT8ceBHO/Dhc8l9gTu5YRgfIE0DNtga4ZycJFKlPncq80pO31JCmaT3pAPnYNf7+D9y5rZVIoJWP3nY7U4vzMm5X/+vNpNrjrLuulq+++lVm5s7kxxf8mJm5M/s99pt1b/KZFz5D0k7yq4t/xSnFx7ioxgTy6M9/wJ41r/Ghn/6GYEHh4Dt01MJvLwZlw4efpTWay9aXDrHz1SPEIxZZxS6ez/479vwW7rz6N7jNvjWnu1Mpm9iuFqKbG4hXdZBqPrqQh3hNXMV+3MUBXMV+XMUBPBXZuHL7jpSmQmGqPvAB4rt2Uf6bX5N15pnH9D5YlsWRI0e6Pmpra6mvr+8Kmk2Xi7grm31hN022n5nTp3H9uYu5eMk0zGNcebG+cj/3fvU/KZkxm3d97duYroHfo8H8bsvv+OmbP+W6udfxtbO+Nr5BcioJT34Z3rgD5lwE198N/rzxa88w6QB5Ati7sRbffXtIojj4gYVcsKBkvJukadoEoQPkY/fPG29j7YIi/Lnz+dynbsq4TbIxSt0P1nHwtHZujXyeM6acwU8u+MmQUieqO6r5yJMfoSnWxE8u+AlnTzt7pC9h1NVX7ueez9/O6mvewXk33TL4DpFm+P1V0HIQPvgYTDk66dFKpFj7ym6efmwdBe3TMN3CvNPLWHreNEpn5Qy5TalQguSRMFZDlGRDBKshitUQJdV2dOESM9+Ld3Ye/sUFeOflY3icgNBqaaHqfe8ncegQM+66E/+KFUM+b8a2pFI0NDRQW1tLbW2tEzzX1pKIO22xFUQMPzn5xSyeU8Hy+TOYMmUKweDg3z+d+ciLzr2Ayz/+KYxhBrW/3PhL7th0BxeUX8D3zvseAXdgWMcbtjf/15nAWTAHbvqzs6z1JDTUvndyj5NPcNFECl/680OtfcvSaJqmaUPT/Orr7JxSgNguPtTPxDyA8JpalCi+2PYd3jLrLfz4gh/jMYeWY1qeXc49V97DR5/6KLc9exs/PP+HXFgx+K39iULZNs/cdQf+YDanX3P94DuEGuCP/wJN++Dm+3sExwAtVjPfbPkMrae28tNlvya0yc3uNXXsfPUIZbNzOfWSCmYuL8IYZLTVDHow53lgXs/UAzuRwqqLED/YTqKyjei2JiLr68Bl4Jubh39JIb7FhZTf+TsOvue9HPzgh5j2ox+SfcEFx/rWHG2LaXalWnRSStHa2sqhI7W8tmUveypraG+qZWtzFVvXvgyA2xdg2tQypk2Z0rV/YWEhhnE0x3rBWefRWnuEl+/7XwzTxaUf/QSGefxB8sdXfJx8bz7fW/s93vXIu/j2ud8e3zsbK98H+bPg/vfCby9yJu/NmHx/RA6VHkEeRWtfrWbKQ5UkUdz3lmK+cOWi8W6SpmkThB5BPjZ/uuWj7J45hSLXYm77cubc41Q4SfV3XuUV/wbeOGs/Pzj/B0MOjrtri7fxb0//GzuadvC9t3yPS2deOtzmj4mtzz3FE3f8lEtv/STLLhykzQ27nAlYbYecVdXmvbXHy7XhWm596lYOhw/z20t/y/JiJ3iORy12vnaETc9U09EUI7fEz4q3VrDwzDJcnuGNmKqUTfxAO7HtTUS3N5FqjYPg5DHP9NL8228R27aesq9+hfwbbhjWuQbTEk7wyIaDvLZ1HzWHj5BthykwIuQbUQycuMkwXRSXlDB96tGgubS0lHX/eIDXHvgTs05dxZWf+A98WcOb+Lm2di1feOkL1EfquXbutXxw6QeZlTuOo7dN++BP73LuOlzzM1iR+W7ORKVTLCaAl54/wKzHa7BQfLrC5MGPnTPeTdI0bYLQAfLQPXrfo7y55TVE5XPdVTew+JypGbd7/p6/MXtbAf979rN87qovD5orO5BQIsS/Pf1vbGncwrfO/RZXze5/1HoiaKuv438/+wmKZ8zk3V/7LmIMUD1iywPw0CfBE3CC44qeub1bGrZw+3O3E06G+flFP2f1lNV9DmGnbPZvbGTDkwepP9iBL+hm2fnTWHr+dAI5w6sKAc6obvJwmOjWRqJbG7EanLuwymogvvN5/MumUPrFT+DKHv2qI7FkivUHW3jzYAubqpvZV30EI9pGgRGhQCIUmhE8HK2D7A3mkmVAeN8Osn1uLr35A8xfObwf9Y5EB7/e9Gv+tPNPJO0k5007j+vnX89ZU8/C7/IP9xKPXbQF7n+fM3nvnH+Hi78K45knfQx0gDwBPPXUPhY9c5gUcJHRwcavXkK2r2eHXbtvD82Hqll4zvnDuhWjadrkogPkodmwr46nfvF9osEcSmNn8K/fvgSXu2dfqZTizpd/zfmPzqGmrJnzPvEOXEbfDML2xnr2r19Lw8EDJGJR/Nk5lMyaw+yVp2cshRZJRvjYMx/jzbo3+cbZ3+C6edeN2nUOh5VM8pf/+iKN1ZW87/s/J7ekLPOG4UZ4+muw4Y9Qfia8827IOfrHhlKKf+z7B//v9f9Hkb+In1/0c+blzxvw3EopjuxtZcNT1VRubsQwhJnLi1h09hTKFxdgHmeZt96S9RGiWxqJbm0geSTinDvRjndePsGz5+Kdm4+ZNbyJcUOllOJQa5Q99SEONISpbAxRXddES2M9RFvJFydwzjYSR3eyFe6cQsrKZ7BwVjmL5s4kPz9/SBU9umuKNnH/rvu5b9d9NMea8Zk+zpx6JqvLVrOydCUL8hdk/N4fFakkPPqfsP5umHkevON3kN3P994EogPkCeDhR3dz6ot1KIHzVDt3vn8VFy8qJZFIcP/999Pe2EB07YtgJVl97fVDm1ChadoJQQfIg9ta08L9P/4xRlDIaV3KuZesYvXbet5ajiQjfO2Vr3HeS/NYGptH+X+ciTu/54haY/VBXr7vf9m37g0AfNk5+LKyCLe2koxFMUwXSy64mNXXvpO80p6/4KNWlE8++0leP/I6H1j6AW4/9fbxrSjQi1KKJ+74Kduef5qrbv8sC8/OUHPfSjhBzHPfgkQYzroNLvoydBthr26v5puvf5PXjrzGaaWn8aMLfkSB79hWIWypDbP95cPsfL2WWCiJN+Bi5rIiZiwtZMrcPIL5I1PT12qN0fH0Jtqf3IARnIl4nPJs7mlBfHPz8M7NwzszB3GP/dcplkxR1RyhsjHM/toWqqqqUHvWEIg2oLw+Ul7/0YVPTB++/FJmzKjgjGULmFsxtUdO80CSdpJ1tet4rvo5Xqx5kUOhQwAEXAGWFy9nZelKTis9jVOKTxn9Wsob/wT//Ax4suCaX8CCy0f3fMOkA+QJ4C//2MFZrzWCwMVmiJvPmMFXr17M+vXrefjhhwHINRQzfSaVG9/kgz+5o/+//DVNO6HoAHlgz+84zMN/+D3ZvgRFbaX4ZAk3f+NM/NlHb9/XdNRw+3O3s3r3fG5uvJLca+eQfdbREdH2xnpevf9PbH/xWdw+HyuvvJbF511AXtlURASlFPWV+9nyzBNsfe5JbNtm6QVv5ex3vYdg/tHgMJlK8t013+X+3fdzztRz+N5bvkeut//FN8aKUornfv8bNjz+cOYV8yLNTmD8xm8gVAuzL4QrvgfFRxezqOmo4Y87/sgDux/Abbi5feXtvHP+O4f1R0DKsqna1sT+jQ0c2NxIPOwsBZ1T5GPKnDyKK7IpmJpFwdQsAjmeYx5FTaVs2huiNB9s5vAjLxHd14Q/Zxq5wQLyTANDhJRStCG0u03ieV485UHySrPIKwmQVxYgmOdFjrGU23BEQx28/tDf2PzsE8QTCVJZOURyirE9Pjrj+CQuVLCI0qnTOWXhXM5cMge/d2ij4rXhWjbUb2B93Xo21G9gT8seFAqP4eGU4lNYVbaKVaWrWF68HJ/LN/gBj1X9TnjgA1C/HRa/HS7/LuRMGfnzjAAdIE8A//eHNzh/RwIEPjfHTUNHnCc/dT533303Ryr34w230xHM55Lzz2fdXb9g7ulnctUn/7PPcbY3beexA49R2VZJni+Pi8ov4rzp543dbRRN00acDpAzC8ctfvzQGjo2Po3flWJmnUGY87j4lkUsPNP5hZu0k9y/635+tv5nXNt0Ae878jYCp5WSf/08RIRoRztr/vEAGx5/GJRixeVXc8bb34k/u//SZKHmJtY89ACbnnwM0+Vi1dX/wqqrr8PjOzoa/Zfdf+Hbb3ybPG8en1v9OS6bcdkxB3cjJRGN8MT//JTdb7zCaW+7jvPf80GnLdFW2PMUbHsQ9j4NqYQTGJ99G8y5GERoi7fx0qGXePrg0zxX/RwGBlfOvpLbV95OSWBky5HaKZvGmhBH9rZxeG8rR/a2Eu1Idr3uzXKRU+gnK89Ldr6XQJ4Xj890JvwpSMZTJOMWoZY4Hc0x2hqitDfGUPbR2MWf5SKQbMZ7aCfuRITckmnklFSQZQbxObE5SaVoshQNlqIxaRMxDfLKAuSVBsgvdYLmnCI/2fk+J2gfpeDZtlMc3rWDPW+8SvX2LdRXVaJcHlJZ2SRyikh6A5guZxTZUkLMk0uwoJTZM2dw5rJ5zJtWNKTvubZ4GxvqN7Cudh1r69ays3kntrJxG26WFS3jtNLTWFm6kuXFy8n2jNAaDVYCXv0pvPDfYHrgjI/Cmf8GWUUjc/wRMiECZBG5HPgpYAK/U0p9t9frkn79SiAC3KKUenMo+2YykQJkZVmsefcnmTbPWZrx2TPcfPWNJv558zz+8tc/4ak/xKmbNnPglJXUl5SQm4wT6WjlinfdyMrzzgecW14/3fBTnqh8ArfhZlbuLOoidbTF25gWnMZ7F7+X6+ZeN/61ETVNO2YTNUA+1r53pPrd1kiCPz6/hU1rXmeqqscXjzOvzkOd9wLmrSrhkg8tIWpFeezAY9y97W7am1v4YvtHWVo3C//SQgpuXEhHSxPr//l3Nj/zOFYiwZJzz+fsS84jx2iH9sPOxKJoixM0KhunREIQvNkQKILc6bQmfLz0z6fZveY1svLyWXHZ2zjl4ssI5OYBsKNpB1979WvsaN7B0sKlvH/p+7mo/KLjqpZxPJRts/uNV3nhj3cSamrivGuuYNWSQqR2E1S+DLWbsZVNLHsqsUVX0jz/Emr9QQ6HDrOzeSc7mnaws3knlrIo9BVyzdxruGnhTZRljc3dS6UUkfYEzUfCNB8O03IkTKglTqglRqglTjxiZdzPF3STXeAjp9BHXjqgzSsNkFcSwJfOPU6FwrT/85+0/f3vRDdtAtvGKJqCf9mFuMqWYNsFEHeGa21DiLoM2pI27VGLqK1I2DhT7UTwB90Est0Estz4/S58fhOvx8TjMnC7BJdpOIGsKYghiEsQvwsz4MYIuDGyXM6/ATdi9h/QxsIhjuzeyeHdO6g7sI+6/XsJhcOk/EFS/iDJYC7K4+0KimO2C3zZ5BeVML2igvmzZrB4ZilZg4w0dyQ6jgbMtWvZ0byDlEohCHPz57KieAULCxYyN28uc/LmDO8OSdM+eOYbsP0hcPth+Q2w9HqoOAuGmEIymsY9QBYRE9gNXALUAGuBG5VS27ttcyXwCZwA+Qzgp0qpM4aybybjESArpUhZNlbcJplIkUo6/zb84f+IvLiZspVOgFy94x5eI5/CnDYOzCkjf+82Ll9+Me4ppazdsYlDkQ7as7PAMMjzu2mvSPFi+4skvAnevfzdvHfJe8nx5JCMtfHCzgf4/d4H2BSuIVdcvNsOcFNrO4WxNkjGnI7fEwB3+sOXA77cDB954O3nNU8WjNPIiKadDCZigHw8fe/x9LtKKQ63Rth64Ag7Kw+zv7IK1XqIAiOKkUoxZ+8+VpeVsaH4najsFOqiQ7x45AV21GxjVngKV8TP54zmJRi2YCy0OJJaw56t2zl8qAmARWUpVhdWU5iq7ntyw+380hYBpSARSgfLPR1WFbxSP52qZhPTEGbNmcKMRYsoX76anJkLeeTIi/xm82+oCdXgd/k5e+rZnD31bOblz2NmzkzyfUNbbtiyLaJWlEgyQtgKE0lGCMU7CEcbCIcbCEebCHU0ET7SQPxgC3IggRkWYsEkVQtqacqLETOEqBjETDdxQ4irVMZz5XhyWFS4iFOKTuH88vNZVrQMQ8Y/YOnOSqa6fp+KgMtj4vaYmO5ja6fV0kL4pZeIrFtPdPNm4nv2QCqF+PMxixbiKpmHWVCB+IoR89irQNjp2MkYyu9Jn4kRcGMGO4Pn9EfQCaQl4MbwmuAywGMSCbXRePgADdUHaKjeT3PtYVo6OrA8PlKBIClvAOXpllds22DZGEpw4cZjevF5AmT5ggQDQbID2WQHcsjxB8kOZOF3ubGsOI2hOhpCtTR3NNISaQZL4VYu3MpF0AgSNLLwml5MjwuX14PpNjHdLkyXgcvnxZsVwJvjxx/MwhcM4gl4MfwuDJ8LcRlOKcGXfwLb/gZWFIJlMOstMP10mHqqs9BIoHDMY42JECCfBXxdKXVZ+vEXAJRS3+m2za+B55VS96Yf7wIuAGYOtm8mx9pRH9zaRNX2JlRKYStQtsK2lfNvSqHU0c9Tlp2+1XP0w0r/m+kttKJvUOBSXFh8HgD31/6TWL6bRLZghtvJbZ6H6e1ZF9lWrYTM50jkBXt98ysMS2EmbVwpE7c4Ha8CUgjuaDYuy4sJCIKgQCAWNBCU81jZgA1K4VY2RVYSxDmKpGs6Ov92fo5TssUwnL9cxXDKBonh/AUogojzWETAEGcf0wUFc45+v0v6WOknOp93jsnRc6X/J9J3n65Pxbm+o693O27vc3X7vOsomV6faCZgo2RiNmpCWXTOFAqnHlu5qQkaIA/ab/d2rP1uYyjOf/z37yinEVOc/kYBRlYBiza8iDtykJdPUxQFz2NmeBYB20uW7aciVkoA525ZSiU4HNnKlua1dFitABR7Q8zNaWVJuUFu6VTInwF5M9P/VkDONAgUOIMG3X8hdwbJ4QZoq3HqArdVQ2sVtB6k6fAhNlXB3vYCOiwnd9PAJseTIOBRhL0GTW7FEVeKiNgoca7HFHAjuMXodTpFSilSKCxF1+8PUen+W4FhC25L8FgGwYiLrLgr/T4pWvJj1FeEiU6x8fuC+Pz5+P1F+LKK8bkD+Fw+/KYfn8uH1/SS78unLKuMKVlTKA2UjltKyHizYzGS1dUkqqtJHKwiUXWQVGMjVmMTVksrdkcSZRlguBDTDSqFSllgJ1F2iqThJpFdgBXIJx7IIeHOIe7OJm4GiZsBkuJHiR/DcOERwSPgTf/rMY5+7jU6X2PQr4WtFJ1/unWFGUohAhYp2owwzUaINonS0e0jKZn/QAIQJbgxcWE6v0KR7gc/uqHq/jj9uzkdYQxEuv7j6Dd3r3+l83s+fQrp2s9I/wwkSFp1WKkwoDADBTSXLU3/7u4MBoSps+bxkSv6liAczERYSW8a0P3P9xqcUeLBtpk2xH0BEJGPAB9JPwylg+yJpghoHO9GjDB9TZODvqaJa8Z4NyCDIfW9Q+h3h/c1+gfA+uPeHTYMZaPJ8n2k2zlyJkMbYXK0c0K08aODb5KpnUPqe0czQM70Z0bvsdb+thnKvs6TSv0G+M2xNW1sici6iTZSNFz6miYHfU3aMRpS3ztYvzsZvkaToY2g2zmSJkMbYXK0czK0EYbXztEMkGuA8m6PpwOHh7iNZwj7apqmaSNrKP22pmnaCW80s/PXAvNEZJaIeIAbgId6bfMQ8D5xnAm0KaWODHFfTdM0bWTpvlfTNI1RHEFWSlkichvwBE65oLuUUttE5Nb063cAj+JUsNiLU+btAwPtO1ptHQMTOgXkOOlrmhz0NWlDNoJ972T4Gk2GNoJu50iaDG2EydHOydBGGEY7T6iFQjRN0zRN0zRtuCZWAURN0zRN0zRNG2c6QNY0TdM0TdO0bnSAPIpE5HIR2SUie0Xk8+PdnqESkXIReU5EdojINhG5Pf18gYg8JSJ70v/md9vnC+nr3CUil41f6wcmIqaIbBCRR9KPJ/U1iUieiDwgIjvTX6+zToBr+lT6+26riNwrIr7Jfk0nuoG+Pt22ydivjEHbBuyH05PEf5Z+fbOIrByLdh1HO29Ot2+ziLwqIssnWhu7bXe6iKRE5PqxbF+38w/aThG5QEQ2pr8XX5hobRSRXBF5WEQ2pdv4gXFo410iUi8iW/t5faL87AzWzuP72VFK6Y9R+MCZ4LIPmI1Ttm4TsHi82zXEtk8BVqY/z8ZZenYx8H3g8+nnPw98L/354vT1eYFZ6es2x/s6+rm2TwN/Ah5JP57U1wT8AfjX9OceIG8yXxPOQhUHAH/68f3ALZP5mk6Gj/6+Pr22ydivjHK7Bu2HcSaKP4ZTA/pM4I1xeP+G0s6zgfz051eMdTuH+jstvd2zOJPwr5+g72UesB2oSD8umYBt/GK3fq4YaAY8Y9zOtwArga39vD7uPztDbOdx/ezoEeTRsxrYq5Tar5RKAPcB145zm4ZEKXVEKfVm+vMOYAdO4HItTkBG+t+3pz+/FrhPKRVXSh3AqUpy7Os/jjIRmQ5cBfyu29OT9ppEJAenY7gTQCmVUEq1MomvKc0F+EXEBQRw6vBO9ms60fX39ekyQL8ymobSD18L/K9yvA7kiciUUW7XMbdTKfWqUqol/fB1nBrVE6qNaZ8A/grUj2XjuhlKO28CHlRKVQEopca6rUNpowKyRUSAIE6AbI1lI5VSL6bP25+J8LMzaDuP92dHB8ijp79ltCcVEZkJnAq8AZQqp0416X9L0ptNlmv9CfBZ6FreHib3Nc0GGoC702kjvxORLCbxNSmlDgE/AKqAIzi10Z9kEl/TSaK/r09GvfqV0TSU74+J8D10rG34EM7I3VgatI0iMg24DrhjDNvV21Dey/lAvog8LyLrReR9Y9Y6x1Da+AtgEc4AwRbgdqWUzcQyEX52jtWQf3ZGcyW9k92Ql8ueqEQkiDMS8O9KqXbnD9nMm2Z4bkJdq4i8DahXSq0XkQuGskuG5ybUNeH8/K4EPqGUekNEfopze7s/E/6a0rmr1+KkS7QCfxGR9wy0S4bnJtQ1nShE5GmgLMNLXzrG4/ToV0aibQOdLsNzvb8/JsL30JDbICIX4vySP3dUW5Th1Bme693GnwCfU0qlBvh9MdqG0k4XcBpwMeAHXhOR15VSu0e7cWlDaeNlwEbgImAO8JSIvDQGPzPHYiL87AzZsf7s6AB59EzqJVtFxI3zS+z/lFIPpp+uE5EpSqkj6dsonbelJsO1ngNcIyJXAj4gR0T+yOS+phqgRinVOQr3AE6APJmv6a3AAaVUA4CIPIiTPzaZr+mEoJR6a3+viUh/X5/e22XqV0bTUL4/JsL30JDaICKn4KSIXaGUahqjtnUaShtXAfelg+Mi4EoRsZRSfx+TFjqG+jVvVEqFgbCIvAgsx8mLHwtDaeMHgO8qJ3F2r4gcABYCa8amiUMyEX52huR4fnZ0isXombRLtqZznu4EdiilftTtpYeA96c/fz/wj27P3yAiXhGZBcxjYv0Qo5T6glJqulJqJs7X4lml1HuY3NdUC1SLyIL0UxfjTDyZtNeEk1pxpogE0t+HF+Pkqk7mazoZ9Pf16TJAvzKahtIPPwS8Lz0j/0yctJ4jY9S+IbdTRCqAB4H3juFI5zG1USk1Syk1M93PPgB8bIyD4yG1E+f78zwRcYlIADgDp5+ZSG2swun/EJFSYAGwfwzbOBQT4WdnUMf9s3O8swb1x5BmVl6J8xfpPuBL492eY2j3uTi3STbj3OLZmL6WQuAZYE/634Ju+3wpfZ27cP5CG/frGOD6LuBoFYtJfU3ACmBd+mv1dyD/BLimbwA7ga3APTgVKib1NZ3oH/19fYCpwKPpzzP2K2PQtj79MHArcGv6cwF+mX59C7BqnN7Dwdr5O6Cl23u3bqK1sde2v2ccqlgMtZ3Af+IMKGzFSfeZUG1M/+w8mf6e3Aq8ZxzaeC/OXJAkzmjxhyboz85g7Tyunx291LSmaZqmaZqmdaNTLDRN0zRN0zStGx0ga5qmaZqmaVo3OkDWNE3TNE3TtG50gKxpmqZpmqZp3egAWdM0TdM0TdO60QGypmmapmmapnWjA2RN0zRN0zRN60YHyJqmaZqmaZrWjQ6QNU3TNE3TNK0bHSBrmqZpmqZpWjc6QNY0TdM0TdO0bnSArGmapmmapmnd6ABZm/BE5BYReXkEj/d1EfnjMWyvRGRu+vM7ROQrI9SOChEJiYiZfvy8iPzrSBw7fbzHROT9I3U8TdMmPxGpFJG3ToB29OjX033h7BE69hdF5Hfpz2em+3DXCB27R7+tnbh0gKwN27EGnJOZUupWpdQ3B9tuKL+ElFJVSqmgUio13HZl+hoopa5QSv1huMfWNE0biIhcICI1wzlGui/cPxLnUUp9Wyk1IoMNvfvykey3tYlNB8jaCW2kRg1G2kRtl6Zpk5fuV/R7oI0cHSBrQyYinxORQyLSISK7RORiEbkc+CLw7vRtp03pbT8gIjvS2+4XkY92O84FIlIjIp8RkXoROSIiH+j2eqGIPCQi7SKyBpjTqx0/FZHq9OvrReS8bq99XUQeEJE/ikg7cIuIzBKRF9JteQooGuQ6/zPdpsMi8sFer/1eRP5f+vMiEXlERFpFpFlEXhIRQ0TuASqAh9PvyWe73eb7kIhUAc/2c+tvjoisEZE2EfmHiBR0f896taVSRN46wNegK2Uj3a4vi8jB9Hv+vyKSm36tsx3vF5EqEWkUkS8N9B5pmjYxpPuBz4nIZiAsIi4RuUZEtqX7pudFZFGv3U4Xke0i0iIid4uIL32sPuls0jPF7Mr0fh3p3wX/ISJZwGPA1HT/ExKRqRnaOVi/flzn6afPz3RX84PpPv2IiHym23m7+vT0466+dpC+3JXeZmr6uppFZK+IfLjbsb4uIven+9uO9Ndk1aBfVG1C0AGyNiQisgC4DThdKZUNXAZUKqUeB74N/Dl922l5epd64G1ADvAB4McisrLbIcuAXGAa8CHglyKSn37tl0AMmAJ8MP3R3VpgBVAA/An4S2cHn3Yt8ACQB/xfepv1OIHxN4F+83LTweZ/AJcA84CB0iQ+A9QAxUApTpCqlFLvBaqAq9Pvyfe77XM+sAjn/cvkfenrnQpYwM8GOD84J+zva9DdLemPC4HZQBD4Ra9tzgUWABcDX83wS1XTtInpRuAqnD5vNnAv8O84fdOjOAGep9v2N+P0QXOA+cCXh3ieO4GPpn8HLAWeVUqFgSuAw+n+J6iUOpxh38H69eGcp3efn8mFOH36pcDnZQh52IP05Z3uxfk9MBW4Hvi2iFzc7fVrgPvSbXuIvv2uNkHpAFkbqhTgBRaLiFspVamU2tffxkqpfyql9inHC8CTwHndNkkC/6WUSiqlHgVCwAJxJj68A/iqUiqslNoK/KHXsf+olGpSSllKqR+m27Wg2yavKaX+rpSycX5BnA58RSkVV0q9CDw8wHW+C7hbKbU13SF/fYBtkzid/Yz0dbyklFIDbA/w9fR1Rft5/Z5u5/4K8C4ZmckgNwM/UkrtV0qFgC8AN/Qavf6GUiqqlNoEbAIyBdqapk08P1NKVaf7lXcD/1RKPaWUSgI/APzA2d22/0V6+2bgWzgB9lAkcX4H5CilWpRSbw5lp6H068M8T1efP0Df+o30ubcAdzP0a+6XiJTjDCx8TikVU0ptBH4HvLfbZi8rpR5N5yzfg+5XJw0dIGtDopTaizMi8XWgXkTuy3QbrZOIXCEir6dvO7UCV9IztaFJKWV1exzBGdUsBlxAdbfXDvY69mfESd9oSx87t9exu+87FWhJB5wZj9fL1IHO3ct/A3uBJ8VJI/n8ANtmattgrx8E3AySEjJEU+l5LQdx3ufSbs/Vdvu88+uhadrE17vP6/pZTw8UVOPcrcu0/cH0PkPxDpy+/KA4aWtnDXG/Qfv1YZ5nsH619zbHcs0DmQo0K6U6eh27+3vdu1/1ic6TnhR0gKwNmVLqT0qpc4EZgAK+1/lS9+1ExAv8FWfkolQplYdzm0+GcJoGnNSC8m7PVXQ79nnA53BGevPTx27rdezu7TkC5Kfz1/ocL4Mj/Z27N6VUh1LqM0qp2cDVwKe73VrrbyR5sBHm3udOAo1AGAh0vpAekSk+huMexvm6dT+2BdQNsp+maRNf95//Hj/rIiI4/cqhbtv07mc6UxV69zNlPU6i1Fql1LVACfB34P4M589kwH69t+M4z2DnJ8O5M14zTvrfUI99GCgQkexexz7Uz/baJKIDZG1IRGSBiFyUDn5jQBQn7QKcIGumiHR+P3lw0h4aAEtErsDJ+xpU+jbUg8DXRSQgIovpmTOcjdPRNgAuEfkqTp5zf8c7CKwDviEiHhE5FyeY7c/9OJM8FotIAPhafxuKyNtEZG76F1A7zvvR/T05npqe7+l27v8CHki/J7txRh6uEhE3Ts6gt9t+vb8Gvd0LfEqcCYtBjuYsW/1sr2na5HQ/cJU4k6jdOHMl4sCr3bb5uIhMF2cS8BeBP6ef3wQsEZEV6XkdX+/cId1/3iwiuenUjc4+D5z+p1DSE397G0K/3mU45xnEV9LnXoIzL6bzmjcCV4pIQfoPgn/vtV+/fblSqhrnff2OiPhE5BScOTX95UFrk4gOkLWh8gLfxRnNrMX5y/6L6df+kv63SUTeTN9u+iROR90C3IQzOWGobsO5vV8L/B4nX6zTEzgzmXfj3MqKMfjttZuAM4BmnID3f/vbUCn1GPAT4Fmc9IlnBzjuPOBpnPzp14BfKaWeT7/2HeDL4swi/49B2tfdPTjXXAv4cN5HlFJtwMdw8tsO4Yx6dK9q0eNrkOG4d6WP/SJwAOd9+8QxtEvTtElAKbULeA/wc5z++mqcSWaJbpv9CWdeyP70x/9L77sb5w/zp4E9QO8Fmt4LVKarRdyaPg9KqZ04f4TvT/d5mdIXBurXexvOefrzAk6f/gzwA6XUk+nn78H5w6AS5z35c6/9BuvLbwRm4owm/w34mlLqqWNolzZByeBzijRN0zRN0zTt5KFHkDVN0zRN0zStGx0ga5qmaZqmaVo3OkDWNE3TNE3TtG50gKxpmqZpmqZp3ZxQxaqLiorUzJkzx7sZmqZpg1q/fn2jUqp48C0nNt3vapo2mQy17z2hAuSZM2eybt268W6GpmnaoERkoJXEJg3d72qaNpkMte/VKRaapmmapmma1o0OkDVN0zRN0zStm3EJkEXkchHZJSJ7ReTzGV7PFZGHRWSTiGwTkQ+MRzs1TdM0TdO0k8+YB8giYgK/BK4AFgM3ptdl7+7jwHal1HLgAuCHIuIZ04ZqmqZpmqZpJ6XxGEFeDexVSu1Prw1/H3Btr20UkC0igrN2ezNgjW0zNU3TNE3TtJPReATI04Dqbo9r0s919wtgEXAY2ALcrpSyMx1MRD4iIutEZF1DQ8NotFfTNE3TNE07iYxHgCwZnlO9Hl8GbASmAiuAX4hITqaDKaV+o5RapZRaVVw86UuKnvBsW6FU7y+3pmmaNtpUMomyM441aZrWy3gEyDVAebfH03FGirv7APCgcuwFDgALx6h92ih66s5t/OHzr1B7oG28m6JpmnZSOfi+93Pg2rfrIFnThmA8AuS1wDwRmZWeeHcD8FCvbaqAiwFEpBRYAOwf01ZqIy6VtNm7vp5wW4IX79093s3RNE07aSiliG7YQHzPHpI1NePdHE2b8MY8QFZKWcBtwBPADuB+pdQ2EblVRG5Nb/ZN4GwR2QI8A3xOKdU41m3VRlbdwXYA8koDNB0KkUrqUQxN07SxkGpq6vrc0vN1NG1Q47LUtFLqUeDRXs/d0e3zw8ClY90ubXQd3t0CAssvLueFP+2i6XCIkhkZU8s1TdO0EZQ8dKjrc6u+fhxbommTg15JTxszR/a2UTg1SMXiAgDqD3aMc4s0TdNODsluQbEOkDVtcDpA1sZMW2OU/CkBsgt9eAMuGqp0gKxpmjYW7Paj/e1QUiwSMYvGmtBoNknTJjQdIGtjQilFqDlOdr4PEaGoPEjTId35apqmjQU7lA6QXS5SHYP3vWsePsCf/98aXvvbvlFumaZNTDpA1sZEtCNJyrIJFvgAyC7wEWqOjXOrNE3TTg6dQbG7tBQ7NHiAXLW9GYCNT1eRsvSEau3kowNkbUyEWpxgOJjvdf4t8BFuT5BK6Y5X0zRttNkd7RiBAGZu7qABcuW+g9Q1V5NfFsBOKZqPhMeolZo2cegAWRsTHenR4uxuI8goCLfEx7NZmqZpJ4VURwgjOxsjO5tUuP8Aubm5md/fczdt+VspX+X0143Ver6IdvLRAbI2JkLNTiDcGSB3jiR3jixrmqZpo8fu6MDIDmIEg9ih/keEt2/f3vV5mzqEy2vSUK3ni2gnHx0ga2OiozmGy2PgzXJKb3cGyh3NegRZ0zRttKU6OjCD2ZjBLOyO/keE9+/fT5YnD59VyL79eymeHtQjyNpJSQfI2pgINcfILnAqWAAE850AWY8ga5qmjT47GsHIysLICg6Yg1xXV4dPcsjxFtPS0kJWkUlbQ3QMW6ppE4MOkLUxEW5LkJXn7Xrs9pp4s1x6BFnTNG0MqGgM8fswgkFS4cwpFuFwmHA4jJEIkJ9dBIDlCRHRE6q1k5AOkLUxEQ0l8AfdPZ7Tpd40TdPGhh2NYvgDGH4fWBYqmeyzTUN6ARE75KWkuBSAOB3OhOpWPZihnVx0gKyNiVgoiS/o6fFcVq6XcJvudDVN00abHYti+HyI10lvs+N9+962tjbntYib/KIc/H4/8ZQz2qwrDmknGx0ga6POTtnEIxa+XiPI/hwP0Y6+oxiapmnayFKRKEbA74wgAyrW9+5da2srAGbKSzDfS0FBAeF4OwAhPYKsnWR0gKyNuljYAuiTYhHIdhPtSKCUGo9maZqmnRSUUtixGOLzHx1BjmUeQfZ5/QgmwXwfBQUFdIScUeWQni+inWR0gKyNumgoAdB3BDnbg51SxCPWeDRL0zTtpKCSSUilMPzdR5D7VqZoa2sj4A0CkJXnjCC3t7fj8gqhVj1fRDu5jEuALCKXi8guEdkrIp/P8Pp/isjG9MdWEUmJSMF4tFUbvljISaPoM4Kc4+QkRzsSY94mTTsZDaHvzRWRh0Vkk4hsE5EPjEc7tZGlok4wbPh9A44gh0IhPKbzuj/bTX5+PkopvPk2IZ2DrJ1kxjxAFhET+CVwBbAYuFFEFnffRin130qpFUqpFcAXgBeUUs1j3VZtZHTmGfeepOfPdh5H2nWArGmjbSh9L/BxYLtSajlwAfBDEfGgTWp2OkAWnx/D55TbzDSCHA6HMfFguAS316SgwBmXMrKSuoqFdtIZjxHk1cBepdR+pVQCuA+4doDtbwTuHZOWaaMiFk6PIGf3N4KsJ+pp2hgYSt+rgGxxVvQJAs2AzoGa5DoDZCPgR3x+57leI8hKKSKRCIby4MtyIyJdAbJyx4iGdD+tnVzGI0CeBlR3e1yTfq4PEQkAlwN/7e9gIvIREVknIus6azhqE0usMwc5q28OMugRZE0bI0Ppe38BLAIOA1uA25VSfVaI0P3u5NJZsUJ8vqMjyPGeOcWxWAzbtsFydaXDZWVl4Xa7sYxYv6lwoZdfIfzGmlFsvaaNj/EIkCXDc/2VMbgaeGWg9Aql1G+UUquUUquKi4tHpIHayIqGknh8Jqar57ebL+hGROcga9oYGUrfexmwEZgKrAB+ISI5fXbS/e6kotI1jw2vF/Glc5CjPQPkSCTifJI0uwYzRIScnBwsYiRjKaxEqsc+0S1bqf7Xf6Xq/e8nunnzKF+Fpo2t8QiQa4Dybo+n44xWZHIDOr1i0ot2JPtUsAAwDMEXdBPRAbKmjYWh9L0fAB5Ujr3AAWDhGLVPGyV2wuljxePBSAfIvUeQw+nlp+242aO/zsnJIZFyUjR6p1m03v/no5//5YGRb7imjaPxCJDXAvNEZFZ68scNwEO9NxKRXOB84B9j3D5thMXCfVfR6xTI8RDVKRaaNhaG0vdWARcDiEgpsADYP6at1EacSjiBrXg8R0eQY5lHkFNRo0c6XE5ODrGEEzz3vtsXevElsq+4nOxLLiH08suj1n5NGw+usT6hUsoSkduAJwATuEsptU1Ebk2/fkd60+uAJ5VS4bFuozay4uHMI8jg5CHrFAtNG31D7Hu/CfxeRLbgpGR8TinVOG6N1kaE6hxBdncbQY5lHkFOhqTPCHIkFsaP6jGhOllbi1VXR+DUlaBsOp56CquhAZdOudFOEGMeIAMopR4FHu313B29Hv8e+P3YtUobLfGoRW6xP+NrvqCbxmpdPkjTxsJgfa9S6jBw6Vi3SxtdKuH0sUMZQZaUu88IslIK20j0GMyIbnJyjv3LT3EWIgGi27aRfcEFo3YdmjaW9Ep62qhLRC08gX5GkLPcXSvtaZqmaSOvawTZ40YMA3G7M44gu11uBLPHok45Oc4cTduM9xhBjm7ehLjdeBctwjtvHgCJfTobRztxjMsIsnbyUMpZStrrz/yt5gu6iUcs7JSNYeq/1zRN00ZaZ4BseJy5IOL396mDHIlE8KVrJHuz+gbIuJM9RpBj27bjXbjQOabHg5mXR6KqajQvQ9PGlI5ItFFlJW3slMIb6C9A9oCCeESvRaBpmjYaulexAKfcW6YRZK/bSb/onYMMYASsHgFyYv9+vLNndz12z6ggcfDg6FyApo0DHSBroyoedgLf/gLkzlt5epUmTdO00dGVYuF1FgkRny9jDrLHlQ6Qu6XEBQIBTNNEPMmufjoVCmPV1+PpFiB7ZswgUaUDZO3EoQNkbVTFo06H6hkgxQIgpgNkTdO0UdG9zBuA4fP1GUF2VtJz+unu/bWIkJ2dje1KEAs7x0kcOOBsN3tW13aeihlYR2qx43rStXZi0AGyNqoSkYFHkHWArGmaNrpUrxQL8fmwey0U0hGOsOOwU+otpnousJidnY0t8a5+OlHpBMjeWd0C5BkzQCmS1dVo2olAB8jaqIpH0wGyv58qFl0pFrqShaZp2mhQiQS4XIjh/Mo3fD5Ut6WmlVIkEwnEdmGhuPfNnkFuMBgkqeJdI8jx/fvBNHFXVHRt4ymfDkCipma0L0fTxoQOkLVRFR9sBDk9W7qz49U0TdNGlkokukaPoXME+WgqxMHGdgTF9Nwgtkv4+4ZDPfYPBoMkUzHiUQvbViQOVOKePq2rKgaAq7QUAKuufpSvRtPGhg6QtVGVSI8g95eD7PKYuLymnqSnaZo2SlQigeE+ehfP8PWsYvHqziMA5Lh9eP1u9tSHqGqKdL2enZ1NMpVAKZt4JOlUsJh1dIIegKuoCAwDq65ulK9G08aGDpC1URWPOIFvf3WQwVksJK4DZE3TtFGhkr1HkP09qljsOtQMgAc32TnOdmsrm7teDwaDANhmgmhbnERlZY8KFgDiduMqLCRZVztq16FpY0kHyNqoikcsXG4D093/t5ov6CaqUyw0TdNGRe8UC8PnRXVLsdhf1+pslzTIyfaQ5THZVNPa9XpXgGwkCFfXoRIJZ1JeL67SUp1ioZ0wdICsjap41MLTT/5xJ3/QratYaJqmjRI73msE2dMzQK5r6XC2SwjegItl03PZVN3a9Xp2drbzupEgVOWkUHgqyvucx1VWqlMstBOGDpC1UZUYYJnpTt4st85B1jRNGyV9Jul5vV2r67XHkiQTTrBsxQSv38WK8ny2H2knlkwBvUaQjzQB4C6voDd3SSlJHSBrJwgdIGujKh61+q1g0UmPIGuapo2evgGyp2sEubo5glucQDgVETx+FyvKc0mmFDuOtAOQlZWFiDg5yA3t4HLhLivtcx5XaSl2ezt2NDoGV6Vpo0sHyNqoSkQtPL6BA2Rf0E0iapFK2WPUKk3TtJOHSiQQb7ccZK8XUimUZVHdHMGDEyDbSQNvwMWiKTkA7K5zUi8MwyAQCKDMBNHWMO5pUxFX3369M2jWaRbaiUAHyNqoSsRSuAcJkP16NT1N07RRoxKJHjWLxeN1no/HqW6O4pEUIgLKwON3MT3bh89lsLsu1LVPdnY2ymMR60jgyZBeAUdrISdrdYCsTX7jEiCLyOUisktE9orI5/vZ5gIR2Sgi20TkhbFuozYykjELj98ccBtf0Om4dYCsaZo28lQigbh7plgA2IkEVc0Rslw2Xq8PQQgeaOPIN17ja55g1wgyOHnIykwQi6mME/QAXCXpEeR6HSBrk9+YB8giYgK/BK4AFgM3isjiXtvkAb8CrlFKLQHeOdbt1EZGIpbC4x08xQJ0gKxpmjYaetdBNrzdRpBbIuR5wOP2kGWAe3cLpBTnRSC3Jty1TzAYxCZBUjy4p2cOkN2lJYAeQdZODOMxgrwa2KuU2q+USgD3Adf22uYm4EGlVBWAUkoXVpyElK1IxlO4u40gh9fXceT7a2n8/TZUOue4M8VCV7LQNE0beXaGKhbQmWIRIculcLs8zPEaiClM+eJqol6D86LQFnX65ezsbJLESbgC/Y4gG1lZGNnZOgdZOyGMR4A8Daju9rgm/Vx384F8EXleRNaLyPv6O5iIfERE1onIuoaGhlForna8knFn4ofH6yIWi9FQVUfr3/cihhDb2Uzb45VAtxFkvViIpmnaiFOJZJ86yAB2PE5dexyf2LhMDyUuAynPxszxEp2byxm42FfVAnSWelPEvb6MJd46uYqLsRobR/V6NG0sjEeALBmeU70eu4DTgKuAy4CviMj8TAdTSv1GKbVKKbWquLh4ZFuqDUsiZgEQSjbzox/9iF/ddQe71CGKPrCEwMoSwq8fwY5Z+LI6UywS49lcTdO0E1KmMm8A8UiUUNzCxMKtTLJMwT3DqWCRt7IUF0LrVqfucWct5ITXjXt67zGto1xFRTpA1k4I4xEg1wDd789MBw5n2OZxpVRYKdUIvAgsH6P2aSMkEUuhUGza8xqmaZInWbzm3k3CrwieNRWVtIlsrMd0GXh8pk6x0DRNGwV9lppOp1i0tDhVKgw7iSvphAPeObkATF1QSAgFNc42navppVwpUqa333M5AbK+m6tNfuMRIK8F5onILBHxADcAD/Xa5h/AeSLiEpEAcAawY4zbqQ1TImaRckVobK3j3JVnc1FsCUllsWbNGtzTg7jLsohsdDpSn14sRNM0bVSoeBzxuLsed+Ygt7Y5k/BUysIdF5JK4S93RpBdLoN9HshvchYU6b6a3kB9tau4iFSDHkHWJr8xD5CVUhZwG/AETtB7v1Jqm4jcKiK3prfZATwObAbWAL9TSm0d67Zqw5OMpYh7nY5ytl1CvgoyY3oFW7c6X0rfogISVe1OmkXQc8wBsq30wiKapmkDUUr1TbFI5yC3pwPklJXEkxQ6Ugq37+ik6qYCD8UJRSqUOBogm4kB54uYRUXYkQh2ONzvNpo2GYxLHWSl1KNKqflKqTlKqW+ln7tDKXVHt23+Wym1WCm1VCn1k/FopzY8iZhFwttMafEUXIeSuEoDLFtxCo2NjdTV1eGbnw82xPe24g+6h5xisbtlN+96+F2svGclH3/m4zRG9WiFpmlaRkmnXzV6pFg4n4c6IhjYKNvGmxRCiLNgSJoqywIgUtWBCzCtlDOCPECA7Cpy5gJZTU0jfSWaNqb0SnraqImGE1juENOnlZM8HMIzPZv58525lvv27cNTkY14TWJ7WoacYnEodIhbHr+Fxmgj717wbtbWruXWp24lZsVG+3I0TdMmHTvh9Kudo8ZwNMUi1BHGjXMnzmObRF09Q4K82U4+cuPeZpI1h/DF4thGcpAAuQhAT9TTJj0dIGujprGpDkQxvbgMO5TEMzWLnJwciouL2bdvH2IaeGfmEK9sx5flJjpImTelFF9++csopfjD5X/gC2d8gR+c/wN2tezi7m13j9FVaZqmTR4q6VQHylQHOdIRJd/njBi7MYm7e4YEs6bmUE2KaHUHyeoq/NEothknFrL6PZ+rOB0g6zxkbZLTAbI2ahqanGLxUzwFALinOTlss2fPpqqqCsuy8FTkYNVH8PtMrHgKK5Hq93gvHXqJdXXr+PeV/055jlMI5S3T38JlMy/jri130RprHd0L0jRNm2RUIkOAnP48Go5QHHByjt3KJOHruerprKIsdmHjaoiRqKrGHw0PPoKcLreqK1lok50OkLVR0xpqwrDdBNoEBNxTnAC5vLwcy7Koq6vDU5ENCoJJJzAeqOP9zebfMC04jX+Z9y89nv/oKR8llorxwJ4HRu9iNE3TJqFMAXJnmbd4JEqB3wkDTEzw9wyQs31ujniFQCxFovow/qQ1+CS9vDwwTZ1ioU16OkDWRk1HpBW3HSRZF8FV6MfwOiMV06dPB+DQoUN4yrNBwJvucPvreHc272RTwyZuWngTbtPd47V5+fM4Y8oZ/HnXn3VlC03TtG6OBsjdyrx5OhcKiVHgc8IAGxeeXgEygJXvBNPJwyGCPi9KUoTbo/2eT0wTV0EBKR0ga5OcDpC1UaGUIhxvw2sEsRoiuIr9Xa/l5uaSlZVFTU0Nhs+FqySAq93pxPurZPHA7gfwml6unXttxtffPvft1IZr2VC/YeQvRtM0bZLKmGLhcoHLhRWNkZN+2lJmjxJvnTxlAQBS7TbB9GIhHaGOAc9pFhfpHGRt0tMBsjYqOjo6SCkLv5lNsjGGq+hogCwiTJ8+nZqaGgA8U4NIs1OFIlMlC8u2eLLySS4sv5Bcb27G811UfhE+08djBx4bhavRNE2bnDoD5O5l3sAJmFUiQcBUAFgpE4+37whyyfQcoijspI/svHwAwoPUOHYVFWE16BxkbXLTAbI2KhrSnWOuOxssu8cIMjhpFs3NzUQiEdxTs1DhJB7JHCCvObKGlngLl8+6vN/zBdwBzpt+Hs9WPYtSamQvRtM0bZLKNIIMgMeLO5UkmC7zFrXIOII8pySbatvC8BeTW1LibBsbLEAu1jnI2qSnA2RtVLS0tABQ6HJuybmLAj1enzZtGuDkIbunOpP3ck3JmGLxdNXTBFwBzp127oDnPH/6+TREG9jRrFcl1zRNA7DjmQNk5XHjsS0CllOyLZYw8WQIkGcXZ1FnRTCyp5A73em3Y8nIgOd0FRVhNTWhbD0nRJu8dICsjYqWlhZQQr44Ezx6jyBPnToVgMOHD+OZ4qzWVOgz+4wgK6V4oeYFzpl2Dl7Ty0DOnXYugvBCzQsjdRmadkIRkctFZJeI7BWRz/ezzQUislFEtomI/mGa5PobQbZdHjwpC3cyCQpiSnBnSLGYmusnlGjD8OeTVTYdQwySqRgpq//g11VUBJZFqq1tZC9G08aQDpC1UdHS0oJL+QkoEK+JEexZecLn85Gfn09dXR1GwI2Z5yXPYxALJXpst7N5J/WRet4y/S2DnrPQX8iiwkW8ceSNEb0WTTsRiIgJ/BK4AlgM3Cgii3ttkwf8CrhGKbUEeOdYt1MbWf0FyCmXG4+dxLCSziIhtmRMsTAMwZNy7ggankJ83qxBS70dXSxE5yFrk5cOkLVR0dLSgmn58KQUrgIfItJnm9LSUurqnMVE3FOD5NC3isWrh18FGDS9otOq0lVsadhCPBUf3gVo2olnNbBXKbVfKZUA7gN6l4W5CXhQKVUFoJSqH+M2aiMs00p6AJbLjTtlQTKJC5OEAo+v7wgyQHaiFgA75iLgz8I2BgmQ08tN61Jv2mSmA2RtVLS0tCBJH+5kCjPfl3Gb0tJSmpqaSCQSeKZm4bMViV4jyGtr1zIndw5F/qIhnXdV6SoSdoLNDZuHfQ2adoKZBlR3e1yTfq67+UC+iDwvIutF5H2ZDiQiHxGRdSKyrkGPEk5o/VWxSJpuvKkkdjKJW5zAONMIMkB++DB2KkGsNkwwK4htxokPtFhIOkDWE/W0yUwHyNqIi8VixGIxzJQXVzyFKz9z7nBpaSngVLxwTw0igKvbCHLSTvJm/ZucXnb6kM+9snQlgrCubt2wrkHTTkB9b+NA75IvLuA04CrgMuArIjK/z05K/UYptUoptao4vbSwNjH1l2KRMFx4bItkMoHbcAJkjzdzgJzX3kQ42kyoJkROTrYzghyy+j1n13LTuhayNonpAFkbce3t7QB4bC+SUgOOIAPU1dV1VbLwxVNdZdq2NW4jakVZPWX1kM+d681lfv581teuH84laNqJqAYo7/Z4OnA4wzaPK6XCSqlG4EVg+Ri1TxsF/QXIcXHhUxbJZBKX4cwRcfeTYuFtbqApEcJujJKbl4syUoTa+69kYWRlIT6fHkHWJrVxCZAHm0mdnkXdlp5JvVFEvjoe7dSOT2eAnEW6gkU/AXJ+fj5ut5u6ujrMXA+22yAbsBLO7Oi1tWsBJ23iWKwqW8Wmhk0kU/3fAtS0k9BaYJ6IzBIRD3AD8FCvbf4BnCciLhEJAGcAum7iJGb3EyBHDROfSpFIJXGZ6RHkDCkWdiyGtLZwJBXHE7HIzXFKd7a29F+hQkScUm86QNYmsTEPkIcykzrtJaXUivTHf41pI7Vh6ehwliENKidANvtJsTAMo2uinohg53jIMSGazkNeU7uGefnzyPflH9P5Ty89nVgqxtamrcO4Ck07sSilLOA24AmcoPd+pdQ2EblVRG5Nb7MDeBzYDKwBfqeU0j9Ik1h/I8hRTHwISdvC7BpB7hsgW/XOPM3G9O5BnE/a2wdebtoJkHV+ujZ5jccI8lBmUmuTWOcIcg7OyPHHHt7Ktb98hZf29O0sOwNkpRRS6CfHFKIdCZKpJBvrN7K6bOjpFZ1Wlq4EYEP9hmFchaadeJRSjyql5iul5iilvpV+7g6l1B3dtvlvpdRipdRSpdRPxq2x2ohQiSSYJmL2DH4juPC5/SQlhdGVg9w3xaIzQA4XOos9+WPONh2h0IDndRUX6SoW2qQ2HgHyUGZSA5wlIptE5DERWdLfwfRs6omnvb0dr8dH0DCIoHjjSBtNoTgf+sM6Nla39ti2tLSUaDRKR0cHrtIALhHiRyLsbN5JLBXjtNLTjvn8+b58pgens7VRD3xpmnZyU4lE32WmgbAy8LqzSGJhGG4MUzDdfUOCZLoUp1leQhKFt8PZJhIZOEA2i4r0JD1tUhuPAHkoM6nfBGYopZYDPwf+3t/B9GzqiaejowO/Nwu/CPXK5q5bTueh286lMMvDl/++Bds++uXuPlHPO92ZqJc4EmZL4xYAlhUtO642LCtapgNkTdNOeioezxggh5SB6Q5ikUKJq98Sb1a9M/BUMmcaNdhY9XEEk2h88OWmU62tXSkemjbZjEeAPOhMaqVUu1IqlP78UcAtIkMrhKuNu/b2dryuAD4DkgEXp88soCDLw+cuX8jWQ+08sa22a9uSkhLACZCzKnJRSmE3RtjSuIVifzGlgdLjasPSoqUcCR+hMapHMDRNO3mpZALx9FzJ1LYVYWUiniBKAMyj6RVKwfo/wP+9Cx7/AlbNAcTnY+aMMiqxSdZH8Zg+4snBAuR0qbfm5lG4Kk0bfeMRIA86k1pEyiS99JqIrMZpZ9OYt1Q7Lu3t7SQsN35DKJgS7Hr+6uVTKS/wc9crB7qe8/v95ObmUltbizfXQ8gGaY2ztXErS4uWZlyBbyiWFTsjz3oUWdO0k5lKJDDcPUeQQwmLhOEiFcgBwLbNoyPIT30FHv4kNO6CNb/Fev3PuArzmVOSzUFszPYEPrefRCo64HmPLjetBym0yWnMA+ShzKQGrge2isgm4GfADaqzOK42oVmWRSQSIRQRvALlM/O6XjMN4b1nzmBtZQsHGsNdz5eUlFBfX49hCCERzI4Ele2VnFJ8ynG3Y2HBQkwxu1I1NE3TTkZ2IoF4e1YS6oilA2S/EyCrlOEsM73/BXj157Dqg/DJjfCR57HCCpeqp9Sf4oipMBQEXH4sFWegX8uurtX09NwgbXIadoAsIn8VkatEZMjHGmwmtVLqF0qpJUqp5UqpM5VSrw63ndrY6CzxloiYiAjeXjWQr1k+DRF4aOPRrJqSkhIaGxtJpVLEPAaepI0/5WVp0dLjboff5Wde/jw9gqydkI6n39VOTiqR7JOD3BFLkjDdWH7nDp9KilMD+emvQ245XPYdEIGypVhGKW5XCHn8C9gFTn8edPmxjQSJ6ACr6enlprVJbiQ61/8BbgL2iMh3RWThCBxTm6S6VtFLODlvZm7PkYuyXB9nzCrgH5sOdY0+lJaWYts2TU1NJP1OHtzM+DSWFPZbvGRIlhYtZUvjFmxlD+s4mjYB6X5XG5JMVSy6RpC9WQDYloHbboPDb8J5nwa3EwgrpUi2hnHNXgZv/oFZebuwUWThQRkp2lv6r2RhpgNkXepNm6yGHSArpZ5WSt0MrAQqgadE5FUR+YCIuAfeWzvRdAbIuZ2LhOT2nT19zfJp7G8Is+2ws23nRL36+npUntMxn26cQrYne1htWVq4lI5EB1XtVcM6jqZNNLrf1YYqc4CcJGm6sbxObeNUXHB37AVvDpzy7q7t7HAYFYkgp17O98um8X/mT6lzN9HS6ky0bm5o7/e8hseDkZuLpcuvapPUiNyeE5FC4BbgX4ENwE9xOu6nRuL42uTRmWJRqPxA3xFkgCuWlmEawmNbjwBQVFSEiFBfX4+70EdSKZbZC4bdlkWFiwDY2bJz2MfStIlG97vaUDgBcs+/mTpiFpgeLNOZBG3HwdO2GxZfC56sru06Fwl5oO0l7vGbXNcRokVFmaIKAHhh14sDntulayFrk9hI5CA/CLwEBICrlVLXKKX+rJT6BBAceG/tRNPR0UEKgyLTTUpAvH1ra+ZneThtRj7P7XRGFlwuF4WFhdTV1UFWivaUYnr4+Mq7dTc3by4ucbGzSQfI2olF97vaUGUaQW6PWXjcfpLi5BCn4uBW7bDkuh7bdQbIz8e38pmVn+YLdhHz7R1MTToB8pr9a9jetL3fc7sKC3WZN23SGokR5N+llyX9jlLqCICIeAGUUqtG4PjaJNIRChNVLoJiYLmMfsu0XbighO1H2qltiwFHK1m0mY20pRQ5bb4BZ0gPhcf0MCdvDjubdYCsnXB0v6sNiUokMDKkWPhcPpKknCdsE48rBTPP67Fd3cEdACyedzbvX3oLxkVfoNjYQbbt3BnMtnP49hvf7neeh1lYQKpJV2jVJqeRCJD/X4bnXhuB42qTUGNrO1Hlxg/Y7swrMwFcuNApIv/CbmeEoqSkhJaWFg5bVbSnFEYSUi3xYbdnYcFCdjTvGHawrWkTjO53tSFRiQTi7jtJL+DyYaUDZFEu3EXTwNVzuxc2O0sUfOziLyEiGAuuYl27BzcujJSiLOpiS+0mnq16NuO5XfkFegRZm7SOO0BOL+ZxGuAXkVNFZGX64wKc237aCSxx8CBNd95Jorq6x/Nt7R3ElAsvoDKkV3RaUJrNlFxfV5pF55LT1aH9tKcHNZK14f52H7JFhYtojjXTENUTRbTJT/e72rGyk5kn6eX5/CQkhXOPT/BMndtjm53NO6k7tAvbZVBcVEEiGuH+//cVNjU4Axc+200i2sbl2yr43ebfZhyEMAsLsNvb9XLT2qTkGsa+l+FMEJkO/Kjb8x3AF4dxXG0SqPvOdwk9/zzN/3sPc595GnE530qxaJQEAbwCSX//AbKIcMGCEh7edJiEZR9dcjp0iOkphQKSh0P4FxcOq50LC5zqVzubd1ISKBnWsTRtAtD9rnZMVDxDDnLUYrrbi0UbLkAQ3NMX99jmri13MTfmwl2Yj7Jt/vGDb1G7dxcFl98EO1rIlmySWYqSXXvZ/2Y1605fx+llp/c4hqvQ6b+tllbcpbr/1SaX4x5BVkr9QSl1IXCLUurCbh/XKKUeHME2ahNMorqa0Asv4Jk9G6uujvAbbwBOzUw7ESPL68djCBIYuNrUhQuKCcUt1h1sJj8/H5fLRSQUxjIUls9F4lDmGptWMomyh1bbeEG+Uw1jR9OOY7hCTZuYdL+rHav+yrzluD0kVRK37dyyc5dUdL1eH6nniYNPMJ8yXIWFvPG3+6nauolLPnwbqy+9ggaJkqs8pESYvnQZp+7N48Gt9/c5t1ngTOZLNes8ZG3yOe4RZBF5j1Lqj8BMEfl079eVUj/KsJt2Auh46mlQium//AWV17+T9kcfJXjOOcTjcQSbEn8WhECCAwfI58wtwm0Kz+2s5+w5RQTzg+R0ZOPOgojHwNsrQK47sI+X7/0DVVs3oWzF7NNO5/z3fJD8KdP6PUfQE6Q8u1xP1NNOCLrf1Y6VSiQQb98c5BzDQ5MVx8SpZOHxHe2vH9r3ELaymZLw05qTzWsP3Mui8y5k6YWXYKVs/iQBCohhSx1nvet91Hz1P9n54hrazmsj15vbdRxXOkDWecjaZDScSXqdxRKDQHaGD+0EFdu6BdeUKXhnzSJw1plE178JQFOrUzS+LL06kyu77yIh3WV5XbxzWjPzNn0fHvk0GE3kJHMI5vpoR7DbE6Tandy1jU/8k//74qeor9zPqVdcw8orr6Fm+1bu/cp/0lQz8EIgnRP1NO0EoPtdbciUUv2upJdtmCRIYKbSI8g+s2uff+z9BytLVqLawqxJtpNTXMzFH/w3AFymQVNePjnK+Vb0ZOdRtGg+cw/6efpAzxLcZoGTYpHSAbI2CR33CLJS6tfpf78xcs3RJoPo1m34ly4FwLdoEaFnniUVCrO7xikIX+pJLxKSM0CArBS8+N98q/7bJJSJvSWLdnMZ/tTpBHPiNLUalAOJQx1se/FFXrjnTmaftporPvZpfEGnzOvyS67gz1//PA9+9xu8/we/wOPzZzzVooJFPHXwKdoT7eR4ckbujdC0Mab7Xe2YWBYolbHMWxAvlkpipOfWedIB8qaGTVS2V/LBpR9kl/yEsJXkXbfejjdwdA5oYGqQYIuz6mn99rWcfeX1NP7w27z68sO8Y+H1Xdu5CtMjyLrUmzYJjcRCId8XkRwRcYvIMyLSKCLvGYnGaRNPqrWVZFUVvmXLAPAtWgxKEd+1kwO1zihBscsJVN3pZaMzev1/4Llv0T7vOlbF7+AvF79IbanTmUrdU9S1RkGg9o3tvHDPncw/81yu/cyXuoJjgPwp03jbpz5Pe0Mdr9x3T7+n6pyot6t517CuXdMmCt3vakPRWT0i0whyIAVJUhi2Ewa4fc542d/3/h2/y8/pah7784PMLptO+ZJTeuw/c3ExQeX07017NjHntDMg4CaxtZq2eFvXdkZODrhcpJr0CLI2+YxEHeRLlVLtwNuAGmA+8J8jcFxtAortdHJ5fUsW9/g3tn0Hdc1Ox1hge1FK4c7vu8w0ALVb4amvwIKryLnxdwRy8nlhTxN7zFoALJ9NLAEqYNG4YT9T5i/k8o9/CsPsWxVj+sIlLL/kCjY88QittUcynq5ryWmdh6ydOHS/qw3K7gyQu9VBtm1FKGHhtxRJSWHg5B67vSaJVIInKp/gkhmX8Nr/3YOhbM44/Zw+x101v4g25UKU0Fxfi2EYlJ92GtPqfTy994mu7UQEV34+VosOkLXJZyQC5M7M/iuBe5VS+ifhBJaoPAiAd/ZsAFwlJZj5+cR376KlrQMAT9wgrsCbqYqFUvDYZ8GbA9f+AjFMzp9fzEv7DlJr1WK4DWLlp6DsKDX1O8j3lnHtf3wZt6efYBs48x03Ypgmb/y97yxqgCJ/EUX+Ih0gaycS3e9qg1KJJNBzBDmUsPAocNlgGQoRLy6PgWEIa2rXEEqGODM+n6qd25hX20L2tOl9jlsY9HLEYxBQXtqSbji8gTMvvAZ3yuC1lx/psa1ZWKhHkLVJaSQC5IdFZCewCnhGRIqB2AgcV5uAElVViMeDK72wh4jgmTmTxMEqwuEwKXFhRm3iCjz+DCnue5+Bg6/ARV+CgJNScf78EiLqCAhkF2TTngiTjDxFY6wOnxHAl+q/njJAML+AUy6+nO0vPktHc2PGbfREPe0Eo/tdbVAq2TfFoiNmkZdeHiRpAHi60iuerXoWv+mn+Yl1ZGfnUNHU1lXLuLdUqZ8c5adDsmDHQ0xftAR8LiK7e6ZZuAoKsHSZN20SGnaArJT6PHAWsEoplQTCwLUD7SMil4vILhHZKyKfH2C700UkJSLX97eNNrYSVQdxV5QjxtFvHU9FBYmqKhLxKOL2ITGLuK1wZ1pJ76UfQs50OPV9XU+dO7cI01sHwLSyaTQ21ZFK7iUwzVmOOvHonYO269QrrsZOpdj63FMZX19UsIj9rfuJp4a/fLWmjbfj6Xe1k0+mHOSOWJJ8BIXCMg1EefB4TWxl83z181wSOYXGgwc4bfGpmOpoLePeiubmE8RHxPDB7icwDJPSxYuY0uDl1UOvdm1nFhSQam4Z1evUtNEwEiPIAIuAd4vI+4DrgUv721BETOCXwBXAYuBGEVncz3bfA57o/Zo2fpIHq/BUzOjxnHtGBVZtLaYVw+sPYCRSxEUwDOm585FNUPUqnPUxcB3tsHMDbkqL2hDlpSQ7HyuVQnyz8C++BMQmvuMA7Hl6wHbll01lximnsuWZJ7HThe+7W1CwgJRKsbdl7/FfvKZNLEPud7WT09EA+Wi6W3vUIg8Di3Q/qdy4fSZbG7fSHGqgZH2IkllzqAg69Yxd/QTIC5eXElQ+4qSw6ndB+2GWr76IQNzFa5uODlS4CgtI6SoW2iQ0ElUs7gF+AJwLnJ7+WDXALquBvUqp/UqpBHAfmUc+PgH8Fagfbhu1kaFsm0R1NZ6Kih7Pe8qdx0EVI5gVwEjaWKb0PcDaO8HlhxU393kpK9iMFS1i78vPARCYfg4d7Uk807NJmKvg4dshnnllvU6nXHwZHU0NVG3d3Oe1RQXORD2dZqGdCI6j39VOQiru3DHrPYKch5BMB8jKNvH4XDxX/RyLqnKxWkO85eYPYLe0Ij4fRrfybt0VT8nGZ/tBoIUc2Pccs1acBsChLVuwlbPaqVlQiB2JYEejo3mpmjbijrsOcjergMVKKTXE7acB1d0e1wBndN9ARKYB1wEX4XT8/RKRjwAfAajoFbhpI8tqaEDFYrgryns875nhvO8+scgPBjEUpFy9/vZKxmDrg7DkOvDn9Tl2lEPMqy6m9cA2WHAqrhyD9oYo3hVFdByaid3WiPHct+Dy7/TbvtkrV+P2+dn92kuUz55Hy733Etu2Hd+C+Ux5z81kubP0RD3tRHGs/a52EuocQTZ65SDnA0npDJBduH0mL+57ltX785lxygpmLFvB4T/e2+/ocSfDdBYLafTOpHjfMwRPvRnPlELyjxxiZ/NOFhcu7qqFnGpuxpjW/6qnmjbRjESKxVag7Bi2zzC0SO9O/ifA55RSfe+V995Rqd8opVYppVYVFxcfQzO0Y5U8fBgAT69Ozl1eji2CaSiKAk6HmfL0yj/e+xQkOmBZ33TyUCJEtK2ZMyujJArKyc7OJuWO0FoXwTMzB2xIzLsd3rgDDm/st30uj4c5p61mzxuvsv/dN9Dwwx8R27aNhp/+jKobb+JU12wdIGsnimPtd7WTUFeZN+/RKkAdsSQVREnijC4r203KTOLd3Igrrjjn3U45bau5BbOfCXqdstIB9F73Stj3HNg281eeSWmLl5f2Pw8czWG2dB6yNsmMRIBcBGwXkSdE5KHOjwG2rwG6D0FOBw732mYVcJ+IVOLk1v1KRN4+Am3VhsGqcybSucp6/l428/IIB4OICLnu9O04X68AeeuDECiEWef3Oe6+1n2cta0Al4InC86nuLiEmN1BIpYiVejcwksUvQP8+U795AEGzeafdgaxcIi6tmYq7r6LuU89ScXdd5E8dJgb7z3CnuZdpDLkKGvaJHOs/a52Eso0Sa89ZlFODBun0oSy3TQlDrPkQA4lSxcxZe4CAFJNTZgF+QMev3heCR7loio2DaLNcGQji1edi6GELW++CBzNYU7pShbaJDMSKRZfP8bt1wLzRGQWcAi4Abip+wZKqVmdn4vI74FHlFJ/H1YrtWFLHnEW8nD3CpBFhOZ8Z/TejxtIQfcayIkw7H4clt8AZt9vuc2vPkNFXQDPuRdSeSiAK8tLR6SSfBTtbXHcpVnEaxLwls/C45+Dfc/C3IsztjH46hu4UjatF59P1llnAZB11lmUfemLqC9/hbPXGVRfXc3M3JnDf0M0bfx8fbwboE18meogd8QsysTCMpw5HTYeGqtexpc0eeuN/9q1ndXcjHfBggGPn7OggJw1fjriBpjAvmeZevbt4DKIHjhCe6IdX3oU2tK1kLVJZiTKvL0AVALu9OdrgTcH2N4CbsOpTrEDuF8ptU1EbhWRW4fbHm30WLW1iN/vLB/aS33QGWnwWU5gbAS6BcK7H4dkBJb8S5/9krEY9Y+8QktOkn+5+YMAHIp7SNkpUmaUltoInlk5JKraUae+H/JmwNNfB9vuc6zY7t20/uF/mZ5TwMGaSlKW1fVa7jveAacs4p0v2ew6vGk4b4Omjbtj7Xe1k5PKsJJeRyxJLiaWy3nNVgKHdxGfGewaPVZKkWpuHnQEOW9aEH8qABInXLAE9j2L6XKTO6uC0iYP62vXY+anR5D1anraJDMSVSw+DDwA/Dr91DTg7wPto5R6VCk1Xyk1Ryn1rfRzdyil7siw7S1KqQeG205t+JK1tbjLyhDpmUZu24oGXzYAPsskpRSurG4jyDsehqwSmHF2n2O+/rc/Q0ecmjMCTCvIZWVFHm8ccYJf2xumtT6Kd1YuKmGTrLfgwi9B7WbY07P6n1KK2v/6L8ysLJa97wPEQh1UbT0aCIsIU//js+SHIfT3h0fqLdG0cXE8/a528slcB9nCh5dUuotW0Z2YqRRzrnxr1zZ2OIxKJHAVDJyD7A24casAcYmx3jgVqtdAIsKCU86goN3DGwdfwcgKIF6vHkHWJp2RyEH+OHAO0A6glNoDlIzAcbUJJll7BPeUvvOCGsNx2vzO5DxPxCCmwNOZYpGynJSIeZeC0TMvuflwDese/huHZ9qUzJsHwBVLp7C+IYVpmhg5MVprw3hnO/U4Y7tbYOk7ILcCXvlpj2OFXniB6Lr1FH/q35l9zltw+/zsW/dGj21yV59JTbmPssc3oCf/a5Oc7ne1QR1dSe/ogEU4GsNQWVjphZxSsc205Ho5f9XburbprFvc3yIh3Xm9OSiBFxsXgJ2EqteYsXg5grB7y1pEBFPXQtYmoZEIkOPpesYAiIiLvlUptBOAVVuHq7RvgHykNUbU70dsG7M1SdxWR5eZrlkLsTaYd0mPfZRSPHv3r3F5Pbw05zCz82YDcPnSMhQGRiCPlDdEQ3UIM+jBXZ5NbGezk8N81seh6jWoeqPrWA0/+xnu8nLy3vEOXG43M5YtZ/+GtX0C4YOXLKGgLkLk9ddH4R3StDGj+11tUJnKvGWHalD4sXzp51IR2maVUJZ1tG+3mp3RXtcgKRYAwWLn77JYIg8lLjjwIlPmLwBDsKubaYw24ioo7Dqmpk0WIxEgvyAiXwT8InIJ8BdA38M+wahUCquhAVdZaZ/XjrRFSXi9eONx7PY4MRs8nVUs9jwJYsLsC3rss2fNqxzcvIE5V11C1Jtidq4TIJcXBFgyNYday0/EaiXUGiPSnsC/sIBETQepjgSsfK9T0eLVnwHQ8dRTxLfvoOhjH0PczkjJrFNX0dHYQFP1wR7n9V16Me1+qP3fu0f4HdK0MaX7XW1QdudCId3KvE0JHwEg6fGCsjHMMqbNXdRjv1SLU5JtKCPIxRVlGEooMxJUZy2BAy/g9njJm1lBWZOPNUfWYBbkk9IBsjbJjESA/HmgAdgCfBR4FPjyCBxXm0BSzc1g27gy1Jo+3Boj5XY5AXLEJq66jSDvfQoqzuyxOIiVTPLCPXdRXDGT1HIn4J6TN6fr9SuWlrGz3YWVSpIyY9QfbMe3sAAUxHa1gCcLTvsA7HoU1VpN46/+B8/MmeReffQW4axTnUXF9m9Y16OtC8qW8swKIf7CyyTr9SKN2qR1XP2uiFwuIrtEZK+IfH6A7U4XkZSI9C1crk0amXKQp8YbAGiLxSBl4/KtYm7p7B77dQXI+YMHyPllQQJ2AK8R5ZnIYtSRTRBtYd4pp1PY7mFN1Wt6BFmblEaiioWNMznkY0qp65VSv9WrO514rMZGAFxFRX1eO9IWxXAb+GJxJCXEbPD6XdB+BGq3wNy39th+05P/pL2hjvPf+68c6KjEJS4qso+ugnj50jKabKeesuXuoKGqA/fULIwcD7Gd6Ty2024BpQjf813iO3dS+OEPI66jlTOyC4oonjmbA70C5Pn583lhmYHYivZHHx2Jt0bTxtzx9LsiYgK/BK4AFgM3isjifrb7Hk6lIW0SU/EEuFyIeXT+x9RUOwCNTbUYysZwz2Fh8dwe+x1LikXR9CBmMosWCXEgchqibKh8hYrFp2AoYfe2dZgFTg6yDg20yeS4A2RxfF1EGoGdwC4RaRCRr45c87SJwmp0AtNMAfLh1hh+l8KXrrzWNYK8/znniW4Bciwc4vUH/8zM5SuZccoK9rXuoyKnArd5dBLJ3JJsiouLsRFceTHqKtsREfwLC4jtbkVZNuTPgLkX0/TXZ3CVlfYYPe40+9RVHNq1nVgo1PVcrjcXmTGdxopc2h9+ZCTeGk0bM8Psd1cDe5VS+9P5y/cB12bY7hPAXwF9i2WSU4lEj/zjlK2YYjtpF+FwB4IgYjA9u+f8zlRzC+L1In7/oOfILQmg7CARiVNiTCchXjjwIlPnLwQRXIdChLIMVCKBHY6M7AVq2igazgjyv+PMoj5dKVWolCoAzgDOEZFPjUTjtIljoBHkw21RPCTxu53O1MlBdiZr4C+A0qVd2675xwPEwiHOu+kWAPa37e/KP+7uutMqaLb9JL1hDu9pJWXZ+BYWoBIpYvtaAYhkXUikVii88owetxA7zTr1dJRtc3DLhh7PL8hfwGtLXcS2bSO+/8BxvR+aNk7+nePvd6cB1d0e16Sf6yIi04DrgD4lN3tt9xERWSci6xoaGo7xErSxohLxHn1jKJakGGcl0ZQBKh0CeMTqsZ9TA7mgT0nPTAxDKMx3UuUWuOKstRdi738ejz9A3oxyypq9VBrOiLSuhaxNJsMJkN8H3KiU6oowlFL7gfekX9NOIKmmdIBc2LcuZl1LBFNZBDxOqbe4Ao/fhAMvwazzwHC+zcKtLWx49CEWn3sBJTNnk0glqO6o7qpg0d11p06jSWURSrSQiFnU7m/DNz8f8buIvOkMbDU9sQ3Tq8gr3pexzVPmzccXzGb/m2t7PL+wYCH/nN0GIrQ/ouc1aZPKcPrdTNFO73vePwE+p5QacD12pdRvlFKrlFKrijPMS9AmBjuR6DFBL9x8GJcKYKsU7pwgdvqrb9qJHvtZrS248gdPr+hUUTEdlBC2W9mYPBOjcRd01DFn6WkUtXnZlnD+LtMT9bTJZDgBslsp1dj7SaVUA+DOsL02iVkNjUgggJGV1fP5lE17qAOAgC9dr9hWeGI10F4DM8/r2vbNR/9ByrI48/obATjYfpCUSjEndw69leb4KCwuBWWh3HGqtjcjLoPAimKi2xqJbNlJ6PnnyX/rMoyqZ6Cjts8xDMNk5vKVHNi4HtVt5b0FBQtozgZ75RLa/vlPnRenTSbD6XdrgPJuj6cDh3ttswq4T0QqgeuBX4nI24+7tdq4UvFEjxHkZN0uWpIlxFIRlM+DwsC0oqhIz9SHVHPLkCpYdCqbVYDbyqJO2sgyz3CerHyJ8sXLMG1hV7NTTUhP1NMmk+EEyInjfE2bhKympsyjxx1xvDi357LSAXIScB96xdlg1lsAiEfCbHzyUeadeQ75ZVMB2NfmjPx2r2DR3fkr5gMgxQn2vVmPUoqslaVgKZrveRoJBCj4+BdB2bDpvozHmL3ydKLtbdTu39P13KICp6TR4dUzSR6sIr5797G8FZo2nobT764F5onILBHxADcAD3XfQCk1Syk1Uyk1E2elvo8ppf4+jPZq40glEoj3aICs6ncRtopJkiCuLMDElYphR8I99ks1N2Mewwjy9IX5uBI5NJjtrDJLaLWziO1+lmkLF4NAMmylj9syItelaWNhOAHychFpz/DRASwbqQZqE4PV2Ji5gkVrFJ8kAfB7crCsBKbXRA6+BMFSKHKC3I1P/JNENMLqa49Wjdrfuh9BmJEzI+M5rz5zESkMDkkTbfVRDu1uxT09iFngJtUaJP9d78KcfSqUnwkb/w8yjATPXL4SEYP9bx6tZlGWVUaOJ4f1C1wgQscTTw7rvdG0MXTc/a5SygJuw6lOsQO4Xym1TURuFZFbx6Dt2hhT8Z45yFbtDmyVgwp6SSaTuMSLacX6TJ6zWlqGVMGiU3aBj9xAMRYpYvFWNqcuJbn3eXxZQfKmTSc37AN0DrI2uRx3gKyUMpVSORk+spVSOsXiBJNqasRV1HcE+XBbDF96BNnvyiGRSuJxK2eC3szzQIRkIs6bjz3EzBWnUTrr6GjxvtZ9TM+ejs/ly3hOn8eNL7eYULIJl89ky/M1iAiqYydmwRxyrr7B2fDUm6FxN9Ss63MMf3YOU+Yt4MCGo3nIIsLCgoVssioJrFpF+5O6mpU2OQy331VKPaqUmq+UmqOU+lb6uTuUUn0m5SmlblFKPTAa16GNDZWIY3iO5iDX7z+I1wzgKc4FCzyGv88Ish2LoSKRIdVA7m7+vLmghIPuRgzXxWRHD6GaDzBz6QqK23wk3AaWHkHWJpGRWChEOwlYDY2YGUu8dRtBJotEKoWbOITqYOY5AOx69SUiba2cfvU7euy7v21/xvzj7pYvmkO+RGiaarJ/QwM1G6pof/x3QIrodqdcEUuuA3cANtyT8RizTl1F3f69hFuPds4LChawp3UPWZe+lcTefcT3ZZ7op2maNlnZiZ45yIdqI3jNAIk8wVQmbvy4rCh2txzko6voDX0EGWD+6dNxJ/KodDUwLVWBrbwcXP845YuWYqaEI3lerOamkbkwTRsDOkDWBqWSSVKtrf2mWOS4bVwuF66Em7ht40o6hegpPxOArc89Sf7U6ZQvOXoH2LItKtsrM1aw6G7h3NkYAk+0VePL8fDcH7aRjITwLc4msrEeqy0O3mxYfC1sfRASfetsdq6qV7npza7nFhUsIp6K03rGAgA6ntRpFpqmnVhU/GgVi3hrHUdC2bgNL/XpEtcufOkUi6MjyJ0T6Y4lBxlg2rw88lxT6LAjtKQ6qE9dRdOWp5i2cAkA9dle2utqRuKyNG1M6ABZG1TXqkqFmWogx8h322RlZaFiNjEFrlgreHOgeCHNh2s4tHM7Sy94a4+amtUd1Vi2lbEGcnfTp09HRCg0QtTO9dAedbP7nE+Rc8UiUIrQy4ecDVfcDIkO2NG3bFvJzNlk5Rf0WHZ6QYETGO9yNeI/9VTadR6ypmknGNVtBHn/i4/hkiAAB60qACTlTqdYdBtBTqdBuI6higWAGMJpZ6xAbJPNWTXE1XWUt64nZvrIKSuj3ecj3NC7aIqmTVzjEiCLyOUisktE9orI5zO8fq2IbBaRjeli9OeORzs1h9WQroFcnHmZ6aCZIssfQCVtYpiY0VaYdhoYBlufewoxDJacf3GP/fa37gf6r2DRyefzUVpaytLcJJUvPcm8vQ9Qa5TzwsMH8C8rJvxGLalwEmacA3kzYOMf+xxDRJi14jQObn4TO+WUd52VOwu34WZX8y6yL7uU+M6dJA4ePJ63R9M0bUJS8ThGuorF3jfXkud20tT3RioBSCUNXKl4jxHkzol0x5qDDLDyrbPJSVVQadXSYptkq3k8+/zTzFiynITbj9Wic5C1yWPMA2QRMYFfAlcAi4EbRWRxr82eAZYrpVYAHwR+N6aN1HoYaJGQI60xfJLE702voicmZqwdyleTsiy2vfAMs1euJiuv5+26/W1OgDwrd9ag56+oqMATa+GqvS+Rk9jLGdfMYveaOnaGkqhkio7nqp3FSE59jzM5sKVvoDtrxWnEw2EO79kJgNtwMzdvLjuad5Bz6aUAtOs0C03TTiAqkUDcHpRtU7X/ENODTqWfmqRz581OCC4jlTEH+ViqWHTy+Fy89crzMVIenvZsodb6F1o3PEzZ/MUoDBJxm5Q94Bo0mjZhjMcI8mpgr1Jqv1IqAdwHXNt9A6VUSB1dvSGLvqs9aWOoc5lps6jnilmxZIqmcAKXnSCQrkQRVi7MeAymr+bAxvVE2lpZeuElfY65r20fU7KmkOXO6vNab3PmzMGykuR5Yvxp2pkUri5h1ZUz2bi+gfYCH6HXDmM1RWH5jYDApnv7HGPGKacihsGBbmkWiwoXsat5F64pU/AtW6bLvWmadkLpXEmv/uABYnGLHL+TYhERp2S2KBO3afcIkK3mFjBNjJyc4zrnsnNmsnzm+URIcJ+nheKkiy1JJ9gO+/zsrN00zKvStLExHgHyNKC62+Oa9HM9iMh1IrIT+CfOKHJGIvKRdBrGuoaGhhFvrAZWozPzuHeZt9q2GKBQyTh+w5kIElOCxOIwfRU7X3kBf04us9OT5Lrb37p/0Al6nWbOnImhFLUVFbw8+3S+/egOVl89ixVvLee1/R3YCtqeqIS8cph9vlMTudvKeQDeQBbTFi7uESAvyF9AS7yF+kg9OZddSmzrVhI1h47hndE0TZu4OnOQq7ZsBED8ziBH0nBKc4pt4napnikWzc2YeXmIcfzhwdW3nMWSgovIsQNsNEvY8cqjqNJyGrMDbNz10vFfkKaNofEIkCXDc31GiJVSf1NKLQTeDnyzv4MppX6jlFqllFpVXFzc32baMFiNjRjBIIavZ73iI20x3NgoO4UfJ88tpsBMxEgkDQ5sWMvcVWdgmGaP/VJ2igNtBwadoNfJjEQoamigfs5cPnTJEp7aXser+5o4+x1zmXnWFPZELKKbG4kfaIMV74HWKqjs2wnPWrGKhoMH6Gh2RsQXFiwEYFfLLrLTaRYdTz11bG+OpmnaBKXiccTr4eDmDRR6I0SkFIsUxcFSwBlB9ril5whyS/NxpVd0Z5gG1/7bWSxzreKq+EqClkmooJSDy1aya2/fevWaNhGNR4BcA5R3ezwd6Hdqq1LqRWCOiPSdIaaNCauxIWOJt7r2WFcNZG/KDaaQVOCyYlS+9jKJaJS5q8/qs9+h0CFiqRjz8uYN6fztDz/MlMOHaUbxrlMKmZ7v55uPbCdlK95yw3wacr1EFTT/bS9q/lXgzXVGkXvpHMk+sGE9APPznVX+djTtwFNRgXfRIjqe0IuGaJo2+SmlUIkEtsvk0M5tzAi0ELbzaXN1MCPorF4qysTtEVS4ew5y63FN0OvN5TFZ/ZkzyE1lcU38bGgzsPwBktVZJFKDrYquaeNvPALktcA8EZklIh7gBuCh7huIyFxJ1wQTkZWAB9AVxsdJqrEJM8Mqeke6raLns0zwOjcHXKkoe9e+jsfvp2Lpij777W3dCwxewQKcTr71gb8yI8vJnauq3M+Xr1rEztoO7nrlAG6PyVs/vIztsRSp+gjhN1th6b/A9ocg1tbjWIXlMwgWFlG50QmQg54gFdkV7GrZBUDOZZcS3biRZF3d0N4YTdO0iSqZBKVojEWwkkkqslpJKh+tZgdTfVOB9AiyzyQV6ZVicYw1kPvjC3oombeFHNNgcWI53vpDeI0ynl7z9IgcX9NG05gHyEopC7gNeALYAdyvlNomIreKyK3pzd4BbBWRjTgVL97dbdKeNsasxkZcRX3TV2rbohR6nS+LL26ijBgAphXlwJ4dzFqxCpe77+q3xxIgx7ZuI757NzPfdhUFBQVs3bqVy5aU8dZFpfzoqd1UNUUomh5k+uUzaEjatDx+gNSC94AVhW1/63EsEWH2ilUc3LKBlOWMfC8oWMDOZqeyRfbFTim60HPPDfWt0TRNm5DshNPH1ba1ICKUB9pw46LV1UGJpwRIB8h+V88R5ObmY15FbyC5FywFalgeyMff1ArxEOtfXo/da56Ipk0041IHWSn1qFJqvlJqjlLqW+nn7lBK3ZH+/HtKqSVKqRVKqbOUUi+PRzs1h9XUlLnEW1uMEr8TIHsiBrbdAUDYFScWy5xeAU6APDVr6pAqWLQ9/BDi8ZB71VUsW7aMAwcO0NHRwTffvgRThC/9fQtKKVa8dQYH/G5UwqZ1UzYUL4QNfdMsZp26ikQ0yqGdOwAnD7m6o5pQIoRn7lzcMyroePqZIb83mqZpE5FKxAGob2+hNN+FK7eYXExCrgQe5cE0TATB43d3jSDbiQSptraMKXXHS2afT1HwT2SZwuz8C/A11pMKp9i5c+eInUPTRoNeSU8bkB2PY7e3Z1wkpLY9Rn56BNkbElIJp8B8a46JIcKsFX2rV4ATIA8pvSKVouOxx8l6y3mYOTksW+YsVb1161am5Pr57OULeWlPI3/bcAjTbbDy3fPZF0sRXV9PfMaHoWYNNOzuccyKZcsxTBcHNjoTRbpP1BMRsi+6mPAbb5AKhYb4Dmmapk08KpFAAY2tzUzJipDIm0e+7UP5vSQSCUzDubvnyfJ2jSBb9U4lKHdp6cg1xHTjXToDt7mDxTmL8HZ0EDUjvPb6ayN3Dk0bBTpA1gaUanJSv81+RpCzzRRerxeJ2liJVgCaslyUePx4A4E++yTtJJVtlczNnzvouSPr12M1NJBzxRUAFBUVMXXqVDZv3oxSivecOYNTK/L45iPbqe+IMXNZEdHZecSUomXPKSjcfSbreXx+pi9e2lXurTNAPppmcREkk4Rf0qWINE2bvFQ8TofPg5WymCKHqQ7MxKc8eIK5xONxXKYLAE+2DzsSQVkWVn09AK6SkhFtiyx9O3nmnfhMLwtyTsOOxqiuqqZFr6ynTWA6QNYG1LlISO9bbgnLpjEUxy8WWX4nEE6oJMruIGxCcSLzaknV7dUk7SRz8wYPkNsfewzx+ci+4IKu51auXEltbS2VlZWYhvDf159CJJHicw84QfPp181haySFVRcnXPhJ2HQfpKwex5214jSaaqpob6in2F9Mga+AXc3ORD3/qadi5ufT8cyzQ36PNE3TJhqVSNAacOrTT3HXs9lwFv7Izy8jHo9jiBu318SdnwdAqr0dq96ZoOwayRFkgFnn482qw27fzsLcM5hS76TXbdmyZWTPo2kjSAfI2oCOBsg9J+nVd8RQCtwqQcDjLDMdtxUoZ6GNwub2jMfrnKA3WICsLIuOJ54keOEFGFlHc5WXL19OMBjkpfQI79ySbD5/xUKe29XAn9ZUUVyejX9ZEc0pRVvD+dgdIdjXM6d4Vme5t43rEBEW5B+dqCemSfCCCwi9+CIqmRz0/dE0TZuI7HiC1iwfPo+bXHeMAwnn1/2U4nLi8TgmLjw+s6tiRaq1ddRGkDHdsPBtGLUP4DF9LDALsMRg69atI3seTRtBOkDWBnQ0QM60ih6IFSfgdhYQibmzwa7+/+3dd3hc1Zn48e+5d3pR71225SYXXHEH23QITmATSELbhCSEEEiyaftjUzZ9UyGbQlggJEASCAESunEBN3Dvlm0Vy7J6L9Nn7j2/P0Y2NnIFWyPZ5/M8eqS5c2fmvfbonVfnvvccbLoFV1MLx5t4pLq7GoGgNLn0pK8b3LYNo7OTpCuvPGa71Wpl9uzZ1NTUUF9fD8Dts0uYX5bBD16q4EC7n5nXj2BHIIYZ0egRn4P1Dx3zHGl5BSRnZVNzVJtFVXcVUTNeEHsXL8Ls7SWwSU1oryjK8BQfQXaQleRACOgIxXN2cro3PoKMBZvTgp6SAoDR1UW0pQVhtR7ZdlaVfxhLbC99PVWM9pbj6c2ktbVVtVkoQ5YqkJWTOlwgv7cHuam/QDYiIZwivopewJZCLHSQ3MwciEYxjpP4KrsrKfQW4rQ4T/q6vlWrQddxz5074L7p06fjdrt55ZVXME0TTRP87N8mY7NofOnpbbgznOTOzOFgxMQfvpRY5R5ofnekQghB6ZTp1O3aTiwSYWzaWKJmlJruGgDcc+Yg7HbVZqEoyrAV6uvBZ7eS7TKI2pOIBeMX4rlTHYTD4fgy0w4L+uEWi64uYq1tWLKy6F+G4OwqvQSL205w/6s4LV5GROKteZWVlWf/tRTlLFAFsnJSRnsHWnIyms12zPbmnhACSTgUxBExAJMeU8eI9VJQGm+fiB1nwY3q7urTmsHCt2Y1zikXoXu9A+6z2+1cddVVNDY2srJ/zuKcZAc/uWEi2w9186NXKphxbSn7IyYmgl7zFlj3v8c8R+lF04mFw9Tv3X3MTBYAmsuFe+5c+lYsP+4ouKIoylDXWl8HQpBj6WF/ZgneWHxQwtNfIGPGFwmxHB5B7m+xOOv9x4fpVvTSiTgadtIVaWGcPQ0t5mBvxb5z83qK8gGpAlk5qfgiIQOneGvqCZFqk0gpcYYiaPTQ64tPEVQ0cXL8sf39bIdFjAgHew+esv84q/H7VAAAStJJREFU1tZGeE8FnvkLTrjPxIkTmTJlCqtXr2bt2rVIKbl6Yi6fnlfK4+tqWXGokxGzczkQNgnELiG6Yx301B95fGH5RCxWGzWbN1CcVIxDdxzpQ4Z4m0WssYmwmqtTUZRhqLm+DqQk2zzENm8ayYaHICY2pzVeIMfii4QcPjsYa2sj2tyEJfss9x8fRR+/EAF0aftItaSQHE3nwIEDRCJq6Wll6FEFsnJSJ1okpLk3SL4nfhrOEYyh6z0E+g5hsSeRMa4cYMCSzbW9tRjSOGWB7FuzFgDP/Hkn3e+6666jvLycN954g8cff5yamhq+fuVoZpSk8p/P7SRlagZVYRNTCPqiHzumF9lqd1A06SKqNr2DJjTKUsuOzGQB4Ln0UhBCtVkoijIstbY04glHcUSb2a5DupFOrxBEo1EMw0DGNGwOHc3hQM/IIFJ7kGh9A7bi4nMWk2V0fPEoW/QdwkaAQmFHYrKvQrVZKEOPKpCVk4q1t51wBDmnf5pjR0hDc0IkUEtyVhnWzEwQgljLsSPIVV2nt8S0f/Uq9MwM7OPGnXQ/Xde58cYbufbaa2lvb+fPf/4zv/rFz7nOfYAJ1ha+9c915E7N5EDEJGAsILbhJQh2H3n8qBmz6Gtvo+3gAcamjaWis+JIS4UlPR3n5Mn4Vq061T+RoijKkCKlpK2thZRACM0i2R7tJC2Wic9CfPQYMCICuyu+WIg1Lw//hg1gGNhKSs5ZXHr/xd453buo6dvBRRQipMbKFVvP2WsqyvulCmTlpIz2juOvotcTIv3wKnoxD1GHDWkGSCsYE78KOj39yJyah1V1V6EL/aQzWEjDwLd2HZ65807rQhFN05gxYwb33XcfH/vYxxg3bhw9XR2UmweYFtrC6oZX2Wk2YSLwBRcfM4o8cupMEIKqjW8zNm0sfZE+mvxNR+53z59HaOdOYp2dp4xDURRlqOhpaSYUCZPiD9NpEzRGukmOJROwiCMFsoxo2F3xxUKs+XnEmuK5zz5ixDmL6/CUct5wmIbobmxY8BheujsbMKLmOXtdRXk/VIGsnJAZCGD6/ejpxxbIMcOktS9MsiW+GIhDptPdn9uySscDYM3KIvqeHuR9XfsoTS7Fph97wd/Rgjt2YPb04Fkw/4xitdlsjB8/niVLlnDvvffyla98hZKpl+CPmbQn7+UVfSed8krMdY9DqAcAV3IK+WPGUbVpPWPSxgAc04fsWbAApMS/dt0ZxaIoipJITVXxdrGUQIid7vipvqSYk7BNO1IgC2k5MoLsnDjpyGMdpzhz90Hoycmg6xj2PDJdjTSH6ygWyZh6kFf+pRYNUYYWVSArJxTrX2b6vS0W7b4IhilxiihWDazYae/rQWjJpObkxB+TnU2s+dgR5L0de4/MGHEi/tVrQNNwz5nzgWJPSkrijusXMmHxjeyJFNBsaeN1y266A3Ng/R+O7Ddy+izaamvIjiYjEMcUyI7ycvTUVHyrVZuFoijDR1PlPiyahicUYXt6BlZhxWvoxOz6UQWyfmQE2btoIVitpHz0owir9ZzFJTQNPTUVw1FKkV7Lwd6djInlArBn/W5MU80apAwdqkBWTuhEi4Q09QSB+Cp6bhFfxrm19QCapejdU3Z5eUSb3m1X6Ah20BpsPWWB7Fu9GuekSWdtovrPLBjJ+Fmz6fWNpkX08Lw+EXPtb4+MIo+afjEAjdt3UJJcQkVnxZHHCk3DPW8e/jVrkaY6/acoyvDQVLWPNJcX3QJbHXamJU/BgsBwHFUgmxYc7ngxbCspYcyG9eR+/3vnPDZLRgYxmUyJp5d6/35c0ooVK6boYsvahnP++opyulSBrJzQuwXysSPIR1bRiwZxG/GffcFONGvhkYRrzcvD7O3F6I0vOX14ZHZc2olP38U6Ownt2oX7FLNXnAkhBN++bjyOCWPI95dxSPSwKnQprH8YgNTcfNILiqjcsI7x6ePZ07HnmMd75s/D6OwktHvPcZ5dURRlaIlFIrQeqCHD7kToJrtliJneafE73VZC/SvqaUeNIANozpMv3nS2WDIyiHX14i1fRLKjl5rIXgrNNML2Lta+XKPmnleGDFUgKydk9LdYvLcHubm3fxW9QA+u/pHVoNGHZik86qKPfACijY0AR0ZmD/f6Ho9/7VqQMt77exZpmuD7t0+lw15IYSyTt0QpTWv/AqF48T561jzqK3YzxlpKa6CV9mD7kce6580DIVSbhaIow0JrbQ2mESPNNIhZJDFMxtn6ByY81qNGkI8tkAeLJTMzPvgy/d8Z6WqjubOColgGaDGkr4uaXR2DHpOiHE9CCmQhxFVCiH1CiCohxDePc/8nhRA7+r/WCSEmJyLOC12stQ2EwJKWesz25p4QNotGwO/HKS1IJJrXi9Dc744gHy6QG+KnzPZ27iXfk0+yPfmEr+dbvRo9NRVHeflZPxZdE9x+52Ty/KOxY+Xl8BzMd+IzWoydG78YL7U2Pln90aPIlrQ0HOXl8d5oRVGUIa6pMn6BXnrYR8ganwko14znY1uy47gX6Q0mS0YGsfZ25IiFlGZbaQ0exCXjpYjP3smK56sGPSZFOZ5BL5CFEDrwW+BqYDzwcSHE+PfsdgC4REo5Cfg+8PDgRqlAfGUlPT19wEUbTT0h8pJsBKMmTuElZPhJyo4v/nFkBLng2AK5oqPipO0V0jTxr1mLe948hHZu3pa5pclQnM706EjqRSbbVr0MgU7S8grIKhlJ345qBILdHbuPeZxnwXyC27djdHefk7gURVHOlqaqfXjTM7H7e/BbBSOSSqAvnlOdafECWRMaAg27OxEjyBkQjWL09pF3ycew6DFqYhWkmR7C7m4ijQGaD/QMelyK8l6JGEGeCVRJKWuklBHgb8CSo3eQUq6TUnb133wHKBjkGBXiS0VbsjIHbG/uCZHvib91rCKdQLQXd+rI+KpMeny7npKCcLmINjTgi/io66s76QV6od27MTo7T7l63gc1ZclIkkI5pJteVhozqPrHfwMwZs58WqurGKMVDehDds+fD6aJf52a7k1RlKGtqXIfuWVjMH29dNsEU7KnEekOE0CS5LURDofRNSsWu46uD34JYMmMf6bE2trQpt1Gqbubto695JtpWLRegiLGyheqBz0uRXmvRBTI+cCho27X9287kU8Dr57oTiHEZ4UQm4QQm9ra2s5SiApAtK0Va2bWgO1NvUFK7D4ArEYSAaMXu6sYu/vdkWYhBLb8PCKH6tnXFT/lNy79xCPIvtWrQYh4z+85lFOajC/bzcWxUfQJD61V21m3ZRtj58T7nie0Zw0okJ2TJqElJ+NTbRaKogxh/u4uettayB01mkDQR9AqmJI1BaM3QgcmyW4boVAIXVhxJKD/GN696NtobwdvDqNGlxDxd2PXQSKp8XbRsa+brmZ/QuJTlMMSUSAfb3m04162KoRYSLxA/saJnkxK+bCUcrqUcnpm5sDRTuX9i7W2Yck6tkA2TUlLT5hRRi0AbsMLbp1o1DLggg9rUTGRuoPsbo+3LIxPf28nzbv8q1bjKC/HkpZ2dg/iOEZdW4o3mkKWSOFtMZ2GF77D7l6dvNHjSK4JD7hQT+g6nrlz8K1ZraZ7UxRlyGqq2g9A7sgygpEIEQtMzZqK8EfpQJLi6i+QsSbkAj04dgQZYMRH7gFh0hDahy41inIjGEjefqU2IfEpymGJKJDrgcKjbhcAje/dSQgxCXgEWCKlVJe1DjIZjWJ0dAwokDv8ESKGSXo4fhLALZ04c1MI9kVxeo7tVbaXlhA9WMfO1u3kufPIcA5cshrA6O4muGPHGa+e934VlqfT5rAyPVxKHx4KtW5+9qe/kzLxYozWHtK7bQPbLObNx2hrJ7xv36DEqCiKcqaaKvei6TpZKRoRQ4DNQoG3AD0Qox1JitNKMBhM2AV6AHpGf4HcP42oY9Q8MjMlPa2VZMtkHKF2dtsMaja1EPJFExKjokBiCuSNQJkQolQIYQNuBv519A5CiCLgOeBWKeX+BMR4wYt1dICUAwrkhu74IiH2YHyVPCc2UkfkE/JFcHqPXULaVlKCjEY5VLmVSZmTOBH/unVgmrjnDU6BLIQgc3ERWUYK2bZ01jKT+7U/8YO9DnSbnTF13uMUyHMBVJuFMqypGYTOb81V+8gsLsXSVYVhaCR70xBCYA8ZdAmJy6bHC2Rj4Bm/waJ73AiXKz5LUr9pl1yNHojg0TW6wz3YRloQJuxYrRYOURJn0AtkKWUMuAd4HagAnpFS7hZC3CWEuKt/t28D6cDvhBDbhBCbBjvOC12stRVgwEV69V0BbESJBv1YkVjQyRw3sn8EeWCBDGCpbzlpgexbvQYtORnnpIln9yBOYvTcPFrQuMhXRB9uJDoLjLc5mDKGkU0eKhp3HrO/NSsL+9ix+FevHrQYFeVsUjMInd9M06CpqpKcUWOoblyPJQYZqYWY4RhWE/xWDSEEoVAIGdUHnPEbTIenejus7No7MTWTzkD84ryF2SYHLQZbltdhGqqtTUmMhMyDLKV8RUo5Wko5Ukr5w/5tD0kpH+r/+U4pZaqU8qL+r+mJiPNC9m6B/J4R5K4gE8QBeqUTm9E/Y0Wqm2jYwOE9NuEeLpDzOmFixvGLX2ma+Nasxj1nNsIyeCMaulXDPi2bAjOVLFc6a/W5fMfxDNtsxegG+LYNnIvTM38ega1bMXy+QYtTUc4iNYPQeayz/hDRUJC8sjGsb9uGPQrZmaUYvfH53cMODSklwWAQGdFwvOeM32CyZGYe6UEGsDldOEpS6G2qximthBrraMiwYPhiHNjefpJnUpRzR62kpxzX4eRlfU+BXN8VZJ69ih7pxRbVkEIS7r/vvSMSeno6UZeNwk5xwhkswnv3YrS14xmk9oqjjb22lE4DyvsK6DKc7A+n8dCkHbS4nORVSdoDxyZm97z5EIsReOedQY9VUc6CszaDkJo9aOhp7F8gJGfUGDYEGrDHIMmbeaRAjjkshMPh+FLOhmVIjSADTLz8I9jDkkwpOdDTwGXz8+jWTNa9WpuYIJULniqQleOKtraCrqO/Z1aJhu4gs61VdJOMS9oQbv3IhRTv7UEWQtCcY2dMhwO7bj/u6/QtXwFC4Lnk7C4vfTocbivREcmMiKaT7k1jteMKyg48RUpZASk+G48+99dj9ndNuQjN5VJ9yMpwddZmEFKzBw09TZV7cXi8JGWksc2I52ThcGD2xQtk6bEQDMavIdFkggvkzMwjZykPm7fgwwScBqHeBmLCoDzQwW6XSe8hH211fQmKVLmQqQJZOa5YayuWjAyErh+zvaEzwJhYJWFhxyvcWNPdBE9QIMfMGBUZIXKbw0jDOO7r9K1YgXPKlCNzYw620utHEjJhXKiQtpDOPtfFfMG5HL89Rvubb7GzvvvIvsJmwzV7Nv7Vq+OjMIoyvKgZhM5jjfsqyBs9ln0HVxAx4x/tmsNxZARZ89gJhUIACNOCw5O4FgtrTjamz3dMu5rFYiU6KZtA0yEcUmf/rp2MnpVDFMnGZXUJi1W5cKkCWTmu482BLKVE764GGQMgVU/Bkuog2D9C8d4RiX2d+6jKNLCEY0QODkxwkfoGwhUVeBcvPkdHcWrp+R46k+2M7ksjJSmZ1a4rSeqpo6UsRE5fiG/9/gU6fOEj+3vmzyPa2EjkwIGExawo75OaQeg8FezrpbOxnrzR43jn4HLs8RSNcMYL5BASp9d6ZARZmBac3gSOIOfmAhBrajpme/nCyzA1SVYkQk2omY+NTqXCZlCzuZVwQE35pgwuVSArxxVrbT0yofthPcEo5UYFzbEUAJKlB0uynWDf4RHkYxPuhuYNHMiOn9UNVRw7bRqAb8VyALyLF53t8M9I9hXFSCkYTymN7b3UjP8iuUkHCTgMRtWv5Z6nthDrv5L68Ep/ajYLZbhRMwidvxr37wUgf8x4VrdvZ0x/Mak5HER7w0cWCXm3xcKKw524AtnaXyBHm5uP2b6gbDG1OX58rXWYQtLy5jIY5UEYkj3rmo73VIpyzqgCWTmuWGvrcaZ4CzJN7Kc6Gj9L65EO9BQ7IV8ETRfYnMfOQrGxeSOW0hKE00lwy9YBr9G3bDn2slFHZrtIlOJp2TTpGmWtqXjdHlb7S5nkymLHiG5yQ00c2rODn7wa/wCyFRRgKy1VfcjKsKRmEDo/Ne6vQNN1nAVZbAu3cnEk3j4h7HYiPWHaMUlxHTuC7EhgD/KRArnx2KI315NL96Qkor4O0k0r29qbufViJ426yYbldaq1TRlUqkBWBjAjEYyurgEtFvVdQWZpFTTKPABc0o6ebCfQv4qeEO9eAxQzY2xp3cK0gotxTZ+O/z0zP0RbWghs2oTnssvO/QGdgtAE7rn56FJQ7hxJ7cE6cqZ8h8pCH7o9xpLQBh5dXc0/t8UnrXfPn0dg40bM/n4+RVGURGrcV0FW6Ug2dGzGAKbZ4rPzaW43Rk98BDnDYz9SIFt1G1a7fpJnPLcsmZmg60SbB44KTy6fy6GcEPbubnq0MM43n6YxVRLritC4v3vwg1UuWKpAVgYwTjDFW1dTNcWiha6oHQsCGxb0VAehvsiAOTX3du7FH/UzI2cG7lmziFRXE21596rlnudfANMk5cMfPteHc1pGLyqk3oCyhlRcTicVu9vw2Fz0jWhC627hQ9ZqvvGPHexu7MEzfz4yHCawcWOiw1YU5QJnxGI0V+0nb/Q4Vh1cRqphUOIZDcQLZPqitGCS3n+RnhAaLo/jmAGNwSYsFixZWcQaBxbI8/LnsXVkJ70tFSRJB2v9SXw15wmCQrL2tdrBD1a5YKkCWRngcCH73hFkR/06WkMeYpqO2+qM75PmwN8TwZ18bIG8oXkDANNzph9ZprnvjTeA+Ah11zNP45o5E1tx8Tk9ltNld1pgYgZWU2NayngOHDjAdNtstoxJo9jdRVntcnIsET73xGYi4ycj7HZ8b61KdNiKolzg2mpriEUj5JSNYU3DWuYFQuCIn+UTFheaIWnGJN0T70G2CFtC2ysOs+bmDuhBBpiWPQ1/moYclU5aT4BOLUJ3q0GSYyete7vw94SP82yKcvapAlkZINoUn/npcJ/YYZnt69kXyMG02EiyetE8VjS7jr8njDv52HmONzZvZETyCDKcGTjGjMExcSJdf/kLUkq6n/k7scYm0j/72UE7ptMx7spi6iImI2uTSEtJJeNQBjXhTmZceymxqMGX+56gvTfIvc9X4Jo9m74Vy1VPnKIoCdWwrwKAngzojvlZEAxiWtMBkEY8L7cgyXDHWyw0acGVlLgp3g6z5uQQbRo4guywOJiWPY2to7robN5OrpnCKm0s17n/iJCwefnBBESrXIhUgawMEG3sL5Dz8t7dKCVlga1UBnMRdidenFjSHJiGSbA3gjvl3QI5YkTY3LKZGTkzjmxLu+1WIjU1NH71a7T+7Ge4Zs3CPXfOoB3T6UjNcdNXnIQwNWa7JxDri1HWU0b1jMVMn1JE1aEQT3ofY2NVI6tzyok1NhGuqEh02IqiXMAO7dlBSk4u6/o2YUEwW/NiRuMf7WYk3mfcLiRJTguBQABiFlzJx1+4aTBZ83KJNTcjTXPAfXPy5rBTO0DxxdPJ6PQRkSbLUz5GgW0rlSv2YPq7Bz9g5YKjCmRlgGhjI3pycrx/7fC29mqSY910+QWGpuGMWLGkOwn0RpGSYwrkTS2bCMaCLCh4d3W8pOuuI/UTH6f35ZexFReT/4ufJ7QH7kTGX1ZMddggp9rG6JJRjOsex/qq9cz6yoOkJDvZsbuL11J+xqM9VqTQ6Fu2PNEhK4pygTINg0O7d1JYPomltUuZZegkZ0/C9PtACGQwfoYr6rEghMDn80HUOqAlLhEsObnISASjs3PAffPy49NpRmYX0NC1jSlmMdW+KNXpJqFYErUP3Acd1YMdsnKBUQWyMkC0sRFLft4x23p2L+eALxXTEi+EvUEbepoDf3e8H+zoAnl1/Wpsmu2YEWQhBDnf/jZjNm+i9J8vYElPH4QjOXNF49No9dqICZjjL0Nogu6N3SA0LrvnfroiLhrqQzyf8gMa0zNof21pokNWFOUC1XqgmkgwAIWpNPgauLKrDXInY/h8/TNYRAhrYHfH87PP50czrANa4hLBmtc/1VvTwD7kEckjyHHn8HZgK+WLL0O0HCTHTMEvwgQtvexomwb/twiqVw522MoFRBXIygCxxsZj2ysAWbmUnX25aEmpACSZzv4L9PoL5KNGJNY0rGFG7gycFueA59bc7iE5cnyY0ATjFxWy2x/DcijC6JIinEEnL7z4AkUTJzN+wSI2dhQQdJYwpbASaqpo37wu0WErinIBqtu9A4DtzoNYhYVFfh8UzMD0+dE8HmLdYTo1SPfaiEajhMMhhGnDNQRGkK35+QBE6w8NuE8IwcLChaxrXMfk66+nLlzBvNhoLFLQlVZJfWgc3fYJ8OSNsOH/Bjt05QKhCmTlGFJKog3vKZBjYTyNb1PvTya5ZCQASdKFJcM5YAT5UO8hantrmZ8/f9BjP1vGzsqlUdMI2nXm146lMnk/u3fsZtWqVVxy66exuT2s6JlB4PJPAGD8/GaMN38K0WCCI1cU5UJSt2s76QVFvN62krnOPJJMCQXTMfv60DxujM4QjcIkw2PH7/cDoJlDYwTZVhhfcCpy8PgX3S0uWkzYCLPNv4eLrrmWA20buSQ8Hqvmpze5klVJP4CyK+CVr8L6hwczdOUCkZACWQhxlRBinxCiSgjxzePcP1YI8bYQIiyE+GoiYrxQmT09mIEA1tyjCuS6t2n1WZEmuDOysFts2LFgzYwXyEITOPvnQV7dEF+CeTgXyDanhXGzc9nUGUb3S2Yao9HyNVauXMmWHTu59NZP01S1n478hYQLCmk8lIr+5g/hNzNg57OgZrZQFOUcM2JRGvbtwTkyj5ZAC1dEgdRScGdg+n3obg+xjiAHDYN0t+2oAnlojCBrLheWnBwitccvkKdlTyPJlsSKuhVM/9ANNJhV5EgPU51jiDhb2Vuxh9hH/gRjr4NXvwa7nhvkI1DOd4NeIAshdOC3wNXAeODjQojx79mtE7gX+Pkgh3fBi9TVAWArKnx3Y+UbVPZlYGgWYppOssWD7rGhuaz4e8K4kmxoWrxtYuWhlZQklVCUVJSI8M+aiZcW0BmV+LNcfLjjUg65aygvL2fZsmXU+kIUTZzC6r8+TuqVl2PriPGp3v+gGzf849Pw6OXQsjvRh6AoynmsqWo/sXCYSm87Dt3BwqYqKIhf92H4/GjeDGTE5KAZI91jj1+gR/8IclLiR5ABbMXFRGprj3ufRbNwaeGlvFn/JprDxvQPf4RtrSuY0pWP05JJwF3Fite3w789BoUXwz+/oPKuclYlYgR5JlAlpayRUkaAvwFLjt5BStkqpdwIRBMQ3wUtcrC/QD5qAQ+5fyl7fdmEs0bR1d1NknRiyYz3F/u6wkfaK7pCXWxs3sjlxZcPfuBnWUq2i9LJGbxT58O0CG6oWsDMy2cwe/ZsNm7cSCB/BDEJW/ydaNKkPKgxu+Pb1M//GXQegIcvhTW/guNMYaQoivJBHdy+BSEEr8fe4Yq8eXj6mqFgOgCmz4fmjS/01IAky/tugey0u9CtQ6O70lZScsIWC4BFRYvoi/SxqXkTF115HW32Zvz08hExGQwHb299neb2LvjYn8GeBH+/Q7W6KWdNIn5L8oGju/Lr+7e9L0KIzwohNgkhNrX1L5GsvH+RuoMgBNb+/jA6a2iubyQc1XCVTaa7uxtv2I410wVAb3uQ5AwHAMvrlmNIgytKrkhU+GfVrCUj8YcNWrOdTAyUUfnmVq688kquueYaDh46RGTMRVQeqKZj/Giub9tBmsfJxzaMpOOOVTD6Klj2XXjmVgj3JfpQFEU5z1Rv2Yi9KItuzc+Nrv58fVSBLBzxmYIaMMlNcRxpsfAmeRIS7/HYiosxurowenqOe/+cvDk4LU5er30di83GnI9+nM3Nr+PqkxTqUxGmzp8ef4LOqA0+8nto3w8rfjDIR6GcrxJRIB9vCoP33bQppXxYSjldSjk9MzPzA4SlAETr6rDk5KDZ+0/B7X6Bip4sDKFRNGECUkq8UTuWTBemYdLXGSYpIz6avLR2KUXeIsakjkngEZw9aXluxszOZcteP1WeBoo3eTF6I8ycOZNPfepT2BxOAiXjWJ+XTWDPbv6wMJPOQIS7n68jduPjcOWPYd+r8NjV4G9P9OEoinKe6G1vo622hpqMXkqTS5nSejA+gpozGegvkG0pSKAJk9xkJz6fDw0LyRlDqEAuKQFOfKGe0+JkUdEiltYuJWyEKV+wmEhqlA6zicXSha27nHAwwmOPPUardwJM+3d4+7fQuHUQj0I5XyWiQK4HjmpwpQBoTEAcynFEDtZhK3q3f9jY+TwVfbnUuErJ9VqB+BRv1iwnvq4w0pQkZTrpCnWxoXkDV5RcMaSncTtTM68rRSCo0Z3ohkbbC3sBKCgo4HN33UVxQT59GXksW3wp3ndW8uMbJrL+QCc/eW0fzL4bPvEMdFTBH6+BvoHzfSqKopypmi0bAVjvruLGshsRtaugeC7oFqRhYAYCILwEnDoxIDc5PoIsDCtJ/Wf8hgJbSbyV70R9yADXj7yevmgfKw+tRNN15t58K5uaXkWPGBR6kknumIQRNfnjH/9Iffld4M6AV7+hLpZWPrBEFMgbgTIhRKkQwgbcDPwrAXEoxxE5ePDdArmjmrqaQ4RiGrXJY7DG4qfokqQLa56H3vZ4r1dShpM3Dr6BIY3zov/4aN40B9OuLiZ40Msrri3E9vQQ2N4KgMvl4vZP38mIVC99qek81drCWEcfd8wp4ZE1B/jX9kYouwxueRZ6G+JzdoaOfypRURTldNVsXo+ZbCfo1bguYyp01kBpfOVSMxAAQJouWu2CNLcNh1Wnt6cXzbCSlD5wfvpEsRUUgKadcCYLgItzLibLlcWL1S8CUDZjNra8JBqiVcxHB1yk9k7Bbnfw+F+eZW/5V+HQ+viMQoryAQx6gSyljAH3AK8DFcAzUsrdQoi7hBB3AQghcoQQ9cBXgP8SQtQLIZIGO9YLTayzE6OrC9vIEfENu5+Lt1dY7LhGTqC9vR2bZsXtdqN7bfS2hwBISnfwz6p/MiplFOPSxiXwCM6NqVcVk1nsJdo6hkZvJ13PVxPrn/9Z0zRu+sznSW86gIyGefrppxkfrmB2oZNvPLuDfc19UDIPbnoC2vbC3z4JsXCCj0hRlOEqGgpRt3sHlWmdXDfqOtKbdsbvOFwg9/aC0JBRG/WaJDc5PmLc3d2DZjjwpg+dEWRhs2EtLCBcfeJlo3VN50MjPsTahrW0B9sRmsbcm29hU+OrSN1kvFsn2qUzKWsRWVlZPL2xhY1JV8GbPwIjNohHo5xvEnIpq5TyFSnlaCnlSCnlD/u3PSSlfKj/52YpZYGUMklKmdL/c28iYr2QhCurALCPKgMpiWx/jkpfJlWeMsbmp9LS0kKa8GDL9wLQ0x5E0wTN1LOjfQcfGfWR86q94jBd17js9vFYTSfLe9uRhkHXM/uQZvwUnt3l4vLbPo394D6KerrYt7eCCd3vMMnazF1/3kBPMAojF8GS30HtanjtPxN8RIqiDFe1O7diRKPUZvq4ddytUPMWuDIgKz5baqyrG+HKACmoNGLkJjsxDAOfvw/dsA+pFgsAx5ixhPfuPek+14+8HkMaR0aRSy+aTvqoEnb3rmWc0BEuScXqNq5acANlZWW83DuOZZ25yO1/G4xDUM5TQ2OuF2VICFdWAmAvK4OGzeyvbidmCnY5RzI2x0trayspERe2XDcAvW1BPOkO/nngBSzCwnUjr0tk+OdUWp6bi27IIamnlG3OPsI1PfS8Vnvk/jHzLiE/OZW+Q5XcctWVlJaWMM6sZZp/Pd965F9EozGYfBPMuRc2PQrb/pq4g1EUZdjas2YlYZtkxMSpjEoqgcqlMGoxaPGPc6OrCz0pvtDT9mCYvBQHvb29SCn7R5CHTosFgH3sGCJ1dRg+/wn3GZEygpk5M3mq4imiRhQhBHNvupWKlnUEvREut1mx2gXLHtvLNZctYdrUqaxhJs+/uoJYJDSIR6OcT1SBPEiiRpQn9jzBF5Z/ge+u+y5VXVWJDmmAcFUlWnIylqxM5MZH2dpdiCMjh0Z7LiOSBaFQiDTTjTUvXiB3NftJznTwUs1LXFp4KWmOtAQfwbk1b/EEGsZt42CdnXaPFd+qevybWwAQQnDZ3V/BFLDpsYf4xCc+wS233EJ6ShJpHTv50c9/xebNmzEu/S8omQ8vfRna9if4iBRFGU7CAT/Vm9ZTk9vH7RPugLp1EOyMrybXz+juQksqAGBPJEJuspOuri4AHFY3dqclEaGfkGPsOJCS8P6T58M7yu+gJdDCq7WvAlA0YRJFEyazuu5pdItGmV0QDsV45Xc7WbzwShZNLmRHtIinHn6AUEgVycqZUwXyIOiN9HL7a7fz040/pb6vntdqX+OjL36UVw+8mujQjhGurMI+ahQi2EXjhqW0Bl1Exs4HIfCa8b/u00wvtqIkjJhJV3OAHm8rnaFObii7IcHRD47Z15WxuvTvrKsP0K0Luv5RSWBnfAq3zIsuYrwnjbrOVqrWrWHUqFF84767CRXNpi0oefHFF/n1b3/HxlFfJmZxw/OfBUOthaMoyunZ8/YqZMxAL89nVu4sqHgJLI74CHI/o6sLPaUYI9lKEMhPddLd3Q1ARkZ6YgI/CcfY+LSgob0VJ91vXv48RqWM4o+7/ojsn6Fi7k230tXdSG9JB2VCJ8sp6W4L8o//2Uz5jI/xkZQKDrYHeOyxx+g5wVzLinIiqkA+x2JmjHtX3EtFZwW/uOQX/PPD/+TVG15lctZkvrn6m6xvWp/oEAGQhkG4ogLHmDGw/W9sbc/A7nSwwzGSsiwPHa3NCASZnjT0FDvdLQFMQ/JO+C1GJI9gbv7cRB/CoLi8+HKaSyqonrWKLRFJZ9Sk46kKutc2ADD33v/AHYqw/A+/JhIKomkaP7j9cqKjFvJGpIywsPHystU8KD7F+kZJdOXPEnxEiqIMF6vf+Du9riifuvxL8QUF9r4EIxeDzX1kn1hXF1pKMT0pNgBGZXriI8gSsvKGXoFsyc1FT0sjtGPnSfcTQvCpCZ+iqruKVfWrAMgbPZYR02ayes1TmHMyuFhYSE2CUDDGsz/bgsj5dz4hX6C7s51HHnmElpaWwTgk5TyhCuRz7A87/sDmls18b873jqwwl+pI5XeLf0dJUglfX/V1ukPdiQ0SCFdXYwYCOCeMp++th9jfl8GERVexucHP9JJUGhoaSBUePCVpCCHoaIgvW7rL3MTt5bejiQvjreSwOLij/A6Win9Qdped1rFptEZNfC/WUPnLzeg5ZcxIzcUX9LPy0YcAsOgav/7EVEaOKuOh5mKSJy4mNTOXV1nIg2u6WPfqM0QikQQfmaIML1JK1jas5Qfv/ID719zPXyr+gj964j7W4a61pZ7IgRbCY1K4OO9iOLg2Pn3k+OuP2S/W1ovmTKHOJhACRmS6aW/rRDPtZPRfYD2UCCFwTp1CYMuWU+57VelVFHoLeWDLAximAcAlt3yaWCTCnvrXkXNymS8tjLSaeFKtrH7Txpaer3GdpQaAxx57jJqamnN6PMr548KoahKktqeWR3c+yjWl1/ChkR865j6X1cVPF/yUnnAPv9ryqwRF+K7Qzvhf7w69im11IBEkT1tIbyjG1KJUGhsayIh6sRXHZ9vraPBjCgMtNca1I65NZOiD7qaxN5HtyuZXe37Own8fR9G9U2lOsmNr8dP2wFa8ZZ9hmlHM/jVrqdywDgC7RefhW6ex5KJ8HtzYyzuWSdxww4fJ1H0sXb+HBx54gDVr1hAOqyngFOVUukJdfH7557lr2V28VPMS7zS9w483/Jjrn7+ejc0bEx3eOfHk0/+DQLDk+s/FN2x+HOzJMO49BXJ3vP1glxmjINWJw6rT0daJHnOQljd0VtE7mmvqNKJ1dURbW0+6n1Wz8uVpX6aqu4pn9j8DQFpePtOu+zC731qGPjaK42OjKdB0LgkZTM62kWLJZ3PdbZRGxuB2eXjyySfZsWPHYByWMsypAvkckVLy4w0/xq7b+dqMrx13nzFpY7it/Daeq3yOTc2bBjnCYwV37ETzejAq/sS27kJGXzyX7d3xt8foJJNgKESOTMYxKgWA6up6upwtfHLCJ7Dr9gRGPvicFif/Mf0/qOis4Ik9T5BZ7GX6/5uJ7dbxtHusWHpMRpV9nI8U34fxTActf95O39oGRJOfX904ifuvGceb+9q47YVWMifN51M8Ta61j2XLlvHAAw/w1ltvEQwGE32YijIktQXauP2129nYtJFvzvwmq29azfKPLueJq5/AZXXx2Tc+y/K65YkO86za37aX4MYqoiVJzB6/CPwdsOefMPlmsLmO2VdGvEhpsNYfYlSmByklXT2d6IaTtFz3CV4hsVxTpwAQPI1R5MuKLmNO3hwe2PwADb54a9usG27Ck5rGskd+R8rENEq/OZN9o7x4wgbjLVYuT7IyqcvLRQfHkaKl8dxzz7F69eojvcyKcjyqQD5HltUtY13jOu6Zcg8ZzowT7vf5yZ8n35PP99/5PlEzcRdsBTZuxFmUwpY6CxFDMPvGj7O6sp2SdBfBziYAClxZWLJdxAyDjtogPanNfHLcJxMWcyJdVXIVi4sW8+DWB9nWug2A3AkZTP3WLOx3TqTCrbHb30d3uI2+Xc30vFhD2++20/TDDdzYHOWVD09mYl4Sd7+dzFomcmvPr1myYAKFhYWsXLmSBx54gBUrVhDoXxVLURQIxULcs+Iemv3NPHzFw3xy3Cex6lYALsq6iKeufYrx6eP52ltfO/J7OdxJKfn9X7+LI6Jz3U13xzdu/TMYEZh2x8AHWHMQWi/7232MzPTQ19dHNBbGZUnClWQb1NhPl6O8HM3rxbdq9Sn3FULw7dnfRgjB19/6OlEjis3h5LLPfIG2gwdY87c/Y02ys/jOizDumsBXvFHWaFtJsqyn2GljiW8ipbEsli9fzgtP/gPTNAfhCJXhSBXI50AgGuB/NvwPY1LHcNOYm066r9Pi5Jszv0lNTw1/qfjLIEV4rGhzM5GaGrDVsLm7iDGz5+PJLeTtmg7mlWVwoOYAHhxkjMlHCMFLG97AErMx7aKxOC1Da07NwSKE4L/n/De57ly+uOKL7Ovcd+S+/NGpXP6tueRlHmR3WyP/PPgbXut4FWNeHs7yNIJ7OnH8o5qf9Vp4ed5oto+4j1qZQ+Zb3+DFzkyK5y6hqLiEVatW8cADD7Bs2TL8/vO3t1JRToeUku++/V0qOir46YKfMi172oB9kmxJ/HbRb8l153Lfyvuo76tPQKRn11MVT+He3ok1O5XyKXMh3Adrfx1ffCh7/DH7xrp9aJ48oo4g4ZjJqCwPrf1tCzl5OYkI/7QIqxXP/Hn43noLeRoFa74nn+/N+R472nfwrXXfwpQmI6ddzOTLr2HzS89Tu2MrANNK0nn4y/N4vXQKwvobHLk/Iun2CUzyTmd8tIjt1bt49od/xr+7Q40mKwOoAvkceHjHw7QEWrh/1v1YtFPPOXlp4aUsKFjA77f/nrZA2yBEeCz/mrUA7HDmIIWF+Z+4g9WV7QQiBotGZ1BTXU1hLB3nuDS6Ql28vG4lANfOWTTosQ4lyfZkHrrsIWy6jdtevY3XDrx2zP3lX72dS7rXUhxOoqd3B88//X+squ/Ddkc5qR8djbDqJK9p5os1AueoR8hC45aeh/nv5Y18vyKFwMhF5BaVsmbNGh544AGWLl2qepSVC9bjux/n5ZqXuWfKPVxaeOkJ90txpPCbxb8hakb54oovEogO37Mwu9t389dXfkOqz8aiG26Pr1T6zkPxuY8X/deA/f3v1CCERlN/q/GE/GRqq+sAGDG6aDBDP2OehQsxOjoIbtt2WvtfUXIF9065l5drXub+NfcTMSJccuunSC8o4uUHf0pHffy4U1w2fnf7HJYmf5Ts9rep7tzClG/M5JJP30CRXsIeo5ZVf3mN+l9sJrS/SxXKyhGqQD7LKrsq+dOeP7Fk5BKmZE057cd9Y8Y3iBgRfrn5l+cwuuPz/f0hutJs7POnMu26j5Cclc0rO5tIdlrJFt1EjRgllhzso1P53tvfI7W9AGeqTnK669RPfp4rSiriqWueYnTqaL626mt85c2vUNtTC4DmcpH/859TXr2TsY5kjMguDm57iqd/8g7r93TivmUcmXdPxjE6lWgFtEYeYZZ/MivmGdwwtYAX9wf4/u4kfCMXUzJyNOvWreM3v/kNu3btUklcuaCsaVjDrzb/iiuKr+AzEz9zyv1Lk0v5+SU/p6anhv9a+1/D8velK9TFV9/8KtP3p+HNymLcvEug6yCsfQDGXAv5A0fQQxVdmKFeNttsOKwaY3O8HKiuQ485KR6XPfgHcQY8CxcinE66n3vutB9z58Q7+eKUL/JSzUt8/OWPU+M/yIe//m10i4Vnf/gtetvio+dOm86SO/8Ln3DTt/RHbD/UTfaIFO64/zZK8key3lrJ3o4DtD+2i6b/3UqoUhXKiiqQzyrDNPjOuu/gtXr5yvSvnNFji5KKuKP8Dl6qeWlQr8I21v6Rrt317CwqICUnl1k33kxPMMqru5q4ZmIOu7ftwC6tjJxYxtPVz7CqZi3FPeMZPSVv0GIc6nLcOTx21WPcfdHdrG1Yy5J/LuHeFfeytmEt9vJxZH/tq4xYv4VpOcXEQpVYxAtUrNnNU995h+07Oki6cTQ5X5uBZ04uITkT25pU7qsNsnLhOO6+uJgX9/n40R4vmdOvxu128+yzz/Lkk0/S2dmZ6ENXlHPuQM8Bvv7W1xmdOprvz/1+fBT1NMzJm8OXp36ZNw6+wSM7HznHUZ5dvoiPu5bdhXefj6Qejfk33Yau6fDPLwACrv7JgMeYYYNoK8Sat7HKb+eiwhQ0AS3tjThkCun5Q3MGi8N0j4eka6+h9+VXMHp7T+sxQgg+O+mz/GbRb+gIdnDzSzfzy6rfcfG9nyUaDvHXb3+Nxv17AfAkpcLcL7FQbOH3f3yUgx1+NE3jk3fcTGFhIW87KlhjdOCv99H+6C5aHtiCf2MzMmqcy8NWhjBVIH9Agd4eWmqqaDlQzRPbHmdn+06+OfOb72vZ5Tsn3kmht5D719xPb+T0EsQHsuUJen5/PzvzsvCjc+Xnv4TVZucfm+sJRU1umJjJ3v37KDNy2FVcx4/X/5gr5b+BKSibMbRHIwabVbPy+cmf55UbXuHfy/+d7W3buWvZXVz73LX8c6qB+7ZPkP36ChaMKicW7iTqewqXZycbXtzPk99+m91b2nAsKiX387mk2B+F7hpiS+u4eWM3y0oLuC0zhV+uaeeF4DjKL76E+vp6fve737F69WpisViiD19Rzon2YDufX/Z5rLqVBxc9iMt6Zmetbi+/natLr+Z/t/4vbx16C9M0aNy/l50rl7LrzWW01tYMuZHC3kgvX1j+BeqaqphTmU3+2HLGzlkAK38Atavhyh9AysB2icC2VpAaRm8FG7sl88syOXSogZgZoaiwBE07vT8sEintlluQwSAdjzx6Ro+7pPASXljyAh8d81FeOfAKt226my2XSgJmkKe/+w02/usfxKJRPJfcS9RbyH+Yf+RTj75Nhy+M1WrlE5/4BOkZ6dSk7mFXsWBrIEZXS4Cuf1TS+OMN9LxWS6xbLVd9oRFDLTl8ENOnT5ebNp376dIiwQDblr7CnlUrjvQ5AUgk4WwHH/63LzB2zgJ0y5mveb+zbSe3vXobi4sX87MFPzvt0ZIzYkThzZ8g3/o5r2yYxN7kZObedCuzbriJUNTgkp+tpDjNzWdK+lj7zjquTJnK3enfYVL6JK7bdQ+h3ii3fH/2uYntPBExIiyvW87T+55mc8tmHJqNb6/NYdSbNVgWL2J3URbVWzZic3pwpkwl6B+J1ZFOycR0StLrKN7+OSyjbsKfdjeBbW2Yvigxu8YyGeX5SIgJk1KYSC1V+/eSmZnJhz70IYqK3v3QlFIS6InQXu8j5I9ixExsDguuJBsp2a4hezX7hUQIsVlKOT3RcXxQ5yrvBqIBPv36p6nqruKxKx9jYubE9/U8wViQ21+5DbGrmfl1RYS7jl1yOL2giHk338bI6RcnPKdVd1dz38r7aOhr4HP7ZxGubeGWnzxI+qEX4fX/hKm3w4cehPfEKU1Jy4NbiNQeoLH5RW4u/Rgv3zuPPSveYnflFj75kTspu6ggQUd1Zhq+9nX6li6l5O/P4Bg9+owf3xnq5IWqF1hau5TKpgrm7UinqNUFyU7GX30VlxYn4fzXnfyveSPLsz/NXz8zC6dNp6enh0cffRTDMLh20b+xd0UHkYN9jHLpZGvxRVfsY1LxzM7DUZaKeB9/cIT8UXxdYcL+KJpFw+bUSc5wYrHpZ/xcyvt3urlXFchnIBoKsfX1l9j44nOE+nopGDeBEVNnIFOd/HLjL8jwOZjSlU93YyPe9ExmLLmRSYuvRLdYz+h1Htn5CA9ueZD7pt7HnRPvPLsHUb8ZXv4KNG1jdfulbGgzGDViNNf/6BcIIfjl0n38ekUVj318POteeJLCWDrP579E5oh8/iP72yz/fSWXfHw0Ey4ZHsl2KNjXuY+/7v0rL1e/xOJ3gty2wsRIT8HymTvZ19ZE9ab1ICUObzZSFGIa2WiWXDJt7WRnx8i+5FpSpUA/1Et4byfEJA2YvGUxSB4H/pZt9Pb2Mqp4PAWecfQ1m7Qd6iPYe+LV+VzJNjIKvGQWecgs8pJZ6MWb7kh4gXAhUQXyiXUEO7hn+T3s6dzDry79FYuK3v8Fwa21Nbz2f7+mraqK9tQo8z50E/NmXINpGBzas4vNLz1PZ2M9BeMmcNmdd5NeMPgXs4ViIR7f/TiP7nwUt9XN3V1XcGjlOi771OeYbK6F9b+HsdfBR/8E+sCBF//GZrr+UUlwwx94tbiQFyZcydJ75/GTH/4CGy6++u17hsUIMkCsrY2aj9yA5nJR/Pgfsea9/3a++r56ltctZ9M7S/G+00Z6rw1Dk8gskxGWBv6lfYTwyCv5/S3TSPfYaWtr47HHHkPTNG655Rak38nu1Q00bW2jQINiu4ZdCAyHjl6eQcbCQhwZx5/JKRo2aKvro6W2l9baXloO9NLXefxRaG+6g8xCLxmFnv7vXtwpNpWPzxFVIJ9F0VCIHctfY8M/nyXQ003JRdOY89FPkDtqDAd7D3LXG3fRE+7hyWufpNRbwoG1S1n/4vM0HmwgKcXDnMvmMm7RdWipxaCduqvFlCb/b83/4+Wal7n7orv53KTPfbClnE0TDrwFG/4P9r1M1JHJ8tDV7K44QAEWbvzz37DYHayraufWx95hQbmfsfU1xAIxXK4Y+uXpfGbs53juf7ZiRE0++b1Z6BbVnXOmesI9PF/5PG+/8Sc+/HwzJa3gy0/F9uElRLILqN23m4Z9ezGi8cJWt7hApIOWjaZnIiwZeJKyKXLZyDRMUg0TIQStsSgbLQdosh8CNFK1IkbllVMwMofMQi+uJBuaRRANGfi7w3Q2+Wk/1Ef7oT46m4NIM54D7C4LmUVeUnPcJGc5SclykZzlJCndgaar/++zTRXIx7evcx9fefMrtAZa+emCn7KwaOH7ep6Qz8e6vz/FttdfxuH1Mu2mj/HDvkeo6zvEl6Z+idvL47NCmIbBzhWvs+ZvTxAJBplx/Y1cfMPHsNr6F0AKdkHlG9CwGfxtYHVCagkUzoKi2cctWE+HlJK6vjperH6R5yufpzXYyuWFl3HZgVIqli5lyqyLWGh9A9G+Fy6+C678EWgDRxpjHUFa/ncrwhKi58kvcN8l9/Lx264iu7GODbtXMm/KFVy2ZM77ijFRgtu2UfeZzyJsNnK+9S28V17xgYvFrmAXyzY8x55VK6CmE08g/m8ZskK7J41Jk2ezeP5crKnp/PXppwkGg1x99dVMmTKFaMigfm8XdbvaCe3pIDtikGnVMKWkRQp6XBYiKXZMi040bODrDtPXHuRweeVNd5BdkkRmoYekdCcOjwXThFAgSk9rsD8n++huDUD/Y5xeKxmFXjILPWQUesko8JCU4VSfvWfBkC6QhRBXAQ8COvCIlPIn77lf9N9/DRAA7pBSnnKJnbOdqHtam9m5Yinb33iVkK+PogmTmfPRT5I/djzBWJBn9j3D77f9DguC3+UsZlL7wfgIbV8jUsJBfwqr20poDXlJtQWYlN7F+NEZuEbMgILpUDgTkvIHnC4DiJpRvrP2O7xY8yIX51zMl6Z9iQkZE04vcCmhtxHqN0DVcozqFXT7mmh1prLPcSl12/qI+oKUdPbS9IV5NGdo7G9rZU9rAx69h6ubFiINnYn2IqbftYji1BJee3gXNdvaWHLfReSPST1r/8YXIlOavH1oDVuf+l9GvLab0pb472BvfgqyfDT6yDHE7F46fb10HNxLR2snJvH3iBA6NncmVkcGXkc2mdZ8Ms1UMjQHvSLAFv0A1ZZmJFBgz6LMVUiBnoHHsCMjBmbYQIYNZLR/rlFdgC4wLBphIQhEDHqDBr6ISdCUBKUkhMCRZicp04U3zRH/Sn/3uzvFftZHp6QhkdF4nDJiICVodh3NYUFYz48PiEQUyOci956tvFvfV89f9v6Fv+79K8m2ZB5Y+AAXZV10xs8T9PWxY9lrbPzXs4QDASZffg3zbroVh8dDX6SP76z7Dm8cfINJGZP43OTPMT9/PkIIAr09vPXEo+xZtQJvWhozJucxwbYba/06MGNg84AnC6JB6IsvnoQrHcZ9CMYvgeJ5YLFhShN/1E9fpI++SB/+qB9f1HdkW0ughdqeWna076DZ34xAMDd/Lh9Lvorm55bRWHOAKfkhFno3IlKK4NpfwOgrjnus0WY/7Y/vxgwZhKr/zKF9e7j/I9/mj9eP4W9P/wm71cVX/9996MPwD9xwZSWN3/gmoT17cEycSPpnP4P30ksR1jM7I3s8ESPCqo1/Y+Mrv6e1z4a3x0GyP/68UoCekUYks4Sg1MhITmLymDJKR4zEk5KKKzmZWFSnbVcH4c0t2Jv96EY8h0cERHQNYdGwWDVsFoEOEDExQzEw3q23hE1DT7ajp9ixpDjQ0+zgseGLmXT0Rmlt9tNe76Oz0Y/Z/zghwJPqICnTQXKGk6RMJ0kZTpL7v9tdltP+Q0Ka/Tk2YsY/EwwT4bCgOeM59nwevR6yBbIQQgf2A5cD9cBG4ONSyj1H7XMN8EXiSfpi4EEp5cWneu73k6hjkQghv4+w30+wr4fOxgY6Dh3k4M5t8f5iISibMoWxC2YQSQpwoKOCje07ectXQ6eMMScY4jvtHeTFDEgtjRe+BTMgcyy40pFSUrlxA5tWvkVTYyeakGQ7/RQ6O8mwB0hOceMuHI+1YBK2zFL0tGKEOwOsTqTFyTMHX+E32/9Ad6SH8tQxzMqaRokzk3RhQ48GIeon4G+nu6+Rbn87PcFOukLddBoGfYaNUMyOxW8nvcdGXpsDe0zHHQozoq2dh6+J0Z6fgSecRlFfIYWhLAwjhikl87OncMmd16L190ZVb2nF3xNh0kLVWnE2tfhbeGfd3+l4/RVcFXWMaDDwHnUWLmzX6Mly0eeSBKwmIZudsDWJCHYiEYnZP/rr0D1kOgpItmai2z20OGPU230EtfjqjA7TilvacEgbmrCg6ToW3YYmdDRNxyJ1rCZYDIklCtrhghzQ0RBSEJMSwzQxDDP+3TQwTIkpBVaLFatVx2a1YLNacQgdm66jCx3dBCE1dECYAoGGoP+7FAhAMwVCgjBl/PtJ0pIUIK060q4h7RZw6AiHBeG0oLmsCLcV3W1BWnUMi4YB/TFLDENiSjANGf+AkBJN17DaNHSrjsUW/2Cz2A7/rKNbNaw2Hd2mYbFo76v38HgGu0A+V7n3TPOulJKOUAetgVaa/E1UdFSwqWUTm1s2owmNJSOX8OVpXybVcfI/xE3DIOTrI9jXi6+zk9baaur37qZ22xZMI8aIqTOYd/NtZBaXDnj9F6pe4KHtv6fR30SmPY3ZqWMZKxwU+LuJ7q2krtJKj9+Lrpsk57txjhkJhcWEPYKACNNndtPXU0NfVw19/jb6hKRX1+mz2PBhYnKcN7CM/z5ZpEaRlsFokcH4sJvcthgddV00dUkcWpSFOTWMG1+MmHorTP44WGxH4pbBGEZvhEiDj1BlF8Ed7WguC33XlfDrP/6D3h4/H73jUireWUkkHOXWW+6gZOTwzdkyFqP7uefoePj/iNbXo2dk4L38MtwzZmAvK8OSk4PmdCJO43ofKSXEYsS6ujA6Ooi2tBDdv4vIqifpbG6lzXDS4HTR6bQRtNmICSsyKZ9oRi7SYkPEougBHyIaBimRFg1ptaJZbbitXtyaF4dw4NEcOIUTp9WOwxb/stvtOJx2rHYb0jAgZsYHK3wGBEyEX6JF3tNXbpFIj0A6NAwNwlISMiShiEkoaBL0m0TCEh0dixDoAmxWDYdDx27TsFk0rFq8QNdMGc+thkQYJiIWv33CfysNpE1H2nWk3YK065hH/YxDx7RbwKGhWXV02+EvDd2iofcPYsSiJkb/VyxqYsTMI3lXyniRLoRAtwj0/lyrWwQWq4Zu0dGtIv58/c8Z3x7/+iB5eCgXyLOB70opr+y//Z8AUsofH7XPH4A3pZR/7b+9D7hUStl0suc+00S95m9PsP75pwdst1h0cm2djPS0M8rbQbItzD3ZmbzlivcaeQ2TWTH4uLOYGXmz4wVxwXRwn3hJaYD2uloq1r7Fod07aKmuPMESl5LD/+0CeWRw2QBMEf+SgCbFkUJCcOo3ip7swjuykMKLZ1DSGSFl2kzkayGiB/oA2K0fYoOlijJ3IfMunUfBzLJTPqdydkWNKNXd1VRXrKOjchdmXT2WhjbczT14uiMk9x5bPEsgYtEJWXWiuk5U14jp2pGfw7qGP8lLX2o6IU8SUaeLmM0B+uBcEKJJQZZM5rrINGJmFENGickYhhnFkDFiMkrMjGFqXkwtFUOCgYx/l/H3fPxniQQsQmAV9H8J7AJsGtiEwCbAJjitUQ8pJYd/8ySw1mfQbZxBHux/HaH1fxdw5WcmUDLx5L//A55m8Avkc5J7zzTvdoW6WPD0giO3NaFRllLGFSVXcP3I68lxn3rFt5aaKp78zy8N2J6UmU3ZxXMYP38hWSUjjv9gXxv8chxRM8rrbhdvuZy87XTQc/TvhYTsLjsjGtwUtDpxhwcWYBL57tk/0f+gI/lbxvNyfFP/1uO/NwWSTI/BmFGZTFowH8f4K+ItHO/R+ex+Apta3n2cw4J7ahbexUU0RaLc+adN/Pf15fTVbKW6upobbriBzMzM4/8bDDMyFsO3ajU9zz+Hf+06zMB7Fn/RNISt/8Jj04wXsFLGz6b23z4R4XRiy0rCQjemr49YWCMS0BGmwASCNit1RYU05+bSm5xC0OVEHNXqIqVE0P9aQsDptENKEyTY2xqwdcb/T3VhxWNJxm1NwWOJf7mtKTh0N3bdhV1zYtFOPnouidcIBhCTEDVkfGBDxm/Ht8v4zxJi9H/vz4mHc2s8nwrsGjgE2LV4vtVOkV+Pzq0xCa/1nrsZljSLIH90Ktffe9EZP3YoF8j/Blwlpbyz//atwMVSynuO2ucl4CdSyjX9t5cD35BSDsjCQojPAp/tvzkG2PfefQZRBtCewNd/P4ZbzMMtXhh+Mat4z70MwC2lHLQK5mzm3iGWd2F4vgdgeMY9HGMGFfdgGuoxF59O7n1/Vxd8MMf7E+S9Vfrp7BPfKOXDwMMfNKizQQixabhddDPcYh5u8cLwi1nFe+71x1wy2C97nG3vK/cOpbwLw/M9AMMz7uEYM6i4B9NwjPl4EtG5Xw8UHnW7AGh8H/soiqIop0/lXkVRlNOUiAJ5I1AmhCgVQtiAm4F/vWeffwG3ibhZQM+p+o8VRVGUk1K5V1EU5TQNeouFlDImhLgHeJ34VEOPSSl3CyHu6r//IeAV4ldRVxGfaujfBzvO92nInHI8A8Mt5uEWLwy/mFW8596gx6xy75A0HOMejjGDinswDceYBzivFgpRFEVRFEVRlA9q+M0eriiKoiiKoijnkCqQFUVRFEVRFOUoqkA+R4QQXxVCSCHEma0eMMiEED8TQuwVQuwQQjwvhEhJdEwnIoS4SgixTwhRJYT4ZqLjORkhRKEQYqUQokIIsVsIcV+iYzodQghdCLG1fz7cIU8IkSKEeLb/PVzRvxjGkCWE+HL/+2GXEOKvQghHomM63wyX3HuYysHn1nDNxTD88jEMv5x8MqpAPgeEEIXEl3OtS3Qsp+ENYIKUchLxZWj/M8HxHFf/Mrm/Ba4GxgMfF0KMT2xUJxUD/kNKOQ6YBXxhiMd72H1ARaKDOAMPAq9JKccCkxnCsQsh8oF7gelSygnEL5S7ObFRnV+GWe49TOXgc2u45mIYfvkYhlFOPhVVIJ8bvwK+zgkWNxlKpJRLpZSH14N8h/i8p0PRTKBKSlkjpYwAfwOWJDimE5JSNkkpt/T/3Ec8SeQnNqqTE0IUANcCjyQ6ltMhhEgCFgCPAkgpI1LK7oQGdWoWwCmEsAAu1BzDZ9uwyb2HqRx8bg3HXAzDLx/DsM3JJ6QK5LNMCHE90CCl3J7oWN6HTwGvJjqIE8gHDh11u55hkOQAhBAlwBRgfYJDOZUHiBcXZoLjOF0jgDbgj/2nIR8RQrgTHdSJSCkbgJ8TH91sIj7H8NLERnX+GOa59zCVg8+hYZSLYfjlYxhmOflUVIH8PgghlvX3EL73awlwP/DtRMd4tFPEe3if+4mfinoqcZGe1GkvPz6UCCE8wD+AL0kpexMdz4kIIa4DWqWUmxMdyxmwAFOB30sppwB+YMj2RQohUomPuJUCeYBbCHFLYqMaXoZb7j1M5eDEGy65GIZtPoZhlpNPZdAXCjkfSCkvO952IcRE4h9+24UQED9VtkUIMVNK2TyIIR7jRPEeJoS4HbgOWCyH7sTYw24JXCGElXhCfkpK+Vyi4zmFucD1QohrAAeQJIR4Uko5lAu4eqBeSnl4NOhZhnYyvgw4IKVsAxBCPAfMAZ5MaFTDyHDLvYepHJxYwywXw/DMxzD8cvJJqRHks0hKuVNKmSWlLJFSlhB/s0wdCgn6RIQQVwHfAK6XUgYSHc9JnM4yuUOGiH9KPwpUSCl/meh4TkVK+Z9SyoL+9+3NwIqhnoz7f68OCSHG9G9aDOxJYEinUgfMEkK4+t8fixnGF7AMJcMx9x6mcvC5NdxyMQzPfAzDMieflBpBVn4D2IE3+kde3pFS3pXYkAY60TK5CQ7rZOYCtwI7hRDb+rf9PynlK4kL6bz0ReCp/g/sGobw0shSyvVCiGeBLcRPpW/lPFmSVflAVA4+t1QuHlzDJiefilpqWlEURVEURVGOolosFEVRFEVRFOUoqkBWFEVRFEVRlKOoAllRFEVRFEVRjqIKZEVRFEVRFEU5iiqQFUVRFEVRFOUoqkBWFEVRFEVRlKOoAllRFEVRFEVRjvL/AUWcZtRuOEKfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 7))\n",
    "\n",
    "for ax, (name, df) in zip(axes.ravel(), data_dict.items()):\n",
    "    \n",
    "    for i in df.columns:\n",
    "        sns.kdeplot(df[i], ax=ax, label=i)\n",
    "    ax.set_title(f'{name} distribution')\n",
    "    ax.set_xlabel('')\n",
    "#     ax.legend()\n",
    "    if name=='original':\n",
    "        ax.legend(bbox_to_anchor=(0.4, 0.35, 0.5, 0.5))\n",
    "        \n",
    "# plt.legend(bbox_to_anchor=(0, 0.5, 0.5, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a85f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with  original  data: 0.717 +/-(0.040)\n",
      "Accuracy with   robust   data: 0.734 +/-(0.044)\n"
     ]
    }
   ],
   "source": [
    "# define and configure the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "pipe_dict = {'original': Pipeline(steps=[('m', model)]),\n",
    "             'robust': Pipeline(steps=[('rob', RobustScaler()), ('m', model)])}\n",
    "\n",
    "for i, pipe in pipe_dict.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipe, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    print(f'Accuracy with {i:^10} data: {np.mean(scores):.3f} +/-({np.std(scores):.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab0933",
   "metadata": {},
   "source": [
    "<a id=\"explore\"></a>\n",
    "<h2><ins>Explore Robust Scaler Range</ins></h2>\n",
    "\n",
    "The range used to scale each variable is chosen by default as the IQR is bounded by the 25th and 75th percentiles. This is specified by the quantile_range argument as a tuple. Other values can be specified and might improve the performance of the model, such as a wider range, allowing fewer values to be considered outliers, or a more narrow range, allowing more values to be considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b5d477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range=(1,99): 0.734 +/-(0.054)\n",
      "Range=(5,95): 0.736 +/-(0.051)\n",
      "Range=(10,90): 0.739 +/-(0.047)\n",
      "Range=(15,85): 0.740 +/-(0.045)\n",
      "Range=(20,80): 0.734 +/-(0.050)\n",
      "Range=(25,75): 0.734 +/-(0.044)\n",
      "Range=(30,70): 0.735 +/-(0.042)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = dict()\n",
    "for value in [1, 5, 10, 15, 20, 25, 30]:\n",
    "    # define the pipeline\n",
    "    robust = RobustScaler(quantile_range=(value, 100-value))\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(value)] = Pipeline(steps=[('r', robust), ('m', model)])\n",
    "    \n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print(f'Range=({name},{100-int(name)}): {np.mean(scores):.3f} +/-({np.std(scores):.3f})')\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518057ac",
   "metadata": {},
   "source": [
    "Interestingly, we can see that there are a couple of ranges that perform better than the default of 25-75. Box and whisker plots are created to summarize the classification accuracy scores for each IQR range. We can see a subtle difference in the distribution and mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e5c61",
   "metadata": {},
   "source": [
    "<a id=\"categ\"></a>\n",
    "<h1 align=\"center\">HOW TO ENCODE CATEGORICAL DATA</h1>\n",
    "\n",
    "Categorical variables are variables that classify observations into groups. They have a limited number of different values, called levels. Regression analysis requires numerical variables. So, when a researcher wishes to include a categorical variable in a regression model, supplementary steps are required to make the results interpretable. In these steps, the categorical variables are recoded into a set of separate binary variables. This recoding is called “dummy coding”.\n",
    "\n",
    "Machine learning models require all input and output variables be numeric. This means that if the data contains categorical data, it must be encoded into numbers before fitting and evaluating a model. \n",
    "\n",
    "<a id=\"var\"></a>\n",
    "<h2><ins>Nominal and Ordinal Variables</ins></h2>\n",
    "\n",
    "**Numerical** data involves features that are only composed of numbers, such as integers or floating-point values. **Categorical** data are variables that contain label values rather than numeric values. The number of possible values is often limited to a fixed set. \n",
    "\n",
    "- **Nominal Variable** - Variable comprises a finite set of discrete values with no rank-order relationship between values.<br><br>\n",
    "- **Ordinal Variable** - Some categories may have a natural relationship to each other, such as a natural ordering (i.e. 1st,2nd,3rd). This type of categorical variable is called an ordinal variable because the values can be ordered or ranked. In this situation, the variable comprises a finite set of discrete values with a ranked ordering between values.<br><br>\n",
    "- A numerical variable can be converted to an ordinal variable by dividing the range of the numerical variable into bins and assigning values to each bin. This is called **discretization**.\n",
    "\n",
    "Some algorithms can work with categorical data directly. For example, a decision tree can be learned directly from categorical data with no data transform required (this depends on the specific implementation). Many machine learning algorithms,however, cannot operate on label data directly. They require all input variables and output variables to be numeric. In general, this is mostly a constraint of the efficient implementation of machine learning algorithms rather than hard limitations on the algorithms themselves.<br>\n",
    "$\\;\\;\\;\\;\\;\\;$Some implementations of machine learning algorithms require all data to be numerical. For example, scikit-learn has this requirement. This means that categorical data must be converted to a numerical form. If the categorical variable is an output variable, you may also want to convert predictions by the model back into a categorical form in order to present them or use them in some application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb8a6b",
   "metadata": {},
   "source": [
    "<a id=\"encode\"></a>\n",
    "<h2><ins>Encoding Categorical Data</ins></h2>\n",
    "\n",
    "There are three common approaches for converting ordinal and categorical variables to numerical values. \n",
    "- Ordinal Encoding\n",
    "- One Hot Encoding\n",
    "- Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6dc59a",
   "metadata": {},
   "source": [
    "<a id=\"ord\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Ordinal Encoding</h5>\n",
    "\n",
    "In ordinal encoding, each unique category value is assigned an integer value. For example, red is 1, green is 2, and blue is 3. This is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used. For some variables, an ordinal encoding may be enough. The integer values have a natural ordered relationship between each other and machine learning algorithms may be able to understand and harness this relationship. \n",
    "\n",
    "An integer ordinal encoding is a natural encoding for ordinal variables. For categorical variables, it imposes an ordinal relationship where no such relationship may exist. This can cause problems and a one hot encoding may be used instead. This ordinal encoding transform is available in the scikit-learn Python machine learning library via the `OrdinalEncoder` class. \n",
    "- By default, it will assign integers to labels in the order that is observed in the data. For strings, this means the labels are sorted alphabetically. If a specific order is desired, it can be specified via the `categories` argument as a list with the rank order of all expected labels.\n",
    "\n",
    ">**If a categorical target variable needs to be encoded for a classification predictive modeling problem, then the `LabelEncoder` class can be used. It does the same thing as the `OrdinalEncoder`, although it expects a one-dimensional input for the single target variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8cc59",
   "metadata": {},
   "source": [
    "<a id=\"hot\"></a>\n",
    "<h5 style=\"text-decoration:underline\">One Hot Encoding</h5>\n",
    "\n",
    "For categorical variables where no ordinal relationship exists, the integer encoding may not be enough or even misleading to the model. Forcing an ordinal relationship via an ordinal encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories). In this case, a one hot encoding can be applied to the ordinal representation. This is where the integer encoded variable is removed and one new binary variable is added for each unique integer value in the variable.\n",
    "\n",
    "One hot encoding transform is available in the scikit-learn Python machine learning library via the `OneHotEncoder` class. We can demonstrate the usage of the OneHotEncoder on the color categories. First the categories are sorted, in this case alphabetically because they are strings, then binary variables are created for each category in turn.\n",
    "\n",
    "If you know all of the labels to be expected in the data, they can be specified via the `categories` argument as a list. The encoder is fit on the training dataset, which likely contains at least one example of all expected labels for each categorical variable if you do not specify the list of labels. If new data contains categories not seen in the training dataset, the `handle_unknown` argument can be set to `ignore` to not raise an error, which will result in a zero value for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3b62a4",
   "metadata": {},
   "source": [
    "<a id=\"dummy\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Dummy Variable Encoding</h5>\n",
    "\n",
    "The one hot encoding creates one binary variable for each category. The problem is that this representation includes redundancy. For example, if we know that [1,0,0] represents blue and [0,1,0] represents green we don’t need another binary variable to represent red, instead we could use 0 values alone, e.g. [0,0]. This is called a **dummy variable encoding**, and always represents $C$ categories with $C−1$ binary variables.\n",
    "\n",
    "In addition to being slightly less redundant, a dummy variable representation is required for some models. For example, in the case of a linear regression model (and other regression models that have a bias (intercept) term), a one hot encoding will cause the matrix of input data to become singular, meaning it cannot be inverted and the linear regression coefficients cannot be calculated using linear algebra. For these types of models a dummy variable encoding must be used instead.\n",
    ">There are occasions when a complete set of dummy variables is useful. For\n",
    "example, the splits in a tree-based model are more interpretable when the dummy\n",
    "variables encode all the information for that predictor. It is recommended to use the full set of dummy variables when working with tree-based models.\n",
    "\n",
    "**We can use the `OneHotEncoder` class to implement a dummy encoding as well as a one hot encoding.** The `drop` argument can be set to indicate which category will become the one that is assigned all zero values, called the *baseline*. We can set this to 'first' so that the first category is used. When the labels are sorted alphabetically, the blue label will be the first and will become the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf3116",
   "metadata": {},
   "source": [
    "<a id=\"bre\"></a>\n",
    "<h2><ins>Breast Cancer Dataset Example</ins></h2>\n",
    "\n",
    "This dataset classifies breast cancer patient data as either a recurrence or no recurrence of cancer. There are 286 examples and nine input variables. It is a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5082a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ade8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    8\n",
       "5    0\n",
       "6    0\n",
       "7    1\n",
       "8    0\n",
       "9    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bc = pd.read_csv('./datasets/Data Transforms/breast_cancer.csv',header=None)\n",
    "\n",
    "# confirms that all features have dtype = 'object'\n",
    "# df_bc.info()\n",
    "\n",
    "# checks for missing values\n",
    "# df_bc.isna().sum()\n",
    "\n",
    "# replace missing values from NaN to 'nan'\n",
    "# df_bc[[4,7]] = df_bc[[4,7]].fillna(\"'missing'\")\n",
    "# df_bc.fillna(np.nan)\n",
    "df_bc.isna().sum()\n",
    "# df_bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7d407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (286, 9)\n",
      "Output (286,)\n"
     ]
    }
   ],
   "source": [
    "# separate into input and output columns\n",
    "X = df_bc.drop(columns=[9]).astype(str)\n",
    "y = df_bc[9].astype(str)\n",
    "\n",
    "# summarize\n",
    "print('Input', X.shape)\n",
    "print('Output', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07411253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'yes'\", \"'no'\", 'nan'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b2ebeb",
   "metadata": {},
   "source": [
    "<a id=\"tran\"></a>\n",
    "<h5 style=\"text-decoration:underline\">OrdinalEncoder Transform</h5>\n",
    "\n",
    "An ordinal encoding involves mapping each unique label to an integer value. This type of encoding is really only appropriate if there is a known relationship between the categories. This relationship does exist for some of the variables in our dataset, and ideally, this should be harnessed when preparing the data. In this case, we will ignore any possible existing ordinal relationship and assume all variables are categorical. It can still be helpful to use an ordinal encoding, at least as a point of reference with other encoding schemes. We can use the OrdinalEncoder from scikit-learn to encode each variable to integers. This is a flexible class and does allow the order of the categories to be specified as arguments if any such order is known. Once defined, we can call the `fit_transform()` function and pass it to our dataset to create a ordinal transformed version of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd75e1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([\"'20-29'\", \"'30-39'\", \"'40-49'\", \"'50-59'\", \"'60-69'\", \"'70-79'\"],\n",
       "       dtype=object),\n",
       " array([\"'ge40'\", \"'lt40'\", \"'premeno'\"], dtype=object),\n",
       " array([\"'0-4'\", \"'10-14'\", \"'15-19'\", \"'20-24'\", \"'25-29'\", \"'30-34'\",\n",
       "        \"'35-39'\", \"'40-44'\", \"'45-49'\", \"'5-9'\", \"'50-54'\"], dtype=object),\n",
       " array([\"'0-2'\", \"'12-14'\", \"'15-17'\", \"'24-26'\", \"'3-5'\", \"'6-8'\",\n",
       "        \"'9-11'\"], dtype=object),\n",
       " array([\"'no'\", \"'yes'\", 'nan'], dtype=object),\n",
       " array([\"'1'\", \"'2'\", \"'3'\"], dtype=object),\n",
       " array([\"'left'\", \"'right'\"], dtype=object),\n",
       " array([\"'central'\", \"'left_low'\", \"'left_up'\", \"'right_low'\",\n",
       "        \"'right_up'\", 'nan'], dtype=object),\n",
       " array([\"'no'\", \"'yes'\"], dtype=object)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_ord = ordinal_encoder.fit(X)\n",
    "X_oe = X_ord.transform(X)\n",
    "\n",
    "# shows the categories for each feature \n",
    "X_ord.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99143123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless function to help identify the values assigned to each category\n",
    "# from pprint import pprint\n",
    "\n",
    "# df_bc[[4,7]] = df_bc[[4,7]].fillna(\"'missing'\")\n",
    "\n",
    "# full_dict = dict()\n",
    "\n",
    "# for i, col_name in zip(X_ord.categories_, [f'col_{i}' for i in df_bc.columns]):\n",
    "#     categories = [val.strip(\"'\") for val in list(i)]\n",
    "#     length = len(categories)\n",
    "  \n",
    "#     enc_dict = dict()\n",
    "#     enc_dict[col_name] = dict(zip(categories, range(length)))\n",
    "    \n",
    "#     full_dict.update(enc_dict)\n",
    "#     print(enc_dict)\n",
    "\n",
    "\n",
    "# pprint(full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da28e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505f7358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=1)\n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train)\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735a6fe",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "<h5 style=\"text-decoration:underline\">OneHotEncoder Transform</h5>\n",
    "\n",
    "A one hot encoding is appropriate for categorical data where no relationship exists between categories. The scikit-learn library provides the `OneHotEncoder` class to automatically one hot encode one or more variables. By default the OneHotEncoder will output data with a sparse representation, which is efficient given that most values are 0 in the encoded representation. Once defined, we can call the `fit_transform()` function and pass it to our dataset to create a quantile transformed version of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cee90e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_up'</td>\n",
       "      <td>'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'1'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'central'</td>\n",
       "      <td>'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'3-5'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1        2      3      4    5        6           7      8\n",
       "0  '40-49'  'premeno'  '15-19'  '0-2'  'yes'  '3'  'right'   'left_up'   'no'\n",
       "1  '50-59'     'ge40'  '15-19'  '0-2'   'no'  '1'  'right'   'central'   'no'\n",
       "2  '50-59'     'ge40'  '35-39'  '0-2'   'no'  '2'   'left'  'left_low'   'no'\n",
       "3  '40-49'  'premeno'  '35-39'  '0-2'  'yes'  '3'  'right'  'left_low'  'yes'\n",
       "4  '40-49'  'premeno'  '30-34'  '3-5'  'yes'  '2'   'left'  'right_up'   'no'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752c39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input (286, 9)\n",
      "One_Hot_Encoded Input (286, 43)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X_one = onehot_encoder.fit_transform(X)\n",
    "\n",
    "print('Original Input', X.shape)\n",
    "print('One_Hot_Encoded Input', X_one.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28323c",
   "metadata": {},
   "source": [
    "Running the example transforms the dataset and reports the shape of the resulting dataset. We would expect the number of rows to remain the same, but the number of columns to dramatically increase. As expected, in this case, we can see that the number of variables has leaped up from 9 to 43 and all values are now binary values 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a76d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.53\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=1)\n",
    "# one-hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=True)\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833cb04",
   "metadata": {},
   "source": [
    "<a id=\"dum\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Dummay Variable Transform</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "314fad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.53\n",
      "R^2: -0.30\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Converting splits into dummies while keeping train & test consistent\n",
    "all_data = pd.concat((X_train,X_test))\n",
    "\n",
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    \n",
    "    cat_dtype_train = pd.api.types.CategoricalDtype(categories=all_data[column].unique())\n",
    "    cat_dtype_test = pd.api.types.CategoricalDtype(categories=all_data[column].unique())\n",
    "    \n",
    "    X_train[column] = X_train[column].astype(cat_dtype_train)\n",
    "    X_test[column] = X_test[column].astype(cat_dtype_test)\n",
    "    \n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "score = r2_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(f'R^2: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1d2be",
   "metadata": {},
   "source": [
    "<a id=\"col\"></a>\n",
    "<h5 style=\"text-decoration:underline\">ColumnTansformer</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d13bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.30\n"
     ]
    }
   ],
   "source": [
    "# separate into input and output columns\n",
    "X = df_bc.dropna().drop(columns=[9]).astype(str)\n",
    "y = df_bc.dropna()[9].astype(str)\n",
    "\n",
    "# X.shape, y.shape\n",
    "\n",
    "oe_df = X[[0,1,2,3,5]]\n",
    "ohe_df = X[[4,6,7,8]]\n",
    "\n",
    "\n",
    "oe_df = pd.DataFrame(OrdinalEncoder().fit_transform(oe_df),\n",
    "                     columns=range(5))\n",
    "\n",
    "ohe_df = pd.DataFrame(OneHotEncoder(sparse=False, drop='first').fit_transform(ohe_df),\n",
    "                     columns=range(5,12))\n",
    "\n",
    "full_X = pd.concat([oe_df,ohe_df],axis=1)\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=1)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "781bd40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('ordinal',OrdinalEncoder(), [0,1,2,3,5]),\n",
    "                                    ('onehot',OneHotEncoder(drop='first'),[4,6,7,8])],\n",
    "                       remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=1)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2252fe",
   "metadata": {},
   "source": [
    "<a id=\"quest\"></a>\n",
    "<h2><ins>Common Questions</ins></h2>\n",
    "\n",
    "**What if I have a mixture of numeric and categorical data?** - Or, what if I have a mixture of categorical and ordinal data? You will need to prepare or encode each variable (column) in your dataset separately, then concatenate all of the prepared variables back together into a single array for fitting or evaluating the model. Alternately, you can use the `ColumnTransformer` to conditionally apply different data transforms to different input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ebac4",
   "metadata": {},
   "source": [
    "<a id=\"gaus\"></a>\n",
    "<h1 align=\"center\">HOW TO MAKE DISTRIBUTIONS MORE GAUSSIAN</h1>\n",
    "\n",
    "Machine learning algorithms like Linear Regression and Gaussian Naive Bayes assume the numerical variables have a Gaussian probability distribution. Data may not have a Gaussian distribution and instead may have a Gaussian-like distribution (e.g. nearly Gaussian but with outliers or a skew) or a totally different distribution (e.g. exponential). As such, better performance may be achieved on a wide range of machine learning algorithms by transforming input and/or output variables to have a Gaussian or more Gaussian distribution.\n",
    "> Power transforms like the **Box-Cox transform** and the **Yeo-Johnson transform** provide an automatic way of performing these transforms on data and are provided in the scikit-learn Python machine learning library.\n",
    "\n",
    "The Gaussian is a common distribution with the familiar bell shape. It is so common that it is often referred to as the normal distribution. Some algorithms like linear regression and logistic regression explicitly assume the real-valued variables have a Gaussian distribution. Other nonlinear algorithms may not have this assumption, yet often perform better when variables have a Gaussian distribution. This applies both to real-valued input variables in the case of classification and regression tasks, and real-valued target variables in the case of regression tasks. \n",
    "\n",
    "Some input variables may have a highly skewed or non-standaard distribution, such as an exponential distribution where the most common observations are bunched together. Some input variables may have outliers that cause the distribution to be highly spread. These concerns and others, like non-standard distributions and multi-modal distributions, can make a dataset challenging to model with a range of machine learning models. As such, it is often desirable to transform each input variable to have a standard probability distribution, such as a *Gaussian (normal) distribution* or a *uniform distribution*.\n",
    "\n",
    "There are data preparation techniques that can be used to transform each variable to make the distribution Gaussian, or if not Gaussian, then more Gaussian like. These transforms are most effective when the data distribution is nearly-Gaussian to begin with and is afflicted with a skew or outliers. Another common reason for transformations is to remove distributional skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69325e1b",
   "metadata": {},
   "source": [
    "<a id=\"power\"></a>\n",
    "<h2><ins>Power Transforms</ins></h2>\n",
    "\n",
    "**Power transforms refer to a class of techniques that use a power function (like a logarithm or exponent) to make the probability distribution of a variable Gaussian or more Gaussian like.** This is often described as removing (or minimizing) a skew in the distribution, although more generally is described as stabilizing the variance of the distribution.\n",
    "- We can apply a power transform directly by calculating the log, square root or inverse of the variable, although this may or may not be the best power transform for a given variable.\n",
    "\n",
    "Instead, we can use a generalized version of the transform that finds a parameter (lambda or $\\lambda$) that best transforms a variable to a Gaussian probability distribution. There are two popular approaches for such automatic power transforms: **Box-Cox Transform**, **Yeo-Johnson Transform**.\n",
    "\n",
    "These are some common values for lambda:\n",
    "- $\\lambda=-1.0$ is a reciprocal transform.\n",
    "- $\\lambda=-0.5$ is a reciprocal square root transform.\n",
    "- $\\lambda=0.0$ is a log transform.\n",
    "- $\\lambda=0.5$ is a square root transform.\n",
    "- $\\lambda=1.0$ is no transform.\n",
    "\n",
    "The optimal value for this hyperparameter used in the transform for each variable can be stored and reused to transform new data in an identical manner, such as a test dataset or new data in the future. These power transforms are available in the scikit learn Python machine learning library via the `PowerTransformer` class. The class takes an argument named `method` that can be set to *'yeo-johnson'* or *'box-cox'* for the preferred method. It will also standardize the data automatically after the transform, meaning each variable will have a zero mean and unit variance. This can be turned off by setting the `standardize` argument to *'False'*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4baff",
   "metadata": {},
   "source": [
    "<a id=\"sonar\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Sonar Dataset</h5>\n",
    "\n",
    "The sonar dataset is a standard machine learning dataset for binary classification. It involves 60 real-valued inputs and a two-class target variable. There are 208 examples in the dataset and the classes are reasonably balanced. A baseline classification algorithm can achieve a classification accuracy of about 53.4 percent using repeated stratified 10-fold cross-validation. Top performance on this dataset is about 88 percent using repeated stratified 10-fold crossvalidation. The dataset describes sonar returns of rocks or simulated mines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57d9f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df_son = pd.read_csv('./datasets/Data Transforms/sonar.csv', header=None)\n",
    "\n",
    "# summarize the shape of the dataset\n",
    "print(df_son.shape)\n",
    "\n",
    "# summarize each variable\n",
    "df_son.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d87dd915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.533654\n",
       "R    0.466346\n",
       "Name: 60, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy score\n",
    "df_son[60].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04f1655c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 60 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histograms of the variables\n",
    "fig = df_son.hist(xlabelsize=4, ylabelsize=4,layout=(6,10))\n",
    "[x.title.set_size(7) for x in fig.ravel()]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368de7c0",
   "metadata": {},
   "source": [
    "The descriptive statistics of the input variables shows that values are numeric and range approximately from 0 to 1. From the histogram, we can see that many variables have a skewed distribution. The dataset provides a good candidate for using a power transform to make the variables more Gaussian.\n",
    "\n",
    "Next, we will fit and evaluate a machine learning model on the raw dataset using k-nearest neighbors algorithm with default hyperparameters and evaluate it using repeated stratified k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1771cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.797 (0.073)\n"
     ]
    }
   ],
   "source": [
    "X = df_son.drop(columns=[60])\n",
    "y = df_son[60]\n",
    "\n",
    "# ensure inputs are floats and output is an integer label\n",
    "X = X.astype('float32')\n",
    "y_le = LabelEncoder().fit_transform(y.astype('str'))\n",
    "\n",
    "# define and configure the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report model performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5a5d1",
   "metadata": {},
   "source": [
    "The model achieved a mean classification accuracy of about 79.7%, showing that it has skill (better than the baseline of 53.4%) and is in the ball-park of good performance (the best being 88%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e376f",
   "metadata": {},
   "source": [
    "<a id=\"box\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Box-Cox Transform</h5>\n",
    "\n",
    "The **Box-Cox transform** is named for the two authors of the method. It is **a power transform that assumes the values of the input variable to which it is applied are strictly positive. That means 0 and negative values are not supported.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd205c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56e1c7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This does not work\n"
     ]
    }
   ],
   "source": [
    "# perform a box-cox transform of the dataset\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "\n",
    "try:\n",
    "    # NOTE: we expect this to cause an error.\n",
    "    X_trans = pt.fit_transform(X)\n",
    "except ValueError:\n",
    "    print('This does not work')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0902bd",
   "metadata": {},
   "source": [
    "As expected, we cannot use the transform on the raw data because it is not strictly positive. **One way to solve this problem is to use a `MixMaxScaler` transform first to scale the data to positive values, then apply the transform.** We can use a Pipeline object to apply both transforms in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "704fe940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 60 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform a box-cox transform of the dataset\n",
    "scaler = MinMaxScaler(feature_range=(1, 2))\n",
    "power = PowerTransformer(method='box-cox')\n",
    "pipeline = Pipeline(steps=[('s', scaler),('p', power)])\n",
    "data_trans = pipeline.fit_transform(X)\n",
    "\n",
    "# convert the array back to a dataframe\n",
    "df = pd.DataFrame(data_trans)\n",
    "\n",
    "# histograms of the variables\n",
    "fig = df.hist(xlabelsize=4, ylabelsize=4,layout=(6,10))\n",
    "[x.title.set_size(6) for x in fig.ravel()]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ce5f7",
   "metadata": {},
   "source": [
    "We can see that the shape of the histograms for each variable looks more Gaussian than the raw data.\n",
    "\n",
    "Next, let’s evaluate the same KNN model, but in this case on a Box-Cox transform of the scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0e34421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811 (0.085)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "scaler = MinMaxScaler(feature_range=(1, 2))\n",
    "power = PowerTransformer(method='box-cox')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('s', scaler),('p', power), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy',\n",
    "                           cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c96aaf4",
   "metadata": {},
   "source": [
    "The Box-Cox transform results in a lift in performance from 79.7% accuracy without the transform to about 81.1% with the transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ea89a",
   "metadata": {},
   "source": [
    "<a id=\"yeo\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Yeo-Johnson Transform</h5>\n",
    "\n",
    "The Yeo-Johnson transform is also named for the authors. **Unlike the Box-Cox transform, it does not require the values for each input variable to be strictly positive. It supports zero values and negative values.** This means we can apply it to the sonar dataset without scaling it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f3f3576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808 (0.082)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('p', power), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy',\n",
    "                           cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003dc4b",
   "metadata": {},
   "source": [
    "The Yeo-Johnson transform results in a lift in performance from 79.7% accuracy without the transform to about 80.8% with the transform, but is slightly less than the Box-Cox transform that achieved 81.1%.\n",
    "\n",
    "**Sometimes a lift in performance can be achieved by first standardizing the raw dataset prior to performing a Yeo-Johnson transform.** We can explore this by adding a `StandardScaler` as a first step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "286ca455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816 (0.077)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('s',scaler),('p', power), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy',\n",
    "                           cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ccd06",
   "metadata": {},
   "source": [
    "Standardizing the data prior to the Yeo Johnson transform resulted in a small lift in performance from 80.8% to 81.6%, as well as having a small lift over the results for the Box-Cox transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec385930",
   "metadata": {},
   "source": [
    "<a id=\"change\"></a>\n",
    "<h1 align=\"center\">HOW TO CHANGE NUMERICAL DISTRIBUTIONS</h1>\n",
    "\n",
    "Numerical input variables may have a highly skewed or non-standard distribution. This could be caused by outliers in the data, multi-modal distributions, highly exponential distributions, and more. Many machine learning algorithms prefer or perform better when numerical input variables and even output variables in the case of regression have a standard probability distribution, such as a Gaussian (normal) or a uniform distribution. The **quantile transform** provides an automatic way to transform a numeric input variable to have a different data distribution, which in turn, can be used as input to a predictive model.\n",
    "\n",
    "`RobustScaler` and `QuantileTransformer` are robust to outliers in the sense that adding or removing outliers in the training set will yield approximately the same transformation. But contrary to `RobustScaler`, `QuantileTransformer` will also automatically collapse any outlier by setting them to the a priori defined range boundaries (0 and 1). This can result in saturation artifacts for extreme values.\n",
    "\n",
    "<a id=\"quant\"></a>\n",
    "<h2><ins>Quantile Transforms</ins></h2>\n",
    "\n",
    "A quantile transform will map a variable’s probability distribution to another probability distribution. Recall that a quantile function, also called a percent-point function (PPF), is the inverse of the cumulative probability distribution (CDF). A CDF is a function that returns the probability of a value at or below a given value. The PPF is the inverse of this function and returns the value at or below a given probability.\n",
    "\n",
    "The quantile function ranks or smooths out the relationship between observations and can be mapped onto other distributions, such as the uniform or normal distribution. The transformation can be applied to each numeric input variable in the training dataset and then provided as input to a machine learning model to learn a predictive modeling task. This quantile transform is available in the scikit-learn Python machine learning library via the `QuantileTransformer` class. The class has an `output_distribution` argument that can be set to *'uniform'* or *'normal'*. It also provides a `n_quantiles` that determines the resolution of the mapping or ranking of the observations in the dataset. This must be set to a value less than the number of observations in the dataset and defaults to 1,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f00255",
   "metadata": {},
   "source": [
    "<a id=\"nqt\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Normal Quantile Transform</h5>\n",
    "\n",
    "We can apply the Quantile transform using the `QuantileTransformer` class and set the output_distribution argument to 'normal'. We must also set the n_quantiles argument to a value less than the number of observations in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "919e3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69dc5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817 (0.087)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', transformer), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894d5a0",
   "metadata": {},
   "source": [
    "<a id=\"uqt\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Uniform Quantile Transform</h5>\n",
    "\n",
    "Sometimes it can be beneficial to transform a highly exponential or multi-modal distribution to have a uniform distribution. This is especially useful for data with a large and sparse range of values, e.g. outliers that are common rather than rare. We can apply the transform by defining a `QuantileTransformer` class and setting the `output_distribution` argument to 'uniform' (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7318c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845 (0.074)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "transformer = QuantileTransformer(n_quantiles=100, output_distribution='uniform')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', transformer), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6bfa4a",
   "metadata": {},
   "source": [
    "<a id=\"select\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Select Number of Quantiles</h5>\n",
    "\n",
    "We chose the number of quantiles = 100 as an arbitrary number. This hyperparameter can be tuned to explore the effect of the resolution of the transform on the resulting performance of the model. The example below performs this experiment and plots the mean accuracy for different `n_quantiles` values from 1 to 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c485e731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.534 (0.016)\n",
      ">2 0.813 (0.085)\n",
      ">3 0.840 (0.080)\n",
      ">4 0.854 (0.075)\n",
      ">5 0.848 (0.072)\n",
      ">6 0.851 (0.071)\n",
      ">7 0.845 (0.071)\n",
      ">8 0.848 (0.066)\n",
      ">9 0.848 (0.071)\n",
      ">10 0.843 (0.074)\n",
      ">11 0.838 (0.069)\n",
      ">12 0.838 (0.069)\n",
      ">13 0.846 (0.071)\n",
      ">14 0.842 (0.071)\n",
      ">15 0.845 (0.068)\n",
      ">16 0.841 (0.074)\n",
      ">17 0.846 (0.071)\n",
      ">18 0.842 (0.075)\n",
      ">19 0.840 (0.075)\n",
      ">20 0.838 (0.076)\n",
      ">21 0.843 (0.071)\n",
      ">22 0.845 (0.073)\n",
      ">23 0.843 (0.068)\n",
      ">24 0.845 (0.072)\n",
      ">25 0.840 (0.077)\n",
      ">26 0.843 (0.072)\n",
      ">27 0.842 (0.073)\n",
      ">28 0.840 (0.076)\n",
      ">29 0.845 (0.072)\n",
      ">30 0.840 (0.075)\n",
      ">31 0.838 (0.076)\n",
      ">32 0.842 (0.075)\n",
      ">33 0.843 (0.074)\n",
      ">34 0.843 (0.075)\n",
      ">35 0.842 (0.075)\n",
      ">36 0.843 (0.073)\n",
      ">37 0.842 (0.075)\n",
      ">38 0.843 (0.075)\n",
      ">39 0.840 (0.076)\n",
      ">40 0.845 (0.074)\n",
      ">41 0.841 (0.072)\n",
      ">42 0.842 (0.075)\n",
      ">43 0.842 (0.074)\n",
      ">44 0.843 (0.074)\n",
      ">45 0.840 (0.076)\n",
      ">46 0.842 (0.075)\n",
      ">47 0.845 (0.072)\n",
      ">48 0.842 (0.073)\n",
      ">49 0.840 (0.073)\n",
      ">50 0.842 (0.072)\n",
      ">51 0.842 (0.075)\n",
      ">52 0.845 (0.071)\n",
      ">53 0.843 (0.075)\n",
      ">54 0.845 (0.074)\n",
      ">55 0.838 (0.076)\n",
      ">56 0.846 (0.073)\n",
      ">57 0.845 (0.073)\n",
      ">58 0.845 (0.075)\n",
      ">59 0.848 (0.073)\n",
      ">60 0.845 (0.074)\n",
      ">61 0.843 (0.073)\n",
      ">62 0.843 (0.074)\n",
      ">63 0.842 (0.075)\n",
      ">64 0.843 (0.073)\n",
      ">65 0.842 (0.074)\n",
      ">66 0.845 (0.074)\n",
      ">67 0.846 (0.075)\n",
      ">68 0.846 (0.072)\n",
      ">69 0.845 (0.076)\n",
      ">70 0.846 (0.075)\n",
      ">71 0.840 (0.075)\n",
      ">72 0.842 (0.074)\n",
      ">73 0.843 (0.073)\n",
      ">74 0.843 (0.075)\n",
      ">75 0.841 (0.075)\n",
      ">76 0.845 (0.074)\n",
      ">77 0.846 (0.074)\n",
      ">78 0.845 (0.076)\n",
      ">79 0.846 (0.072)\n",
      ">80 0.845 (0.075)\n",
      ">81 0.843 (0.073)\n",
      ">82 0.840 (0.076)\n",
      ">83 0.845 (0.075)\n",
      ">84 0.845 (0.074)\n",
      ">85 0.845 (0.074)\n",
      ">86 0.845 (0.076)\n",
      ">87 0.845 (0.075)\n",
      ">88 0.843 (0.075)\n",
      ">89 0.845 (0.074)\n",
      ">90 0.843 (0.075)\n",
      ">91 0.843 (0.074)\n",
      ">92 0.846 (0.074)\n",
      ">93 0.846 (0.075)\n",
      ">94 0.845 (0.076)\n",
      ">95 0.843 (0.074)\n",
      ">96 0.845 (0.074)\n",
      ">97 0.846 (0.073)\n",
      ">98 0.843 (0.073)\n",
      ">99 0.846 (0.075)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = dict()\n",
    "for i in range(1,100):\n",
    "    # define the pipeline\n",
    "    trans = QuantileTransformer(n_quantiles=i, output_distribution='uniform')\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(i)] = Pipeline(steps=[('t', trans), ('m', model)])\n",
    "    \n",
    "results = list()\n",
    "for name, model in models.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    results.append(np.mean(scores))\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.plot(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f84271",
   "metadata": {},
   "source": [
    "A line plot is created showing the number of quantiles used in the transform versus the classification accuracy of the resulting model.There is a bump with values less than 10 and drop and flat performance after that. The results highlight that there is likely some benefit in exploring different distributions and number of quantiles to see if better performance can be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446b281",
   "metadata": {},
   "source": [
    "<a id=\"cat\"></a>\n",
    "<h1 align=\"center\">HOW TO TRANSFORM NUMERICAL TO CATEGORICAL DATA</h1>\n",
    "\n",
    "The **discretization transform** (which maps numerical values to discrete categories) provides an automatic way to change a numeric input variable to have a different data distribution, which in turn can be used as input to a predictive model.\n",
    "- Many machine learning algorithms prefer or perform better when numerical features with non-standard probability distributions are made discrete.\n",
    "- Some machine learning algorithms may prefer or require categorical or ordinal input variables, such as some decision tree and rule-based algorithms. \n",
    "- Some classification and clustering algorithms deal with nominal attributes only and cannot handle ones measured on a numeric scale.\n",
    "\n",
    "Further, the performance of many machine learning algorithms degrades for variables that have non-standard probability distributions. This applies both to real-valued input variables in the case of classification and regression tasks, and real-valued target variables in the case of regression tasks.\n",
    "\n",
    "One approach is to use a transform of the numerical variable to have a discrete probability distribution where each numerical value is assigned a label and the labels have an ordered (ordinal) relationship. This is called a binning or a discretization transform and can improve the performance of some machine learning models for datasets by making the probability distribution of numerical input variables discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c23c9e",
   "metadata": {},
   "source": [
    "<a id=\"disc\"></a>\n",
    "<h2><ins>Discretization Transforms</ins></h2>\n",
    "\n",
    "A **discretization transform** will map numerical variables onto discrete values (i.e., categories). \n",
    "\n",
    "Values for the variable are grouped together into discrete bins and each bin is assigned a unique integer such that the ordinal relationship between the bins is preserved. The use of bins is often referred to as binning or k-bins, where k refers to the number of groups to which a numeric variable is mapped. The mapping provides a high-order ranking of values that can smooth out the relationships between observations. The transformation can be applied to each numeric input variable in the training dataset and then provided as input to a machine learning model to learn a predictive modeling task.\n",
    "\n",
    "Different methods for grouping the values into $k$ discrete bins can be used. Some common techniques include:\n",
    "- **Uniform:** Each bin has the same width in the span of possible values for the variable.\n",
    "- **Quantile:** Each bin has the same number of values, split based on percentiles.\n",
    "- **Clustered:** Clusters are identified and examples are assigned to each group.\n",
    "\n",
    "The discretization transform is available in the scikit-learn Python machine learning library via the **`KBinsDiscretizer`** class. The `strategy` argument controls the manner in which the input variable is divided, as either *'uniform'*, *'quantile'*, or *'kmeans'*. The `n_bins` argument controls the number of bins that will be created and must be set based on the choice of strategy, e.g. 'uniform' is flexible, 'quantile' must have a n_bins less than the number of observations or sensible percentiles, and 'kmeans' must use a value for the number of clusters that can be reasonably found. The `encode` argument controls whether the transform will map each value to an integer value by setting 'ordinal' or a one hot encoding 'onehot'. \n",
    "- An ordinal encoding is almost always preferred, although a one hot encoding may allow a model to learn non-ordinal relationships between the groups, such as in the case of k-means clustering strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c668f",
   "metadata": {},
   "source": [
    "<a id=\"uni\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Uniform Discretization Transform</h5>\n",
    "\n",
    "A uniform discretization transform will preserve the probability distribution of each input variable but will make it discrete with the specified number of ordinal groups or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14546ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ea95dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.829 (0.079)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "transform = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', transform), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fd707",
   "metadata": {},
   "source": [
    "The uniform discretization transform results in a lift in performance from 79.7% accuracy without the transform to about 82.7% with the transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6c087",
   "metadata": {},
   "source": [
    "<a id=\"kmean\"></a>\n",
    "<h5 style=\"text-decoration:underline\">k-Means Discretization Transform</h5>\n",
    "\n",
    "A k-means discretization transform will attempt to fit k clusters for each input variable and then assign each observation to a cluster. Unless the empirical distribution of the variable is complex, the number of clusters is likely to be small, such as 3-to-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c36f3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.814 (0.084)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "transform = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', transform), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbcb66",
   "metadata": {},
   "source": [
    "The k-means discretization transform results in a lift in performance from 79.7% accuracy without the transform to about 81.4% with the transform, although slightly less than the uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9e01e",
   "metadata": {},
   "source": [
    "<a id=\"qdt\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Quantile Discretization Transform</h5>\n",
    "\n",
    "A quantile discretization transform will attempt to split the observations for each input variable into k groups, where the number of observations assigned to each group is approximately equal. Unless there are a large number of observations or a complex empirical distribution, the number of bins must be kept small, such as 5-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "486a87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840 (0.072)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "transform = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', transform), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3207928",
   "metadata": {},
   "source": [
    "The uniform transform results in a lift in performance from 79.7% accuracy without the transform to about 84.0% with the transform, better than the uniform and k-means strategy.\n",
    "\n",
    "We chose the number of bins as an arbitrary number; in this case, 10. This hyperparameter can be tuned to explore the effect of the resolution of the transform on the resulting performance of the model. We can experiment and plots the mean accuracy for different n_bins values from two to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b536566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2 0.822 (0.066)\n",
      ">3 0.869 (0.073)\n",
      ">4 0.838 (0.078)\n",
      ">5 0.838 (0.070)\n",
      ">6 0.836 (0.071)\n",
      ">7 0.852 (0.072)\n",
      ">8 0.837 (0.077)\n",
      ">9 0.841 (0.069)\n",
      ">10 0.840 (0.072)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = dict()\n",
    "for i in range(2,11):\n",
    "    # define the pipeline\n",
    "    transform = KBinsDiscretizer(n_bins=i, encode='ordinal', strategy='quantile')\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(i)] = Pipeline(steps=[('t', transform), ('m', model)])\n",
    "    \n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef81958",
   "metadata": {},
   "source": [
    "A $k$ value of 3 achieves an accuracy of 86.9%. We can see a small bump in accuracy at three bins and the scores drop and remain flat for larger values. The results highlight that there is likely some benefit in exploring different numbers of discrete bins for the chosen method to see if better performance can be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9f52c",
   "metadata": {},
   "source": [
    "<a id=\"cluster\"></a>\n",
    "<h2 style=\"text-decoration:underline\">Grouping Observations Using Clustering</h2>\n",
    "\n",
    "If you know that you have k groups, you can use k-means clustering to group\n",
    "similar observations and output a new feature containing each observation’s\n",
    "group membership\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Make k-means clusterer \n",
    "clusterer = KMeans(n_clusters=8, init='k-means++', max_iter=300, \n",
    "                   n_init=10, tol=0.0001, random_state=None,\n",
    "                   verbose=0, copy_x=True, algorithm='auto')\n",
    "\n",
    "# Predict values and assign to new column\n",
    "df[\"new_col_name\"] = clusterer.predict(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9b7ee",
   "metadata": {},
   "source": [
    "<a id=\"derive\"></a>\n",
    "<h1 align=\"center\">HOW TO DERIVE NEW INPUT VARIABLES</h1>\n",
    "\n",
    "Often, the input features for a predictive modeling task interact in unexpected and often nonlinear ways. These interactions can be identified and modeled by a learning algorithm. \n",
    "\n",
    "Another approach is to engineer new features that expose these interactions and see if they improve model performance. These features are called interaction and polynomial features. \n",
    "- **Polynomial features** are often created when we want to include the notion that there exists a nonlinear relationship between the features and the target. For example, the effect of age on the probability of having a major medical condition is not constant over time but increases as age increases. We can encode that nonconstant effect in a feature by generating that feature’s higher-order forms. \n",
    "- Often we run into situations where the effect of one feature is dependent on another feature. We can encode that relationship by including an **interaction feature** that is the product of the individual features.\n",
    "\n",
    "\n",
    "Transforms like raising input variables to a power can help to better expose the important relationships between input variables and the target variable, although often at the cost of adding thousands or even millions of additional input variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f8f8f",
   "metadata": {},
   "source": [
    "<a id=\"inter\"></a>\n",
    "<h2><ins>Interaction Terms</ins></h2>\n",
    "\n",
    "In some situations, there might be an **interaction effect** between some predictors, that is for example, increasing the value of a predictor variable x1 may increase the effectiveness of the predictor x2 in explaining the variation in the outcome variable.\n",
    "\n",
    "Sometimes interactions could be useful to add to the model, especially when you suspect that two features have a relationship that can provide useful information to your model. To see if an interaction term is significant, we can perform a t-test or F-test and look to see if the p-value of the term is significant. One important note is that **if the interaction term is significant, both lower order X terms must be kept in the model**, even if they are insignificant. This is to preserve the X1 and X2 as two independent variables rather than one new variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805133a9",
   "metadata": {},
   "source": [
    "<a id=\"poly\"></a>\n",
    "<h2><ins>Polynomial Features</ins></h2>\n",
    "\n",
    "**Polynomial features** are those features created by raising existing features to an exponent. For example, if a dataset had one input feature X, then a polynomial feature would be the addition of a new feature (column) where values were calculated by squaring the values in X, e.g. $X^2$. This process can be repeated for each input variable in the dataset, creating a transformed version of each. *As such, polynomial features are a type of feature engineering*, e.g. the creation of new input features based on the existing features. \n",
    ">*The degree of the polynomial is used to control the number of features added, e.g. a degree of 3 will add two new variables for each input variable. Typically a small degree is used such as 2 or 3.*\n",
    "\n",
    "It is also common to add new variables that represent the **interaction** between **features**, e.g a new column that represents one variable multiplied by another. This too can be repeated for each input variable creating a new interaction variable for each pair of input variables. A squared or cubed version of an input variable will change the probability distribution, separating the small and large values, a separation that is increased with the size of the exponent. This separation can help some machine learning algorithms make better predictions and is common for regression predictive modeling tasks and generally tasks that have numerical input variables. \n",
    ">*Typically linear algorithms, such as linear regression and logistic regression, respond well to the use of polynomial input variables.*\n",
    ">>*Linear regression is linear in the model parameters and adding polynomial terms to the model can be an effective way of allowing the model to identify nonlinear patterns.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a7cc7",
   "metadata": {},
   "source": [
    "<a id=\"pft\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Polynomial Feature Transform</h5>\n",
    "\n",
    "The polynomial features transform is available in the scikit-learn Python machine learning\n",
    "library via the PolynomialFeatures class. The features created include:\n",
    "- The bias (the value of 1.0)\n",
    "- Values raised to a power for each degree (e.g. $x^1$,$x^2$,$x^3$,...)\n",
    "- Interactions between all pairs of features (e.g. $x^1$x $x^2$, $x^1$x $x^3$,$x^2$x $x^3$,...)\n",
    "\n",
    "The `degree` argument controls the number of features created and defaults to 2. The `interaction_only` argument means that only the raw values (degree 1) and the interaction (pairs of values multiplied with each other) are included, defaulting to False. The `include_bias` argument defaults to True to include the bias feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4a9f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04a0537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800 (0.077)\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=False,\n",
    "                          include_bias=False)\n",
    "model = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[('t', poly), ('m', model)])\n",
    "\n",
    "# evaluate the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98953",
   "metadata": {},
   "source": [
    "<a id=\"degree\"></a>\n",
    "<h5 style=\"text-decoration:underline\"> Effect of Polynomial Degree</h5>\n",
    "\n",
    "Using a degree of 3 in the previous example sees the number of features increased from 61 (60 input features) for the raw dataset to 39,711 features (39,710 input features).\n",
    "\n",
    "The degree of the polynomial dramatically increases the number of input features. To get an idea of how much this impacts the number of features, we can perform the transform with a range of different degrees and compare the number of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "231af9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 1, Features: 61\n",
      "Degree: 2, Features: 1891\n",
      "Degree: 3, Features: 39711\n",
      "Degree: 4, Features: 635376\n",
      "Degree: 5, Features: 8259888\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = list()\n",
    "degrees = [i for i in range(1, 6)]\n",
    "for d in degrees:\n",
    "    # create polynomial transform\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    \n",
    "    # fit and transform\n",
    "    data = poly.fit_transform(X)\n",
    "    \n",
    "    # record number of features\n",
    "    num_features.append(data.shape[1])\n",
    "\n",
    "    # summarize\n",
    "    print('Degree: %d, Features: %d' % (d, data.shape[1]))\n",
    "\n",
    "# plot degree vs number of features\n",
    "plt.plot(degrees, num_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86feac5",
   "metadata": {},
   "source": [
    "More features may result in more overfitting, and in turn, worse results. It may be a good idea to treat the degree for the polynomial features transform as a hyperparameter and test different values for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af40be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.797 (0.073)\n",
      ">2 0.793 (0.085)\n",
      ">3 0.800 (0.077)\n",
      ">4 0.795 (0.079)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUnUlEQVR4nO3df6zd9X3f8eer16AFwk9xy1ZMApVoYoYGS4+cTNA0LoOarSlKtT/saIuKXFmeIMqmqSst1ZKuQqoUbVq1UHlWQFHVYv5ocHAnBkQdCXOVLr5OzA/beLpyKHie4stgo6XVwPi9P+5xc7gcc7/XPpdzzofnQzry/X4/n8897/PV9/u6X3/O+Z5vqgpJUrt+bNwFSJJWl0EvSY0z6CWpcQa9JDXOoJekxq0ZdwHDXHbZZXXVVVeNuwxJmhr79u17uapmh7VNZNBfddVVzM3NjbsMSZoaSf78dG1O3UhS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGdQr6JBuTHE4yn+TuIe2XJNmV5Jkk301y3UDbC0meTbI/iZ+ZlKT32LKfo08yA9wH3AIcBfYm2V1VBwe6/Qawv6o+k+Sj/f43D7RvqKqXR1i3JKmjLmf064H5qjpSVW8ADwG3L+lzLfAnAFX1PHBVkstHWul7KMlIH5Im0/vlWO9yZewVwEsDy0eBjy/p8zTwS8CeJOuBDwNrgR8CBTyRpID/VFU7hj1Jkq3AVoAPfehDK3kNI9flZixJOvUTIz8A3s/b3W05Wl1f/7Qf712CftietfQV/w7wu0n2A88C3wdO9NturKpjSX4c+GaS56vqqXf8wsU/ADsAer3e9G5RvYN/OEfn/RJMGq0uQX8UuHJgeS1wbLBDVb0G3AGQxVOOH/QfVNWx/r/Hk+xicSroHUEvSVodXebo9wLXJLk6ybnAJmD3YIckF/fbAH4FeKqqXktyfpIL+n3OB24Fnhtd+ZKk5Sx7Rl9VJ5LcBTwOzAAPVNWBJNv67duBdcDvJ3kLOAhs6Q+/HNjVn1dcAzxYVY+N/mVIkk6n09cUV9WjwKNL1m0f+Pk7wDVDxh0Brj/LGiVJZ8ErYyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjesU9Ek2JjmcZD7J3UPaL0myK8kzSb6b5LquYyVJq2vZoE8yA9wH3AZcC2xOcu2Sbr8B7K+qvwd8DvjdFYyVJK2iLmf064H5qjpSVW8ADwG3L+lzLfAnAFX1PHBVkss7jpUkraIuQX8F8NLA8tH+ukFPA78EkGQ98GFgbcex9MdtTTKXZG5hYaFb9ZKkZXUJ+gxZV0uWfwe4JMl+4PPA94ETHccurqzaUVW9qurNzs52KEuS1MWaDn2OAlcOLK8Fjg12qKrXgDsAkgT4Qf9x3nJjJUmrq8sZ/V7gmiRXJzkX2ATsHuyQ5OJ+G8CvAE/1w3/ZsZKk1bXsGX1VnUhyF/A4MAM8UFUHkmzrt28H1gG/n+Qt4CCw5d3Grs5LkSQNk6qhU+Zj1ev1am5ubtxlvKskTOK2m1Zuz9Fye47WNGzPJPuqqjeszStjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLatKll15KkpE8gJH8nksvvXQs26LLlbGSNHVeffXViftI5Kk/Gu81z+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjesU9Ek2JjmcZD7J3UPaL0ryx0meTnIgyR0DbS8keTbJ/iST/SXzWpFJvPJwnFcfni23p1bLslfGJpkB7gNuYfH+sXuT7K6qgwPd7gQOVtWnk8wCh5P8YVW90W/fUFUvj7p4jdckXnkI47v68Gy5PbVaupzRrwfmq+pIP7gfAm5f0qeAC7K4R3wQeAU4MdJKJUlnpEvQXwG8NLB8tL9u0FdYvG/sMeBZ4AtVdbLfVsATSfYl2XqW9UqSVqhL0A/7f9vS/1/+PLAf+AngBuArSS7st91YVR8DbgPuTPLJoU+SbE0yl2RuYWGhS+1nZFTzoP2anQOVNPG6BP1R4MqB5bUsnrkPugN4uBbNAz8APgpQVcf6/x4HdrE4FfQOVbWjqnpV1ZudnV3Zq1iBU/Ogk/R49dVXV+31SlKXoN8LXJPk6iTnApuA3Uv6vAjcDJDkcuAjwJEk5ye5oL/+fOBW4LlRFS9JWt6yn7qpqhNJ7gIeB2aAB6rqQJJt/fbtwG8DX0vyLItTPb9WVS8n+UlgV3+qYw3wYFU9tkqvRZI0RKcbj1TVo8CjS9ZtH/j5GItn60vHHQGuP8saJUlnwStjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjOn1NcUvqixfCly4adxlvU1+8cPlOE2gStyW4PUdtWrenfiRVS2//On69Xq/m5uZW5XcnYdJe8yTW1MWk1j2pdS1nUuue1LqWM4l1r2ZNSfZVVW9YW6epmyQbkxxOMp/k7iHtFyX54yRPJzmQ5I6uYyWN1sJfLfDLj/0yL//1y+MuRRNi2aBPMgPcB9wGXAtsTnLtkm53Ager6nrgU8C/S3Jux7GSRmj7M9v53g+/x/anty/fWe8LXc7o1wPzVXWkqt4AHgJuX9KngAuyeHPYDwKvACc6jp06njFpUi381QKPzD9CUXxj/hvuoyPQwvHeJeivAF4aWD7aXzfoK8A64BjwLPCFqjrZcSwASbYmmUsyt7Cw0LH88fCMabRaOJAmxfZntnOyTgJwsk66j45AC8d7l6DPkHVL3034eWA/8BPADcBXklzYceziyqodVdWrqt7s7GyHssbDM6bRa+FAmgSn9s03T74JwJsn33QfPUutHO9dgv4ocOXA8loWz9wH3QE8XIvmgR8AH+04dqp4xjRarRxIk2Bw3zzFffTstHK8dwn6vcA1Sa5Oci6wCdi9pM+LwM0ASS4HPgIc6Th2anjGNHqtHEiT4OnjT//NvnnKmyffZP/x/eMpaMq1dLwve8FUVZ1IchfwODADPFBVB5Js67dvB34b+FqSZ1mcrvm1qnoZYNjY1Xkpq+/dzph+8xO/OaaqptfpDqRt12/jsg9cNubqps8f/eIfjbuEprR0vHe6MraqHgUeXbJu+8DPx4Bbu46dVp4xjVZLB5La09Lx/r77CoSz4RnTaLV0IKk9LR3vBr3GpqUDSZpkfnulJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuPfld90s3tp2clxyySXjLkETYtL2TZje/bO+eCF86aJxl/E29cULx/K877ugrxp6J8MVSzKy3yXB6PZNcP8EyG+9NnHbIAn1pff+eZ26kaTGdQr6JBuTHE4yn+TuIe2/mmR///FckreSXNpveyHJs/22uVG/AEnSu1t26ibJDHAfcAuLN/vem2R3VR081aeqvgx8ud//08C/rKpXBn7NhlO3FlRbnFPWJJu0/XNc+2aXOfr1wHxVHQFI8hBwO3DwNP03AztHU54mmXPKmmTunz/SZermCuClgeWj/XXvkOQ8YCPw9YHVBTyRZF+Srad7kiRbk8wlmVtYWOhQliSpiy5BP+z/Pqf70/Zp4E+XTNvcWFUfA24D7kzyyWEDq2pHVfWqqjc7O9uhLElSF12C/ihw5cDyWuDYafpuYsm0TVUd6/97HNjF4lSQJOk90iXo9wLXJLk6ybkshvnupZ2SXAT8LPDIwLrzk1xw6mfgVuC5URQuSepm2Tdjq+pEkruAx4EZ4IGqOpBkW799e7/rZ4Anqur1geGXA7v673yvAR6sqsdG+QIkSe8uk/hOcq/Xq7m5yf7I/bS/Cz9p3J6j5fYcrWnYnkn2VVVvWJtXxkpS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4TkGfZGOSw0nmk9w9pP1Xk+zvP55L8laSS7uMlSStrmWDPskMcB+LN/e+Ftic5NrBPlX15aq6oapuAH4d+HZVvdJlrCRpdXU5o18PzFfVkap6A3gIuP1d+m/mRzcIX+lYSdKIdQn6K4CXBpaP9te9Q5LzgI3A189g7NYkc0nmFhYWOpQlSeqiS9BnyLrT3Tzx08CfVtUrKx1bVTuqqldVvdnZ2Q5lSZK66BL0R4ErB5bXAsdO03cTP5q2WelYSdIq6BL0e4Frklyd5FwWw3z30k5JLgJ+FnhkpWMlSatnzXIdqupEkruAx4EZ4IGqOpBkW799e7/rZ4Anqur15caO+kVIkk4vVaebbh+fXq9Xc3Nz4y7jXSVhErfdtHJ7jpbbc7SmYXsm2VdVvWFtXhkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1btkvNZPOVjLstgRn3m/Sv3NE06PrPte176Tumwa9Vt2k7vzS+2XfdOpGkhpn0EtS4wx6SWpcp6BPsjHJ4STzSe4+TZ9PJdmf5ECSbw+sfyHJs/22yb6biCQ1aNk3Y5PMAPcBt7B4s++9SXZX1cGBPhcDvwdsrKoXk/z4kl+zoapeHl3ZkqSuupzRrwfmq+pIVb0BPATcvqTPZ4GHq+pFgKo6PtoyJUlnqkvQXwG8NLB8tL9u0E8BlyT5VpJ9ST430FbAE/31W0/3JEm2JplLMrewsNC1/lWRZNlH134r+ZyutJyV7HPumzqly+foh+0NSz98ugb4aeBm4APAd5L8WVX9D+DGqjrWn875ZpLnq+qpd/zCqh3ADli8OfhKXsSovV8+W6vp476pM9HljP4ocOXA8lrg2JA+j1XV6/25+KeA6wGq6lj/3+PALhangiRJ75EuQb8XuCbJ1UnOBTYBu5f0eQT4mSRrkpwHfBw4lOT8JBcAJDkfuBV4bnTlS5KWs+zUTVWdSHIX8DgwAzxQVQeSbOu3b6+qQ0keA54BTgJfrarnkvwksKs/F7gGeLCqHlutFyNJeqdM4pxfr9eruTk/ci9JXSXZV1W9YW1eGStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjOgV9ko1JDieZT3L3afp8Ksn+JAeSfHslYyVJq2fZO0wlmQHuA25h8d6we5PsrqqDA30uBn4P2FhVL/ZvBN5prCRpdXU5o18PzFfVkap6A3gIuH1Jn88CD1fVi/A3NwLvOlaStIq6BP0VwEsDy0f76wb9FHBJkm8l2ZfkcysYC0CSrUnmkswtLCx0q16StKxlp26ADFm39Eaza4CfBm4GPgB8J8mfdRy7uLJqB7ADFu8Z26EuSVIHXYL+KHDlwPJa4NiQPi9X1evA60meAq7vOFaStIq6TN3sBa5JcnWSc4FNwO4lfR4BfibJmiTnAR8HDnUcK0laRcue0VfViSR3AY8DM8ADVXUgybZ++/aqOpTkMeAZ4CTw1ap6DmDY2FV6LZKkIVI1edPhvV6v5ubmxl2GJE2NJPuqqjeszStjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN6xT0STYmOZxkPsndQ9o/leT/Jtnff/ybgbYXkjzbX+/dRPQ2O3fu5LrrrmNmZobrrruOnTt3jrskqTnL3kowyQxwH3ALizf73ptkd1UdXNL1v1XVL5zm12yoqpfPrlS1ZufOndxzzz3cf//93HTTTezZs4ctW7YAsHnz5jFXJ7Wjyxn9emC+qo5U1RvAQ8Dtq1uW3g/uvfde7r//fjZs2MA555zDhg0buP/++7n33nvHXZrUlC5BfwXw0sDy0f66pf5BkqeT/Jckf3dgfQFPJNmXZOvpniTJ1iRzSeYWFhY6Fa/pdujQIW666aa3rbvppps4dOjQmCqS2tQl6DNk3dI7in8P+HBVXQ/8R+AbA203VtXHgNuAO5N8ctiTVNWOqupVVW92drZDWZp269atY8+ePW9bt2fPHtatWzemiqQ2dQn6o8CVA8trgWODHarqtar6y/7PjwLnJLmsv3ys/+9xYBeLU0ES99xzD1u2bOHJJ5/kzTff5Mknn2TLli3cc8894y5Nasqyb8YCe4FrklwN/E9gE/DZwQ5J/jbww6qqJOtZ/APyv5OcD/xYVf1F/+dbgX870legqXXqDdfPf/7zHDp0iHXr1nHvvff6Rqw0YssGfVWdSHIX8DgwAzxQVQeSbOu3bwf+CfDPk5wA/hrY1A/9y4FdSU4914NV9dgqvRZNoc2bNxvs0ipL1dLp9vHr9Xo1N+dH7iWpqyT7qqo3rM0rYyWpcQa9JDXOoJekxhn0ktS4iXwzNskC8OfjrmMZlwF+f8/ouD1Hy+05WtOwPT9cVUOvNp3IoJ8GSeZO9w63Vs7tOVpuz9Ga9u3p1I0kNc6gl6TGGfRnbse4C2iM23O03J6jNdXb0zl6SWqcZ/SS1DiDXpIaZ9CvUJIHkhxP8ty4a2lBkiuTPJnkUJIDSb4w7pqmVZK/leS7/Tu9HUjyW+OuqQVJZpJ8P8l/HnctZ8qgX7mvARvHXURDTgD/qqrWAZ9g8S5k1465pmn1/4Cf69/p7QZgY5JPjLekJnwBmOr7Wxr0K1RVTwGvjLuOVlTV/6qq7/V//gsWD6hh9yTWMmrRX/YXz+k//LTFWUiyFvjHwFfHXcvZMOg1MZJcBfx94L+PuZSp1Z9m2A8cB75ZVW7Ls/MfgH8NnBxzHWfFoNdESPJB4OvAv6iq18Zdz7Sqqreq6gYW7+28Psl1Yy5paiX5BeB4Ve0bdy1ny6DX2CU5h8WQ/8Oqenjc9bSgqv4P8C18P+ls3Aj8YpIXgIeAn0vyB+Mt6cwY9BqrLN5Q+H7gUFX9+3HXM82SzCa5uP/zB4B/CDw/1qKmWFX9elWtraqrgE3Af62qfzrmss6IQb9CSXYC3wE+kuRoki3jrmnK3Qj8MxbPlvb3H/9o3EVNqb8DPJnkGWAvi3P0U/uRQI2OX4EgSY3zjF6SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMb9f28t9XNLyD0iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = dict()\n",
    "for d in range(1,5):\n",
    "    # define the pipeline\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(d)] = Pipeline(steps=[('t', poly), ('m', model)])\n",
    "    \n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad3e70",
   "metadata": {},
   "source": [
    "In this case, we can see that performance is generally worse than no transform (degree 1) except for a degree 3.  From the Box and whisker plots we see that performance remains flat, perhaps with the first signs of overfitting with a degree of 4.\n",
    "\n",
    "It might be interesting to explore scaling the data before or after performing the transform to see how it impacts model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb850ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.810 (0.080)\n",
      ">2 0.811 (0.073)\n",
      ">3 0.806 (0.074)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = dict()\n",
    "for d in range(1,4):\n",
    "    # define the pipeline\n",
    "    scaler = StandardScaler()\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(d)] = Pipeline(steps=[('t', poly),('sc', scaler) , ('m', model)])\n",
    "    \n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y_le, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f5d8f",
   "metadata": {},
   "source": [
    "<a id=\"func\"></a>\n",
    "<h2><ins>Transforming Features with FunctionTransformer</ins></h2>\n",
    "\n",
    "We can make a custom transformation to one or more features with Scikit-Learns' `FunctionTransformer` method. This is similar to numpy's `vectorize` method and pandas `apply` method.\n",
    "\n",
    "It is common to want to make some custom transformations to one or more features. For example, we might want to create a feature that is the natural log of a feature. We can do this by creating a function and then mapping it to features using either scikit-learn’s `FunctionTransformer` or pandas’ `apply`.\n",
    "\n",
    "```python\n",
    "# Define a simple function\n",
    "def take_log(x):\n",
    "    return np.log(x)\n",
    "\n",
    "Using FunctionTransformer\n",
    "-------------------------\n",
    "# Create transformer\n",
    "log_transformer = FunctionTransformer(take_log)\n",
    "\n",
    "# Transform feature matrix\n",
    "log_transformer.transform(df)\n",
    "\n",
    "Using apply\n",
    "-----------\n",
    "df.apply(take_log)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b038c2",
   "metadata": {},
   "source": [
    "<a id=\"num_cat\"></a>\n",
    "<h1 align=\"center\">HOW TO TRANSFORM NUMERICAL AND CATEGORICAL DATA</h1>\n",
    "\n",
    "It is now apparent the necessity to prepare raw data using transforms prior to fitting a machine learning model to ensure that we best expose the structure of the predictive modeling problem to the learning algorithms. Applying data transforms like scaling or encoding categorical variables is straightforward when all input variables are the same type. It can be challenging though when we have a dataset with mixed types and want to selectively apply data transforms to some, but not all, input features. This is where scikit-learn's library provides the ColumnTransformer that allows us to selectively apply data transforms to different columns in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466c6b2",
   "metadata": {},
   "source": [
    "<a id=\"chall\"></a>\n",
    "<h2><ins>Challenge of Transforming Different Data Types</ins></h2>\n",
    "\n",
    "It is important to prepare data prior to modeling. *This may involve replacing missing values, scaling numerical values, and one hot encoding categorical data.* Data transforms can be performed using the scikit-learn library; for example, the `SimpleImputer` class can be used to replace missing values, the `MinMaxScaler` class can be used to scale numerical values, and the `OneHotEncoder` can be used to encode categorical variables. Sequences of different transforms can also be chained together using `Pipelines`.\n",
    "\n",
    "It is very common to want to perform different data preparation techniques on different columns in the input data. For example, you may want to impute missing numerical values with a median value, then scale the values and impute missing categorical values using the most frequent value and one hot encode the categories. Traditionally, this would require separating the numerical and categorical data and then manually applying the transforms on those groups of features before combining the columns back together in order to fit and evaluate a model. Now, scikit-learn's *`ColumnTransformer`* can perform this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fff2bb",
   "metadata": {},
   "source": [
    "<a id=\"use\"></a>\n",
    "<h3><ins>How to use the ColumnTransformer</ins></h3>\n",
    "\n",
    "The **ColumnTransformer** is a class in the scikit-learn Python machine learning library that allows you to selectively apply data preparation transforms. For example, it allows you to apply a specific transform or sequence of transforms to just the numerical columns, and a separate sequence of transforms to just the categorical columns. \n",
    ">**To use the ColumnTransformer, you must specify a list of transformers.<br><br>Each transformer is a three-element tuple that defines the name of the transformer, the transform to apply, and the column indices to apply it to.**\n",
    "\n",
    "For example, to use the ColumnTransformer to apply a OneHotEncoder to columns 0 and 1:\n",
    "```python\n",
    "transformer = ColumnTransformer(transformers=\n",
    "                  [('num',SimpleImputer(strategy='median'), [0, 1]),\n",
    "                   ('cat', SimpleImputer(strategy='most_frequent'), [2, 3]),\n",
    "                   ('cat', OneHotEncoder(), [0, 1])],\n",
    "                    remainder='passthrough')\n",
    "```\n",
    "Any columns not specified in the list of transformers are dropped from the dataset by default; this can be changed by setting the `remainder` argument. Setting **remainder='passthrough'** will mean that all columns not specified in the list of transformers will be passed through without transformation, instead of being dropped.\n",
    "\n",
    "A ColumnTransformer can also be used in a Pipeline to selectively prepare the columns of the dataset before fitting a model on the transformed data. This is the most likely use case as it ensures that the transforms are performed automatically on the raw data when fitting the model and when making predictions, such as when evaluating the model on a test dataset via cross-validation or making predictions on new data in the future.\n",
    "```python\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), [0, 1])])\n",
    "pipeline = Pipeline(steps=[('t', transformer), ('m',model)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8eaf3",
   "metadata": {},
   "source": [
    "<a id=\"abalone\"></a>\n",
    "<h2><ins>Abalone Regression Dataset</ins></h2>\n",
    "\n",
    "The abalone dataset is a standard machine learning problem that involves predicting the age of an abalone given measurements of an abalone. The dataset has 4,177 examples, 8 input variables, and the target variable is an integer. A naive model can achieve a mean absolute error (MAE) of about 2.363 (std 0.092) by predicting the mean value, evaluated via 10-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dc95a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6      7   8\n",
       "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150  15\n",
       "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.070   7\n",
       "2  F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.210   9\n",
       "3  M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.155  10\n",
       "4  I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.055   7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df_aba = pd.read_csv('./datasets/Data Transforms/abalone.csv', header=None)\n",
    "df_aba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01907f5",
   "metadata": {},
   "source": [
    "The first column is categorical and the remainder of the columns are numerical. We may want to one hot encode the first column and normalize the remaining numerical columns, and this can be achieved using the ColumnTransformer. We can model this as a regression predictive modeling problem with a support vector machine model (SVR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f34c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2d8511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.465 (0.047)\n"
     ]
    }
   ],
   "source": [
    "# split into inputs and outputs\n",
    "X = df_aba.drop(8, axis=1)\n",
    "y = df_aba[8]\n",
    "\n",
    "# determine categorical and numerical features\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# define the data preparation for the columns\n",
    "t = [('cat', OneHotEncoder(), categorical_cols), ('num', MinMaxScaler(), numerical_cols)]\n",
    "col_transform = ColumnTransformer(transformers=t)\n",
    "\n",
    "# define the model\n",
    "model = SVR(kernel='rbf',gamma='scale',C=100)\n",
    "\n",
    "# define the data preparation and modeling pipeline\n",
    "pipeline = Pipeline(steps=[('prep',col_transform), ('m', model)])\n",
    "\n",
    "# define the model cross-validation configuration\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# evaluate the pipeline using cross-validation and calculate MAE\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "# convert MAE scores to positive values\n",
    "scores = np.absolute(scores)\n",
    "\n",
    "# summarize the model performance\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5df1b",
   "metadata": {},
   "source": [
    "In this case, we achieve an average MAE of about 1.4, which is better than the baseline score of 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13125250",
   "metadata": {},
   "source": [
    "<a id=\"reg\"></a>\n",
    "<h1 align=\"center\">HOW TO TRANSFORM THE TARGET VARIABLE</h1>\n",
    "\n",
    "Data preparation is a big part of applied machine learning. Correctly preparing the training data can mean the difference between mediocre and extraordinary results, even with very simple linear algorithms. Performing data preparation operations, such as scaling, is relatively straightforward for input variables and has been made routine in Python via the Pipeline scikit-learn class. On regression predictive modeling problems where a numerical value must be predicted, it can also be critical to scale and perform other data transformations on the target variable. This can be achieved in Python using the `TransformedTargetRegressor` class.\n",
    ">For regression problems, it is often desirable to scale or transform both the input and the target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533b121",
   "metadata": {},
   "source": [
    "<a id=\"imbal\"></a>\n",
    "<h2><ins>Handling Imbalanced Classes</ins></h2>\n",
    "\n",
    "If the target vector contains highly **imbalanced classes**, then there are a few possible solutions. Collect more data. If that isn’t possible, change the metrics used to evaluate your model. If that doesn’t work, consider using a model’s built-in class weight parameters (if available), downsampling, or upsampling. \n",
    "- **Many algorithms in scikit-learn offer a parameter to weight classes during training to counteract the effect of their imbalance.** \n",
    "- Alternatively, we can downsample the majority class or upsample the minority class. In **downsampling**, we randomly sample without replacement from the majority class (i.e., the class with more observations) to create a new subset of observations equal in size to the minority class. For example, if the minority class has 10 observations, we randomly select 10 observations from the majority class and use those 20 observations as the dataset.\n",
    "- The other option is to upsample the minority class. In **upsampling**, for every observation in the majority class, we randomly select an observation from the minority class with replacement. The end result is the same number of observations from the minority and majority classes. Upsampling is implemented very similarly to downsampling, just in reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98a3a3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>blood_press</th>\n",
       "      <th>tricep_thick</th>\n",
       "      <th>serum_ins</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose_conc  blood_press  tricep_thick  serum_ins   bmi  \\\n",
       "0         6           148           72            35          0  33.6   \n",
       "1         1            85           66            29          0  26.6   \n",
       "2         8           183           64             0          0  23.3   \n",
       "3         1            89           66            23         94  28.1   \n",
       "4         0           137           40            35        168  43.1   \n",
       "\n",
       "   pedigree  age  target  \n",
       "0     0.627   50       1  \n",
       "1     0.351   31       0  \n",
       "2     0.672   32       1  \n",
       "3     0.167   21       0  \n",
       "4     2.288   33       1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8adfdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1423b2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_diab = df_diab.drop(columns=['target'])\n",
    "y_diab = df_diab['target']\n",
    "\n",
    "y_diab.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a70967ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "# Indicies of each class' observations\n",
    "i_class0 = np.where(y_diab == 0)[0]\n",
    "i_class1 = np.where(y_diab == 1)[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "print(n_class0)\n",
    "print(n_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82ced897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For every observation of class 1, randomly sample\n",
    "# from class 0 without replacement\n",
    "i_class0_downsampled = np.random.choice(i_class0, size=n_class1,\n",
    "                                        replace=False)\n",
    "len(i_class0_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f97dffc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 1's target vector with the\n",
    "# downsampled class 0's target vector\n",
    "new_target = np.hstack((y_diab[i_class1], y_diab[i_class0_downsampled]))\n",
    "new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3202ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       [  0.   , 137.   ,  40.   , ...,  43.1  ,   2.288,  33.   ],\n",
       "       ...,\n",
       "       [  1.   , 112.   ,  80.   , ...,  34.8  ,   0.217,  24.   ],\n",
       "       [  2.   , 119.   ,   0.   , ...,  19.6  ,   0.832,  72.   ],\n",
       "       [ 12.   , 100.   ,  84.   , ...,  30.   ,   0.488,  46.   ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 1's feature matrix with the\n",
    "# downsampled class 0's feature matrix\n",
    "new_data = np.vstack((X_diab.loc[i_class1,:],\n",
    "                      X_diab.loc[i_class0_downsampled,:]))\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3e9ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536,)\n",
      "(536, 8)\n"
     ]
    }
   ],
   "source": [
    "print(new_target.shape)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "685de2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>blood_press</th>\n",
       "      <th>tricep_thick</th>\n",
       "      <th>serum_ins</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>4.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.244</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.285</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.217</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.832</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose_conc  blood_press  tricep_thick  serum_ins   bmi  \\\n",
       "0         6.0         148.0         72.0          35.0        0.0  33.6   \n",
       "1         8.0         183.0         64.0           0.0        0.0  23.3   \n",
       "2         0.0         137.0         40.0          35.0      168.0  43.1   \n",
       "3         3.0          78.0         50.0          32.0       88.0  31.0   \n",
       "4         2.0         197.0         70.0          45.0      543.0  30.5   \n",
       "..        ...           ...          ...           ...        ...   ...   \n",
       "531       4.0         141.0         74.0           0.0        0.0  27.6   \n",
       "532      10.0          68.0        106.0          23.0       49.0  35.5   \n",
       "533       1.0         112.0         80.0          45.0      132.0  34.8   \n",
       "534       2.0         119.0          0.0           0.0        0.0  19.6   \n",
       "535      12.0         100.0         84.0          33.0      105.0  30.0   \n",
       "\n",
       "     pedigree   age  target  \n",
       "0       0.627  50.0       1  \n",
       "1       0.672  32.0       1  \n",
       "2       2.288  33.0       1  \n",
       "3       0.248  26.0       1  \n",
       "4       0.158  53.0       1  \n",
       "..        ...   ...     ...  \n",
       "531     0.244  40.0       0  \n",
       "532     0.285  47.0       0  \n",
       "533     0.217  24.0       0  \n",
       "534     0.832  72.0       0  \n",
       "535     0.488  46.0       0  \n",
       "\n",
       "[536 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting back to a single dataframe.\n",
    "df_data = pd.DataFrame(new_data, columns=X_diab.columns)\n",
    "df_target = pd.DataFrame(new_target, columns=['target'])\n",
    "\n",
    "df = pd.concat([df_data,df_target],axis=1)\n",
    "df\n",
    "\n",
    "# might be a good idea to shuffle the data befor split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c192b43",
   "metadata": {},
   "source": [
    "**It might be a good idea to shuffle the data before split or shuffle and stratify within the train_test_split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c0e2c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    268\n",
       "1    268\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1abb464",
   "metadata": {},
   "source": [
    "In the real world, imbalanced classes are everywhere. For this reason, handling imbalanced classes is a common activity in machine learning. The best strategy is simply to collect more observations — especially observations from the minority class. However, this is often just not possible, so we have to resort to other options.\n",
    "\n",
    "A second strategy is to use a model evaluation metric better suited to imbalanced classes. Accuracy is often used as a metric for evaluating the performance of a model, but when imbalanced classes are present accuracy can be ill suited. Some better metrics are confusion matrices, precision, recall, F1 scores, and ROC curves.\n",
    "\n",
    "A third strategy is to use the class weighing parameters included in implementations of some models. This allows us to have the algorithm adjust for imbalanced classes. Fortunately, many scikit-learn classifiers have a class_weight parameter, making it a good option.\n",
    "\n",
    "The fourth and fifth strategies are related: downsampling and upsampling. In downsampling we create a random subset of the majority class of equal size to the minority class. In upsampling we repeatedly sample with replacement from the minority class to make it of equal size as the majority class. The decision between using downsampling and upsampling is context-specific, and in general we should try both to see which produces better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e41f9",
   "metadata": {},
   "source": [
    "<a id=\"target\"></a>\n",
    "<h2><ins>How to Scale Target Variables</ins></h2>\n",
    "\n",
    "There are two ways that you can scale target variables. \n",
    "1. Manually transform the target variable.\n",
    "2. Automatically transform the target variable.\n",
    "\n",
    "<a id=\"manual\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Manual Transform of the Target Variable</h5>\n",
    "\n",
    "Manually managing the scaling of the target variable involves creating and applying the scaling object to the data manually. It involves the following steps:\n",
    "1. Create the transform object, e.g. a `MinMaxScaler`.\n",
    "2. Fit the transform on the training dataset.\n",
    "3. Apply the transform to the train and test datasets.\n",
    "4. Invert the transform on any predictions made\n",
    "\n",
    "For example, if we wanted to normalize a target variable:\n",
    "```python\n",
    "# create target scaler object\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(train_y)\n",
    "\n",
    "# transform target variables\n",
    "train_y = target_scaler.transform(train_y)\n",
    "test_y = target_scaler.transform(test_y)\n",
    "\n",
    "# invert transform on predictions\n",
    "yhat = model.predict(test_X)\n",
    "yhat = target_scaler.inverse_transform(yhat)\n",
    "```\n",
    "\n",
    "This is a pain, as it means you cannot use convenience functions in scikit learn, such as `cross_val_score()`, to quickly evaluate a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4470373",
   "metadata": {},
   "source": [
    "<a id=\"auto\"></a>\n",
    "<h5 style=\"text-decoration:underline\">Automatic Transform of the Target Variable</h5>\n",
    "\n",
    "An alternate approach is to automatically manage the transform and inverse transform. This can be achieved by using the **`TransformedTargetRegressor`** object that wraps a given model and a scaling object. It will prepare the transform of the target variable using the same training data used to fit the model, then apply that inverse transform on any new data provided when calling fit(), returning predictions in the correct scale.\n",
    "\n",
    "```python\n",
    "# define the target transform wrapper\n",
    "wrapped_model = TransformedTargetRegressor(regressor=model, transformer=MinMaxScaler())\n",
    "\n",
    "# use the target transform wrapper\n",
    "wrapped_model.fit(train_X, train_y)\n",
    "yhat = wrapped_model.predict(test_X)\n",
    "```\n",
    "\n",
    "This is much easier and allows you to use helpful functions like `cross_val_score()` to evaluate a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e49805",
   "metadata": {},
   "source": [
    "<a id=\"ttr\"></a>\n",
    "<h3><ins>Using the TransformedTargetRegressor</ins></h3>\n",
    "\n",
    "The Boston housing dataset is a regression problem that has 13 inputs and one numerical target and requires learning the relationship between suburb characteristics and house prices. A naive regression model that predicts the mean value of the target on this problem can achieve a mean absolute error (MAE) of about 6.659. We will fit a `HuberRegressor` class (**a type of linear regression robust to outliers**) and normalize the input variables using a Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b25aac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "713f63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 3.203\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df_bos = pd.read_csv('./datasets/Data Transforms/boston_housing.csv', header=None)\n",
    "\n",
    "# split into inputs and outputs\n",
    "X = df_bos.drop(columns=[13])\n",
    "y = df_bos[13]\n",
    "\n",
    "# prepare the model with input scaling\n",
    "pipeline = Pipeline(steps=[('normalize', MinMaxScaler()),\n",
    "                           ('model', HuberRegressor())])\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model = TransformedTargetRegressor(regressor=pipeline, \n",
    "                                   transformer=MinMaxScaler())\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, \n",
    "                         scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# convert scores to positive\n",
    "scores = np.absolute(scores)\n",
    "\n",
    "# summarize the result\n",
    "s_mean = np.mean(scores)\n",
    "print('Mean MAE: %.3f' % (s_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9627e1",
   "metadata": {},
   "source": [
    "In this case, we achieve a MAE of about 3.2, much better than a naive model that achieved about 6.6.\n",
    "\n",
    "We are not restricted to using scaling objects; for example, we can also explore using other data transforms on the target variable, such as the **`PowerTransformer`**, that can make each variable more-Gaussian-like (using the *Yeo-Johnson transform*) and improve the performance of linear models. By default, the PowerTransformer also performs a standardization of each variable after performing the transform. It can also help to scale the values to the range 0-1 prior to applying a power transform, to avoid problems inverting the transform. We achieve this using the MinMaxScaler and defining a positive range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dea4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 2.972\n"
     ]
    }
   ],
   "source": [
    "# prepare the model with input scaling and power transform\n",
    "steps = [('scale', MinMaxScaler(feature_range=(1e-5,1))),\n",
    "        ('power', PowerTransformer()),\n",
    "        ('model', HuberRegressor())]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model = TransformedTargetRegressor(regressor=pipeline,\n",
    "                                   transformer=PowerTransformer())\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, \n",
    "                         scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# convert scores to positive\n",
    "scores = np.absolute(scores)\n",
    "\n",
    "# summarize the result\n",
    "s_mean = np.mean(scores)\n",
    "print('Mean MAE: %.3f' % (s_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b9a18",
   "metadata": {},
   "source": [
    "In this case, we see further improvement to the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d97738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 2.808\n"
     ]
    }
   ],
   "source": [
    "# prepare the model with input scaling and power transform\n",
    "steps = [('scale', MinMaxScaler(feature_range=(1e-5,1))),\n",
    "         ('model', HuberRegressor())]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model = TransformedTargetRegressor(regressor=pipeline,\n",
    "                                   transformer=PowerTransformer())\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, \n",
    "                         scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# convert scores to positive\n",
    "scores = np.absolute(scores)\n",
    "\n",
    "# summarize the result\n",
    "s_mean = np.mean(scores)\n",
    "print('Mean MAE: %.3f' % (s_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d81491b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 2.747\n"
     ]
    }
   ],
   "source": [
    "# prepare the model with input scaling and target log transform\n",
    "steps = [('scale', MinMaxScaler(feature_range=(1e-5,1))),\n",
    "         ('model', HuberRegressor())]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model = TransformedTargetRegressor(regressor=pipeline,\n",
    "                                   func=np.log, inverse_func=np.exp)\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, \n",
    "                         scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# convert scores to positive\n",
    "scores = np.absolute(scores)\n",
    "\n",
    "# summarize the result\n",
    "s_mean = np.mean(scores)\n",
    "print('Mean MAE: %.3f' % (s_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d1363",
   "metadata": {},
   "source": [
    "<a id=\"text\"></a>\n",
    "<h1 align=\"center\">HOW TO HANDLE TEXT</h1>\n",
    "\n",
    "Unstructured text data, like the contents of a book or a tweet, is both one of the most interesting sources of features and one of the most complex to handle.\n",
    "\n",
    "<a id=\"clean\"></a>\n",
    "<h2><ins>Cleaning Text</ins></h2>\n",
    "\n",
    "Most basic text cleaning operations should only replace Python’s core string operations, in particular `strip`, `replace`, and `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3bf20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "text_data = [\" Hybrid-Theory. By Linkin Park \",\n",
    "             \"Binaural. By Pearl Jam           \",\n",
    "             \" Dark Side Of The Moon. By Pink Floyd \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9472904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hybrid-Theory. By Linkin Park',\n",
       " 'Binaural. By Pearl Jam',\n",
       " 'Dark Side Of The Moon. By Pink Floyd']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip whitespaces\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e74a94b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hybrid-Theory By Linkin Park',\n",
       " 'Binaural By Pearl Jam',\n",
       " 'Dark Side Of The Moon By Pink Floyd']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove periods\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "deb177fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HYBRID-THEORY BY LINKIN PARK',\n",
       " 'BINAURAL BY PEARL JAM',\n",
       " 'DARK SIDE OF THE MOON BY PINK FLOYD']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and apply a custom transformation function:\n",
    "\n",
    "def capitalizer(string: str) -> str:\n",
    "    return string.upper()\n",
    "\n",
    "# Apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8b19142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hybrid', 'Theory', 'By', 'Linkin', 'Park', 'Binaural', 'By', 'Pearl', 'Jam', 'Dark', 'Side', 'Of', 'The', 'Moon', 'By', 'Pink', 'Floyd']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = r\"[a-zA-Z]+\"\n",
    "# regex = r\"([a-zA-Z]+)(?:,\\s*|)\"\n",
    "\n",
    "# test_str = (\"\\\" Hybrid-Theory. By Linkin Park \\\",\\n\"\n",
    "# \t\"             \\\"Binaural. By Pearl Jam           \\\",\\n\"\n",
    "# \t\"             \\\" Dark Side Of The Moon. By Pink Floyd \\\"\")\n",
    "# matches = re.finditer(regex, test_str, re.MULTILINE)\n",
    "\n",
    "matches = re.finditer(regex, str(text_data), re.MULTILINE)\n",
    "print([i.group() for i in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38efdfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXX-XXXXXX XX XXXXXX XXXX',\n",
       " 'XXXXXXXX XX XXXXX XXX',\n",
       " 'XXXX XXXX XX XXX XXXX XX XXXX XXXXX']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
    "\n",
    "# Apply function\n",
    "[replace_letters_with_X(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc744c",
   "metadata": {},
   "source": [
    "Most text data will need to be cleaned before it can be used to build features. Most basic text cleaning can be completed using Python’s standard string operations or, by defining a custom cleaning function combining some cleaning tasks and applying that to the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeadac5",
   "metadata": {},
   "source": [
    "<a id=\"punc\"></a>\n",
    "<h5><ins>Removing Punctuation</ins></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a6d2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3fe8bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text = ['Hi!!!! I. Love. This. Song....',\n",
    "        '10000% Agree!!!! #LoveIT',\n",
    "        'Right?!?!']\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6c27a",
   "metadata": {},
   "source": [
    "`translate` is a Python method popular due to its blazing speed. In the example above, first we created a dictionary, punctuation, with all punctuation characters according to Unicode as its keys and None as its values. Next we translated all characters in the string that are in punctuation into None, effectively removing them. There are more readable ways to remove punctuation, but this somewhat hacky solution has the advantage of being far faster than alternatives. \n",
    "\n",
    "It is important to be conscious of the fact that punctuation contains information (e.g., “Right?” versus “Right!”). Removing punctuation is often a necessary evil to create features; however, if the punctuation is important we should make sure to take that into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db628a1e",
   "metadata": {},
   "source": [
    "<a id=\"parse\"></a>\n",
    "<h2><ins>Parsing and Cleaning HTML</ins></h2>\n",
    "\n",
    "Despite the strange name, Beautiful Soup is a powerful Python library designed for scraping HTML. Typically, Beautiful Soup is used to scrape live websites, but can just as easily be used to extract text data embedded in HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1ee87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d44f7590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Masego Azra'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some HTML code\n",
    "html = \"\"\"\n",
    "<div class='full_name'>\n",
    "<span style='font-weight:bold'>Masego</span> Azra</div>\"\n",
    "\"\"\"\n",
    "\n",
    "# Parse html\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", { \"class\" : \"full_name\" }).text.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1826df2",
   "metadata": {},
   "source": [
    "<a id=\"token\"></a>\n",
    "<h2><ins>Tokenizing Text</ins></h2>\n",
    "\n",
    "**Natural Language Toolkit** for Python (NLTK) has a powerful set of text\n",
    "manipulation operations, including word tokenizing.\n",
    "\n",
    ">**Tokenization, especially word tokenization, is a common task after cleaning text data because it is the first step in the process of turning the text into data we will use to construct useful features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b7c798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35c85bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow\"\n",
    "\n",
    "# Tokenize words\n",
    "word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6f193e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing using python's split() function\n",
    "string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f366e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi', 'I', 'Love', 'This', 'Song'], ['10000', 'Agree', 'LoveIT'], ['Right']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['Hi!!!! I. Love. This. Song....',\n",
    "        '10000% Agree!!!! #LoveIT',\n",
    "        'Right?!?!']\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "# For each string, remove any punctuation characters\n",
    "cleaned_text = [string.translate(punctuation) for string in text]\n",
    "\n",
    "[word_tokenize(string) for string in cleaned_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00db145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'I', 'Love', 'This', 'Song', '10000', 'Agree', 'LoveIT', 'Right']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "list(chain.from_iterable([word_tokenize(string) for string in cleaned_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08ad92",
   "metadata": {},
   "source": [
    "**Note the difference - `chain` alone requires unpacking the list with the `*` operator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "275fd543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'I', 'Love', 'This', 'Song', '10000', 'Agree', 'LoveIT', 'Right']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain(*[word_tokenize(string) for string in cleaned_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83f290",
   "metadata": {},
   "source": [
    "We can also tokenize into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2495396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "string = \"\"\"The science of today is the technology of tomorrow.\n",
    "Tomorrow is today.\"\"\"\n",
    "\n",
    "# Tokenize sentences\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ac43872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow', 'Tomorrow is today']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent.replace('.','') for sent in sent_tokenize(string)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801a00d",
   "metadata": {},
   "source": [
    "<a id=\"stop\"></a>\n",
    "<h2><ins>Removing Stop Words</ins></h2>\n",
    "\n",
    "Given tokenized text data, we may want to remove extremely common words (e.g., a, is, of, on) that contain little informational value. While “stop words” can refer to any set of words we want to remove before processing, frequently the term refers to extremely common words that themselves contain little information value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69b04510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this code once\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7abc77e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_string = \"The science of today, is the technology, of tomorrow.\"\n",
    "\n",
    "# Create a dictionary of punctuation characters and remove any punctuation\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "punc_free = text_string.translate(punctuation)\n",
    "\n",
    "# Tokenize the punctuation-free string\n",
    "tokenized_words = word_tokenize(punc_free)\n",
    "tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c7b14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb7d3fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science', 'today', 'technology', 'tomorrow']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All words in this list are lower case\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Remove stop words\n",
    "[word for word in tokenized_words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed2acf",
   "metadata": {},
   "source": [
    "<a id=\"stem\"></a>\n",
    "<h2><ins>Stemming Words</ins></h2>\n",
    "\n",
    "Given a list of tokenized words, we may want to convert them into their root forms. Stemming reduces a word to its stem by identifying and removing affixes while keeping the root meaning of the word. For example, both \"tradition\" and \"traditional\" have \"tradit\" as their stem, indicating that while they are different words they represent the same general concept. By stemming our text data, we transform it to something less readable, but closer to its base meaning and thus more suitable for comparison across observations. NLTK’s `PorterStemmer` implements the widely used Porter stemming algorithm to remove or replace common suffixes to produce the word stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d58ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "51ee6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this',\n",
    "                   'traditional', 'meeting']\n",
    "\n",
    "# Create stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5d255",
   "metadata": {},
   "source": [
    "<a id=\"tag\"></a>\n",
    "<h2><ins>Tagging Parts of Speech</ins></h2>\n",
    "\n",
    "Suppose we have text data and want to tag each word or character with its part of speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "255f3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0ee39a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am humbled by this traditional meeting'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "sentence = ' '.join(words)\n",
    "sentence\n",
    "# word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fcf0f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('humbled', 'VBN'), ('by', 'IN'), ('this', 'DT'), ('traditional', 'JJ'), ('meeting', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "# sentence = ' '.join(words)\n",
    "text = 'I am humbled by this traditional meeting'\n",
    "\n",
    "# Use pre-trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text))\n",
    "\n",
    "# Show parts of speech\n",
    "print(text_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558b0be",
   "metadata": {},
   "source": [
    "The output is a list of tuples with the word and the tag of the part ofspeech. NLTK uses the Penn Treebank parts for speech tags. Some examples of the PennTreebank tags are:\n",
    "\n",
    "|Tag|Part of Speech|\n",
    "|:-:|:-|\n",
    "|NNP|Proper noun, singular|\n",
    "|NN|Noun, singular or mass|\n",
    "|RB|Adverb|\n",
    "|VBD|Verb, past tense|\n",
    "|VBG|Verb, gerund or present participle|\n",
    "|JJ|Adjective|\n",
    "|PRP|Personal pronoun|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093d520",
   "metadata": {},
   "source": [
    "Once the text has been tagged, we can use the tags to find certain parts of\n",
    "speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "edfd691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'humbled']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter words\n",
    "[word for word, tag in text_tagged if tag.startswith('V')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f6798",
   "metadata": {},
   "source": [
    "A more realistic situation would be that we have data where every observation contains a tweet and we want to convert those sentences into features for individual parts of speech (e.g., a feature with 1 if a proper noun is present, and 0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "597216fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "tweets = [\"I am eating a burrito for breakfast\",\n",
    "          \"Political science is an amazing field\",\n",
    "          \"San Francisco is an awesome city\"]\n",
    "\n",
    "# Create list\n",
    "tagged_tweets = []\n",
    "\n",
    "# Tag each word and each tweet\n",
    "for tweet in tweets:\n",
    "    tweet_tag = pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "69084534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PRP', 'VBP', 'VBG', 'DT', 'NN', 'IN', 'NN'],\n",
       " ['JJ', 'NN', 'VBZ', 'DT', 'JJ', 'NN'],\n",
       " ['NNP', 'NNP', 'VBZ', 'DT', 'JJ', 'NN']]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de8a1aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list = sorted(list(set(list(chain(*tagged_tweets)))))\n",
    "tag_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "81f86787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "009bba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one-hot encoding to convert the tags into features\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "\n",
    "one_hot_multi.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a7b6f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d69ae8",
   "metadata": {},
   "source": [
    "If the text is English and not on a specialized topic (e.g., medicine) the simplest solution is to use NLTK’s pre-trained parts-of-speech tagger. However, if `pos_tag` is not very accurate, NLTK also gives us the ability to train your own tagger. \n",
    "- The major downside of training a tagger is that we need a large corpus of text where the tag of each word is known. Constructing this tagged corpus is obviously labor intensive and is probably going to be a last resort. \n",
    "\n",
    "If we had a tagged corpus and wanted to train a tagger, the following is an example of how we could do it. The corpus being used is the Brown Corpus, one of the most popular sources of tagged text. Here we use a `backoff n-gram tagger`, where $n$ is the number of previous words we take into account when predicting a word’s part-of-speech tag. \n",
    "- First we take into account the previous two words using `TrigramTagger`; if two words are not present, we \"back off\" and take into account the tag of the previous one word using `BigramTagger`, and finally if that fails we only look at the word itself using `UnigramTagger`. To examine the accuracy of our tagger, we split our text data into two parts, train our tagger on one part, and test how well it predicts the tags of the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac6f37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9a858e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some text from the Brown Corpus, broken into sentences\n",
    "sentences = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Split into 4000 sentences for training and 623 for testing\n",
    "train = sentences[:4000]\n",
    "test = sentences[4000:]\n",
    "\n",
    "# Create backoff tagger\n",
    "unigram = UnigramTagger(train)\n",
    "bigram = BigramTagger(train, backoff=unigram)\n",
    "trigram = TrigramTagger(train, backoff=bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d0459baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111044507717668\n",
      "0.8193466207103252\n",
      "0.8174734002697437\n"
     ]
    }
   ],
   "source": [
    "# Show accuracy\n",
    "print(unigram.evaluate(test))\n",
    "print(bigram.evaluate(test))\n",
    "print(trigram.evaluate(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa756ce",
   "metadata": {},
   "source": [
    "<a id=\"bag\"></a>\n",
    "<h2><ins>Encoding Text as a Bag of Words</ins></h2>\n",
    "\n",
    "Suppose we have text data and want to create a set of features indicating the number of times an observation’s text contains a particular word.\n",
    "\n",
    "One of the most common methods of transforming text into features is by using a bag-of-words model. Bag-of-words models output a feature for every unique word in text data, with each feature containing a count of occurrences in observations.\n",
    "\n",
    "In the real world, a single observation of text data could be the contents of an entire book. Since the bag-of-words model creates a feature for every unique word in the data, the resulting matrix can contain thousands of features. This means that the size of the matrix can sometimes become very large in memory. However, luckily we can exploit a common characteristic of bag-of-words feature matrices to reduce the amount of data we need to store.<br>\n",
    "$\\;\\;\\;\\;\\;\\;$Most words likely do not occur in most observations, and therefore bag-of words feature matrices will contain mostly 0s as values. We call these types of matrices \"sparse.\" Instead of storing all values of the matrix, we can only store nonzero values and then assume all other values are 0. This will save us memory when we have large feature matrices. One of the nice features of `CountVectorizer` is that the output is a sparse matrix by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76eb9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ce780a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both'])\n",
    "\n",
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# Show feature matrix\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0613a3",
   "metadata": {},
   "source": [
    "This output is a sparse array, which is often necessary when we have a large\n",
    "amount of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6439ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cde59113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d386bba",
   "metadata": {},
   "source": [
    "We can use the vocabulary_ method to view the word associated with each\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d1dd0ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b331704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beats</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>brazil</th>\n",
       "      <th>germany</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sweden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beats  best  both  brazil  germany  is  love  sweden\n",
       "0      0     0     0       2        0   0     1       0\n",
       "1      0     1     0       0        0   1     0       1\n",
       "2      1     0     1       0        1   0     0       0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas dataframe for clarity\n",
    "pd.DataFrame(data=bag_of_words.toarray(),\n",
    "             columns=count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68333788",
   "metadata": {},
   "source": [
    "`CountVectorizer` comes with a number of useful parameters to make creating bag-of-words feature matrices easy. First, while by default every feature is a word, that does not have to be the case. Instead we can set every feature to be the combination of two words (called a **2-gram**) or even three words (**3-gram**). `ngram_range` sets the minimum and maximum size of our n-grams. For example, (2,3) will return all 2-grams and 3-grams. Second, we can easily remove low-information filler words using stop_words either with a built-in list or a custom list. Finally, we can restrict the words or phrases we want to consider to a certain list of words using vocabulary. For example, we could create a bag-of-words feature matrix for only occurrences of country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dd728f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love Brazil. Brazil!', 'Sweden is best', 'Germany beats both'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dbbfae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 0],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix with arguments\n",
    "count_2gram = CountVectorizer(ngram_range=(1,2),\n",
    "                              stop_words=\"english\",\n",
    "                              vocabulary=['brazil', 'germany'])\n",
    "bag = count_2gram.fit_transform(text_data)\n",
    "\n",
    "# View feature matrix\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f2ee8fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazil': 0, 'germany': 1}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 1-grams and 2-grams\n",
    "count_2gram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f062b00",
   "metadata": {},
   "source": [
    "<a id=\"weigh\"></a>\n",
    "<h2><ins>Weighting Word Importance</ins></h2>\n",
    "\n",
    "Suppose we want a bag of words, but with words weighted by their importance to an observation.\n",
    "\n",
    "We can compare the frequency of the word in a document (a tweet, movie review, speech transcript, etc.) with the frequency of the word in all other documents using **term frequency-inverse document frequency (tf-idf)**. Scikit-learn makes this easy with `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d4230ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d8be5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both'])\n",
    "\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "# Show tf-idf feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1bc98134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "047ea611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec43903",
   "metadata": {},
   "source": [
    "The more a word appears in a document, the more likely it is important to that document. For example, if the word economy appears frequently, it is evidence that the document might be about economics. We call this **term frequency (tf)**. In contrast, if a word appears in many documents, it is likely less important to any individual document. For example, if every document in some text data contains the word after then it is probably an unimportant word. We call this **document frequency (df)**.\n",
    "\n",
    "By combining these two statistics, we can assign a score to every word representing how important that word is in a document. Specifically, we multiply tf to the inverse of document frequency (idf): \n",
    "$$\\text{tf-idf(t,d)}=tf(t,d)*idf(t)$$\n",
    "where $t$ is a word and $d$ is a document. There are a number of variations in how $tf$ and $idf$ are calculated. In scikit-learn, $tf$ is simply the number of times a word appears in the document and $idf$ is calculated as: \n",
    "$$idf(t)=log\\frac{1+n_d}{1+df(d,t)}+1$$\n",
    "where $n_d$ is the number of documents and $df(d,t)$ is term, $t$’s document frequency (i.e., number of documents where the term appears). By default, scikit-learn then normalizes the $tf-idf$ vectors using the Euclidean norm (L2 norm). The higher the resulting value, the more important the word is to a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e215af",
   "metadata": {},
   "source": [
    "<a id=\"date\"></a>\n",
    "<h1 align=\"center\">HOW TO HANDLE DATES & TIMES</h1>\n",
    "\n",
    "Dates and times (datetimes) are frequently encountered during preprocessing for machine learning, whether the time of a particular sale or the year of some public health statistic.\n",
    "\n",
    "<a id=\"convert\"></a>\n",
    "<h2><ins>Converting Strings to Dates</ins></h2>\n",
    "\n",
    "Given a vector of strings representing dates and times, suppose we want to transform them into time series data. We can use pandas’ `to_datetime` with the `format` of the date and/or time specified in the format parameter. We might also want to add an argument to the `errors` parameter to handle problems. If `errors=\"coerce\"`, then any problem that occurs will not raise an error (the default behavior) but instead will set the value causing the error to NaT (i.e., a missing value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d568fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "31bc8fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2005-04-03 23:35:00'),\n",
       " Timestamp('2010-05-23 00:01:00'),\n",
       " Timestamp('2009-09-04 21:09:00')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create strings\n",
    "date_strings = np.array(['03-04-2005 11:35 PM',\n",
    "                         '23-05-2010 12:01 AM',\n",
    "                         '04-09-2009 09:09 PM'])\n",
    "# Convert to datetimes\n",
    "[pd.to_datetime(date, format='%d-%m-%Y %I:%M %p', errors='coerce') \n",
    " for date in date_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe048084",
   "metadata": {},
   "source": [
    "When dates and times come as strings, we need to convert them into a data type Python can understand. There are a number of Python tools for converting strings to datetimes. One obstacle to strings representing dates and times is that the format of the strings can vary significantly between data sources. For example, one vector of dates might represent March 23rd, 2015 as \"03-23-15\" while another might use \"3|23|2015\". We can use the format parameter to specify the exact format of the string. Here are some common date and time formatting codes or view the [full list here](https://strftime.org/):\n",
    "\n",
    "|Code|Description|Example|\n",
    "|:-:|:-|:-|\n",
    "|%Y|Full year|2001|\n",
    "|%m|Month w/ zero padding|04|\n",
    "|%d|Day of the month w/ zero padding|09|\n",
    "|%I|Hour (12hr clock) w/ zero padding|02|\n",
    "|%p|AM or PM|AM|\n",
    "|%M|Minute w/ zero padding|05|\n",
    "|%S|Second w/ zero padding|09|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee59a69",
   "metadata": {},
   "source": [
    "<a id=\"zone\"></a>\n",
    "<h2><ins>Handling Time Zones</ins></h2>\n",
    "\n",
    "If not specified, pandas objects have no time zone. However, we can add a time zone using `tz` during creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "06d6e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to get list of timezones\n",
    "from pytz import all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "53d1967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_timezones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7df5fb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 06:00:00+0100', tz='Europe/London')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create datetime\n",
    "pd.Timestamp('2017-05-01 06:00:00', tz='Europe/London')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154afc94",
   "metadata": {},
   "source": [
    "We can add a time zone to a previously created datetime using tz_localize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ecb745e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 06:00:00+0100', tz='Europe/London')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create datetime\n",
    "date = pd.Timestamp('2017-05-01 06:00:00')\n",
    "\n",
    "# Set time zone\n",
    "date_in_london = date.tz_localize('Europe/London')\n",
    "\n",
    "# Show datetime\n",
    "date_in_london"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a57e9b",
   "metadata": {},
   "source": [
    "We can also convert to a different time zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "99b4538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 13:00:00+0800', tz='Australia/Perth')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change time zone\n",
    "date_in_london.tz_convert('Australia/Perth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "39a08fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-02-28 00:00:00+08:00\n",
       "1   2002-03-31 00:00:00+08:00\n",
       "2   2002-04-30 00:00:00+08:00\n",
       "dtype: datetime64[ns, Australia/Perth]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create three dates\n",
    "dates = pd.Series(pd.date_range('2/2/2002', periods=3, freq='M'))\n",
    "\n",
    "# Set time zone\n",
    "dates.dt.tz_localize('Australia/Perth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2203d71",
   "metadata": {},
   "source": [
    "<a id=\"time\"></a>\n",
    "<h2><ins>Selecting Dates and Times</ins></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "82887857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates\n",
       "0 2001-01-01 00:00:00\n",
       "1 2001-01-01 01:00:00\n",
       "2 2001-01-01 02:00:00\n",
       "3 2001-01-01 03:00:00\n",
       "4 2001-01-01 04:00:00"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.date_range('1/1/2001', periods=100000, freq='H')\n",
    "column = 'Dates'\n",
    "df = pd.DataFrame(data, columns=[column])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2163f398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2002-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2002-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2002-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dates\n",
       "8762 2002-01-01 02:00:00\n",
       "8763 2002-01-01 03:00:00\n",
       "8764 2002-01-01 04:00:00"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select observations between two datetimes\n",
    "df[(df['Dates'] > '2002-1-1 01:00:00') &\n",
    "   (df['Dates'] <= '2002-1-1 04:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da2c00",
   "metadata": {},
   "source": [
    "Alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "683f01e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>8762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>8763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>8764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     index\n",
       "Dates                     \n",
       "2002-01-01 02:00:00   8762\n",
       "2002-01-01 03:00:00   8763\n",
       "2002-01-01 04:00:00   8764"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be mindful of what is included and excluded in this range\n",
    "df = df.reset_index().set_index('Dates',drop=True)\n",
    "df.loc['2002-1-1 01:00:01':'2002-1-1 04:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae94bf",
   "metadata": {},
   "source": [
    "<a id=\"break\"></a>\n",
    "<h2><ins>Breaking Up Time Data into Multiple Features</ins></h2>\n",
    "\n",
    "Suppose we have a column of dates and times and want to create features from this. Sometimes it can be useful to break up a column of dates into components. For example, we might want a feature that just includes the year of the observation or we might want only to consider the month of some observation so we can compare them regardless of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cafc8b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-07</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-14</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-21</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-28</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02-04</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year  month  day  hour  minute  seconds Weekday\n",
       "0 2001-01-07  2001      1    7     0       0        0  Sunday\n",
       "1 2001-01-14  2001      1   14     0       0        0  Sunday\n",
       "2 2001-01-21  2001      1   21     0       0        0  Sunday\n",
       "3 2001-01-28  2001      1   28     0       0        0  Sunday\n",
       "4 2001-02-04  2001      2    4     0       0        0  Sunday"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Create five dates\n",
    "df['date'] = pd.date_range('1/1/2001', periods=150, freq='W')\n",
    "\n",
    "# Create features for year, month, day, hour, and minute\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "df['seconds'] = df['date'].dt.second\n",
    "\n",
    "# Using the strftime() function\n",
    "df['Weekday'] = df['date'].dt.strftime(\"%A\")\n",
    "\n",
    "# Show three rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e045bc",
   "metadata": {},
   "source": [
    "<a id=\"diff\"></a>\n",
    "<h2><ins>Calculating the Difference Between Dates</ins></h2>\n",
    "\n",
    "Suppose we have two datetime features and want to calculate the time between them for each observation.\n",
    "\n",
    "There are times when the feature we want is the change (delta) between two points in time. For example, we might have the dates a customer checks in and checks out of a hotel, but the feature we want is the duration of his stay. Pandas makes this calculation easy using the `TimeDelta` data type.\n",
    "[Pandas TimeDelta Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timedeltas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "47aa5fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0 days\n",
       "1   2 days\n",
       "dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Create two datetime features\n",
    "df['Arrived'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-04-2017')]\n",
    "df['Left'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-06-2017')]\n",
    "\n",
    "# Calculate duration between features\n",
    "df['Left'] - df['Arrived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9e6dc751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate duration between features\n",
    "pd.Series(delta.days for delta in (df['Left'] - df['Arrived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f9b78266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrived</th>\n",
       "      <th>Left</th>\n",
       "      <th>test</th>\n",
       "      <th>diff</th>\n",
       "      <th>diff2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0 days</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arrived       Left   test  diff  diff2\n",
       "0 2017-01-01 2017-01-01 0 days     0      0\n",
       "1 2017-01-04 2017-01-06 2 days     2      2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test'] = df['Left'] - df['Arrived']\n",
    "df['diff'] = pd.Series(delta.days for delta in (df['Left'] - df['Arrived']))\n",
    "df['diff2'] = df['test'].apply(lambda x: x.days)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d09ec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype          \n",
      "---  ------   --------------  -----          \n",
      " 0   Arrived  2 non-null      datetime64[ns] \n",
      " 1   Left     2 non-null      datetime64[ns] \n",
      " 2   test     2 non-null      timedelta64[ns]\n",
      " 3   diff     2 non-null      int64          \n",
      " 4   diff2    2 non-null      int64          \n",
      "dtypes: datetime64[ns](2), int64(2), timedelta64[ns](1)\n",
      "memory usage: 208.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275d17e",
   "metadata": {},
   "source": [
    "<a id=\"week\"></a>\n",
    "<h2><ins>Encoding Days of the Week</ins></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d46816ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrived</th>\n",
       "      <th>Left</th>\n",
       "      <th>test</th>\n",
       "      <th>diff</th>\n",
       "      <th>diff2</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Weekday_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0 days</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arrived       Left   test  diff  diff2    Weekday  Weekday_number\n",
       "0 2017-01-01 2017-01-01 0 days     0      0     Sunday               6\n",
       "1 2017-01-04 2017-01-06 2 days     2      2  Wednesday               2"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show days of the week\n",
    "df['Weekday'] = df['Arrived'].dt.day_name()\n",
    "df['Weekday_number'] = df['Arrived'].dt.weekday\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7158b33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Thursday\n",
       "1      Sunday\n",
       "2     Tuesday\n",
       "dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dates\n",
    "dates = pd.Series(pd.date_range(\"2/2/2002\", periods=3, freq=\"M\"))\n",
    "# Show days of the week\n",
    "dates.dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cf018",
   "metadata": {},
   "source": [
    "<a id=\"lag\"></a>\n",
    "<h2><ins>Creating a Lagged Feature</ins></h2>\n",
    "\n",
    "Very often data is based on regularly spaced time periods (e.g., every day, every hour, every three hours) and we are interested in using values in the past to make predictions (this is often called lagging a feature). For example, we might want to predict a stock’s price using the price it was the day before. With pandas we can use `shift` to lag values by one row, creating a new feature containing past values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eb344aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dates  stock_price  Lag1  Lag2\n",
       "0 2001-01-01          1.1   NaN   NaN\n",
       "1 2001-01-02          2.2   1.1   NaN\n",
       "2 2001-01-03          3.3   2.2   1.1\n",
       "3 2001-01-04          4.4   3.3   2.2\n",
       "4 2001-01-05          5.5   4.4   3.3"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Create data\n",
    "df[\"dates\"] = pd.date_range(\"1/1/2001\", periods=5, freq=\"D\")\n",
    "df[\"stock_price\"] = [1.1,2.2,3.3,4.4,5.5]\n",
    "\n",
    "# Lagged values by one row\n",
    "df[\"Lag1\"] = df[\"stock_price\"].shift(1)\n",
    "df[\"Lag2\"] = df[\"stock_price\"].shift(2)\n",
    "\n",
    "# Show data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb6b97",
   "metadata": {},
   "source": [
    "<a id=\"roll\"></a>\n",
    "<h2><ins> Using Rolling Time Windows</ins></h2>\n",
    "\n",
    "Rolling (also called moving) time windows are conceptually simple. Imagine we have monthly observations for a stock’s price. It is often useful to have a time window of a certain number of months and then move over the observations calculating a statistic for all observations in the time window. For example, if we have a time window of three months and we want a rolling mean, we would calculate:\n",
    "1. mean(January, February, March)\n",
    "2. mean(February, March, April)\n",
    "3. mean(March, April, May)\n",
    "4. etc.\n",
    "Another way to put it: our three-month time window “walks” over the observations, calculating the window’s mean at each step.\n",
    "\n",
    "Pandas’ rolling allows us to specify the size of the window using window and then quickly calculate some common statistics, including the max value (`max()`), mean value (`mean()`), count of values (`count()`), and rolling correlation (`corr()`). Rolling means are often used to smooth out time series data because using the mean of the entire time window dampens the effect of short-term fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ab545fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_Price</th>\n",
       "      <th>MA(2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Stock_Price  MA(2)\n",
       "2010-01-31            1    NaN\n",
       "2010-02-28            2    1.5\n",
       "2010-03-31            3    2.5\n",
       "2010-04-30            4    3.5\n",
       "2010-05-31            5    4.5"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create datetimes\n",
    "time_index = pd.date_range(\"01/01/2010\", periods=5, freq=\"M\")\n",
    "# Create data frame, set index\n",
    "df = pd.DataFrame(index=time_index)\n",
    "\n",
    "# Create feature\n",
    "df[\"Stock_Price\"] = [1,2,3,4,5]\n",
    "\n",
    "# Calculate rolling mean\n",
    "df['MA(2)'] = df.rolling(window=2).mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a9ba8",
   "metadata": {},
   "source": [
    "<a id=\"miss\"></a>\n",
    "<h2><ins> Handling Missing Data in Time Series</ins></h2>\n",
    "\n",
    "In addition to the missing data strategies previously discussed in the 'Data Cleaning' notebook, when we have time series data we can use interpolation to fill in gaps caused by missing values.\n",
    "\n",
    "Interpolation is a technique for filling in gaps caused by missing values by, in effect, drawing a line or curve between the known values bordering the gap and using that line or curve to predict reasonable values. Interpolation can be particularly useful when the time intervals between are constant, the data is not prone to noisy fluctuations, and the gaps caused by missing values are small.<br>\n",
    "$\\;\\;\\;\\;\\;\\;$If we believe the line between the two known points is nonlinear, we can use interpolate’s `method` to specify the interpolation method (e.g. `method='quadratic'`). Finally, there might be cases when we have large gaps of missing values and do not want to interpolate values across the entire gap. In these cases we can use `limit` to restrict the number of interpolated values and `limit_direction` to set whether to interpolate values forward from at the last known value before the gap or vice versa\n",
    "\n",
    "Alternatively, we can replace missing values with the last known value (i.e., forward-filling) or with the latest known value (i.e., backfilling). Back-filling and forward-filling can be thought of as a form of naive interpolation, where we draw a flat line from a known value and use it to fill in missing values. One (minor) advantage back- and forward-filling have over interpolation is the lack of the need for known values on both sides of missing value(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a342e63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    NaN\n",
       "2010-04-30    NaN\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create date\n",
    "time_index = pd.date_range(\"01/01/2010\", periods=5, freq=\"M\")\n",
    "\n",
    "# Create data frame, set index\n",
    "df = pd.DataFrame(index=time_index)\n",
    "\n",
    "# Create feature with a gap of missing values\n",
    "df[\"Sales\"] = [1.0,2.0,np.nan,np.nan,5.0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3226da08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>interpol_linear</th>\n",
       "      <th>Sales_ffill</th>\n",
       "      <th>Sales_bfill</th>\n",
       "      <th>interpol_quadratic</th>\n",
       "      <th>limits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales  interpol_linear  Sales_ffill  Sales_bfill  \\\n",
       "2010-01-31    1.0              1.0          1.0          1.0   \n",
       "2010-02-28    2.0              2.0          2.0          2.0   \n",
       "2010-03-31    NaN              3.0          2.0          5.0   \n",
       "2010-04-30    NaN              4.0          2.0          5.0   \n",
       "2010-05-31    5.0              5.0          5.0          5.0   \n",
       "\n",
       "            interpol_quadratic  limits  \n",
       "2010-01-31               1.000     1.0  \n",
       "2010-02-28               2.000     2.0  \n",
       "2010-03-31               3.060     3.0  \n",
       "2010-04-30               4.038     NaN  \n",
       "2010-05-31               5.000     5.0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['interpol_linear'] = df['Sales'].interpolate()\n",
    "df['Sales_ffill'] = df['Sales'].ffill()\n",
    "df['Sales_bfill'] = df['Sales'].bfill()\n",
    "df['interpol_quadratic'] = df['Sales'].interpolate(method=\"quadratic\")\n",
    "df['limits'] = df['Sales'].interpolate(limit=1, limit_direction=\"forward\")\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192dd714",
   "metadata": {},
   "source": [
    "<a id=\"how\"></a>\n",
    "<h1 align=\"center\">HOW TO SAVE AND LOAD DATA TRANSFORMS</h1>\n",
    "\n",
    "It is critical that any data preparation performed on a training dataset is also performed on a new dataset in the future. This may include a test dataset when evaluating a model or new data from the domain when using a model to make predictions. Typically, the model fit on the training dataset is saved for later use. The correct solution to preparing new data for the model in the future is to also save any data preparation objects, like data scaling methods, to file along with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b638b",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "<h2><ins>Challenge of Preparing New Data for a Model</ins></h2>\n",
    "\n",
    "Each input variable in a dataset may have different units. For example, one variable may be in inches, another in miles, another in days, and so on. As such, it is often important to scale data prior to fitting a model. This is particularly important for models that use a weighted sum of the input or distance measures like logistic regression, neural networks, and k-nearest neighbors. This is because variables with larger values or ranges may dominate or wash out the effects of variables with smaller values or ranges.\n",
    "\n",
    "Scaling techniques, such as normalization or standardization, have the effect of transforming the distribution of each input variable to be the same, such as the **same minimum and maximum in the case of normalization** or **the same mean and standard deviation in the case of standardization**. A scaling technique must be fit, which just means it needs to calculate coefficients from data, such as the observed min and max, or the observed mean and standard deviation. These values can also be set by domain experts.\n",
    "\n",
    "The best practice when using scaling techniques for evaluating models is to fit them on the training dataset, then apply them to the training and test datasets. Or, when working with a final model, to fit the scaling method on the training dataset and apply the transform to the training dataset and any new dataset in the future. It is critical that any data preparation or transformation applied to the training dataset is also applied to the test or other dataset in the future. This is straightforward when all of the data and the model are in memory. This is challenging when a model is saved and used later. What is the best practice to scale data when saving a fit model for later use, such as a final model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f76bbf",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "<h2><ins>Save Data Preparation Objects</ins></h2>\n",
    "\n",
    "The solution is to save the data preparation object to file along with the model. For example, it is common to use the **pickle framework** (built-in to Python) for saving machine learning models for later use, such as saving a final model. This same framework can be used to save the object that was used for data preparation. Later, the model and the data preparation object can be loaded and used. \n",
    "\n",
    "It is convenient to save the entire objects to file, such as the model object and the data preparation object. Nevertheless, experts may prefer to save just the model parameters to file, then load them later and set them into a new model object. This approach can also be used with the coefficients used for scaling the data, such as the min and max values for each variable, or the mean and standard deviation for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36e764",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "<h2><ins>Save Model and Data Scale</ins></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c1712a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((514, 8), (514,), (254, 8), (254,))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab = pd.read_csv('./datasets/Data Transforms/Diabetes.csv',header=None)\n",
    "df_diab.columns = ['pregnant','glucose_conc','blood_press','tricep_thick',\n",
    "                  'serum_ins','bmi','pedigree','age','target']\n",
    "\n",
    "X_diab = df_diab.drop('target', axis=1)\n",
    "y_diab = df_diab['target']\n",
    "\n",
    "# ensure inputs are floats and output is an integer label\n",
    "X_diab = X_diab.astype('float32')\n",
    "y_diab = LabelEncoder().fit_transform(y_diab.astype('str'))\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_diab, y_diab, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bc837e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">pregnant, train: min=0.000, max=14.000, test: min=0.000, max=17.000\n",
      ">glucose_conc, train: min=0.000, max=198.000, test: min=0.000, max=199.000\n",
      ">blood_press, train: min=0.000, max=122.000, test: min=0.000, max=110.000\n",
      ">tricep_thick, train: min=0.000, max=99.000, test: min=0.000, max=63.000\n",
      ">serum_ins, train: min=0.000, max=744.000, test: min=0.000, max=846.000\n",
      ">bmi, train: min=0.000, max=67.100, test: min=0.000, max=59.400\n",
      ">pedigree, train: min=0.085, max=2.329, test: min=0.078, max=2.420\n",
      ">age, train: min=21.000, max=72.000, test: min=21.000, max=81.000\n"
     ]
    }
   ],
   "source": [
    "# summarize the scale of each input variable\n",
    "for i in X_train.columns:\n",
    "    print(f'>{i}, train: min={X_train[i].min():.3f}, max={X_train[i].max():.3f}, test: min={X_test[i].min():.3f}, max={X_test[i].max():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d62f7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# transform both datasets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9abb3eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5969b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">col_1, train: min=0.000, max=1.000, test: min=0.000, max=1.214\n",
      ">col_2, train: min=0.000, max=1.000, test: min=0.000, max=1.005\n",
      ">col_3, train: min=0.000, max=1.000, test: min=0.000, max=0.902\n",
      ">col_4, train: min=0.000, max=1.000, test: min=0.000, max=0.636\n",
      ">col_5, train: min=0.000, max=1.000, test: min=0.000, max=1.137\n",
      ">col_6, train: min=0.000, max=1.000, test: min=0.000, max=0.885\n",
      ">col_7, train: min=0.000, max=1.000, test: min=-0.003, max=1.041\n",
      ">col_8, train: min=0.000, max=1.000, test: min=0.000, max=1.176\n"
     ]
    }
   ],
   "source": [
    "# define scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# transform both datasets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# summarize the scale of each input variable\n",
    "for i in range(X_test_scaled.shape[1]):\n",
    "    print(f'>col_{i+1}, train: min={X_train_scaled[:,i].min():.3f}, max={X_train_scaled[:,i].max():.3f}, test: min={X_test_scaled[:,i].min():.3f}, max={X_test_scaled[:,i].max():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4549542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "06b95864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# save the model\n",
    "dump(model, open('model.pkl', 'wb'))\n",
    "\n",
    "# save the scaler\n",
    "dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71262b11",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "<h2><ins>Load Model and Data Scale</ins></h2>\n",
    "\n",
    "We can load the model and the scaler object and make use of them. We will load the model and the scaler, then use the scaler to prepare the new data and use the model to make predictions. Because it is a test dataset, we have the expected target values, so we will compare the predictions to the expected target values and calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4c7e2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw test set range\n",
      ">pregnant, min=0.000, max=17.000\n",
      ">glucose_conc, min=0.000, max=199.000\n",
      ">blood_press, min=0.000, max=110.000\n",
      ">tricep_thick, min=0.000, max=63.000\n",
      ">serum_ins, min=0.000, max=846.000\n",
      ">bmi, min=0.000, max=59.400\n",
      ">pedigree, min=0.078, max=2.420\n",
      ">age, min=21.000, max=81.000\n",
      "\n",
      "Scaled test set range\n",
      ">1, min=0.000, max=1.214\n",
      ">2, min=0.000, max=1.005\n",
      ">3, min=0.000, max=0.902\n",
      ">4, min=0.000, max=0.636\n",
      ">5, min=0.000, max=1.137\n",
      ">6, min=0.000, max=0.885\n",
      ">7, min=-0.003, max=1.041\n",
      ">8, min=0.000, max=1.176\n",
      "Test Accuracy: 0.7755905511811023\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load(open('model.pkl', 'rb'))\n",
    "\n",
    "# load the scaler\n",
    "scaler = load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "# check scale of the test set before scaling\n",
    "print('Raw test set range')\n",
    "for i in X_test.columns:\n",
    "    print(f'>{i}, min={X_test[i].min():.3f}, max={X_test[i].max():.3f}')\n",
    "    \n",
    "# transform the test dataset\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# check scale of the test set after scaling\n",
    "print('\\nScaled test set range')\n",
    "for i in range(X_test_scaled.shape[1]):\n",
    "    print('>%d, min=%.3f, max=%.3f' % (i+1, X_test_scaled[:, i].min(), X_test_scaled[:,\n",
    "i].max()))\n",
    "\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299fbb9",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "<h2><mark style=\"background-color: yellow\">REFERENCES</mark></h2>\n",
    "\n",
    "<ins>BOOKS</ins>\n",
    "- [Data Preparation for Machine Learning by Jason Brownlee](https://machinelearningmastery.com/data-preparation-for-machine-learning/)\n",
    "- [Machine Learning Mastery With Python by Jason Brownlee](https://machinelearningmastery.com/machine-learning-with-python/)\n",
    "- [Machine Learning with Python Cookbook: Practical Solutions from Preprocessing to Deep Learning](https://gaurav320.github.io/vpspu.github.io/eb/pdf/ML.pdf)\n",
    "\n",
    "<ins>ARTICLES / WEBSITES</ins>\n",
    "- [Sebastian Raschka - About Feature Scaling and Normalization](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)\n",
    "- [Towards Data Science - Scale, Standardize, or Normalize with Scikit-Learn](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)\n",
    "- [Feature Scaling With Scikit-Learn by Ben Keen](http://benalexkeen.com/feature-scaling-with-scikit-learn/)\n",
    "- [Pandas/scikit-learn: get_dummies Test/Train Sets](https://dzone.com/articles/pandasscikit-learn-get-dummies-testtrain-sets)\n",
    "\n",
    "<ins>PYTHON PACKAGES</ins>\n",
    "- sklearn\n",
    "    - https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "    - https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data\n",
    "    - https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#\n",
    "    - https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#effect-of-transforming-the-targets-in-regression-model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
